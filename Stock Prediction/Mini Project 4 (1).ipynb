{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Stock_Price_MAX.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000/3/27</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000/3/28</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000/3/29</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000/3/30</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000/3/31</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj_Close   Volume\n",
       "0  2000/3/27  3.812500  4.156250  3.812500  4.125000   4.125000  3675600\n",
       "1  2000/3/28  4.125000  4.125000  4.000000  4.015625   4.015625  1077600\n",
       "2  2000/3/29  4.000000  4.031250  3.953125  4.000000   4.000000   437200\n",
       "3  2000/3/30  4.000000  4.000000  3.843750  3.843750   3.843750  1883600\n",
       "4  2000/3/31  3.734375  3.734375  3.390625  3.390625   3.390625  7931600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df =  data.iloc[:,[1,2,3,4,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close   Volume\n",
       "0  3.812500  4.156250  3.812500  4.125000  3675600\n",
       "1  4.125000  4.125000  4.000000  4.015625  1077600\n",
       "2  4.000000  4.031250  3.953125  4.000000   437200\n",
       "3  4.000000  4.000000  3.843750  3.843750  1883600\n",
       "4  3.734375  3.734375  3.390625  3.390625  7931600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closed_df = df.iloc[:,[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_df = df.iloc[:,[0,1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Z-Score\n",
    "from scipy.stats import zscore\n",
    "for col in normalized_df.columns:\n",
    "    col_zscore = col + '_zscore'\n",
    "    normalized_df[col_zscore] = zscore(normalized_df[col])\n",
    "    normalized_df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_zscore</th>\n",
       "      <th>High_zscore</th>\n",
       "      <th>Low_zscore</th>\n",
       "      <th>Volume_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.894311</td>\n",
       "      <td>-0.885122</td>\n",
       "      <td>-0.892408</td>\n",
       "      <td>1.104938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.883863</td>\n",
       "      <td>-0.886157</td>\n",
       "      <td>-0.886076</td>\n",
       "      <td>-0.497357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.888042</td>\n",
       "      <td>-0.889261</td>\n",
       "      <td>-0.887659</td>\n",
       "      <td>-0.892319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.888042</td>\n",
       "      <td>-0.890295</td>\n",
       "      <td>-0.891353</td>\n",
       "      <td>-0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896922</td>\n",
       "      <td>-0.899088</td>\n",
       "      <td>-0.906655</td>\n",
       "      <td>3.729791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open_zscore  High_zscore  Low_zscore  Volume_zscore\n",
       "0    -0.894311    -0.885122   -0.892408       1.104938\n",
       "1    -0.883863    -0.886157   -0.886076      -0.497357\n",
       "2    -0.888042    -0.889261   -0.887659      -0.892319\n",
       "3    -0.888042    -0.890295   -0.891353      -0.000263\n",
       "4    -0.896922    -0.899088   -0.906655       3.729791"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.concat([normalized_df, closed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_zscore</th>\n",
       "      <th>High_zscore</th>\n",
       "      <th>Low_zscore</th>\n",
       "      <th>Volume_zscore</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.894311</td>\n",
       "      <td>-0.885122</td>\n",
       "      <td>-0.892408</td>\n",
       "      <td>1.104938</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.883863</td>\n",
       "      <td>-0.886157</td>\n",
       "      <td>-0.886076</td>\n",
       "      <td>-0.497357</td>\n",
       "      <td>4.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.888042</td>\n",
       "      <td>-0.889261</td>\n",
       "      <td>-0.887659</td>\n",
       "      <td>-0.892319</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.888042</td>\n",
       "      <td>-0.890295</td>\n",
       "      <td>-0.891353</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>3.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896922</td>\n",
       "      <td>-0.899088</td>\n",
       "      <td>-0.906655</td>\n",
       "      <td>3.729791</td>\n",
       "      <td>3.390625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open_zscore  High_zscore  Low_zscore  Volume_zscore     Close\n",
       "0    -0.894311    -0.885122   -0.892408       1.104938  4.125000\n",
       "1    -0.883863    -0.886157   -0.886076      -0.497357  4.015625\n",
       "2    -0.888042    -0.889261   -0.887659      -0.892319  4.000000\n",
       "3    -0.888042    -0.890295   -0.891353      -0.000263  3.843750\n",
       "4    -0.896922    -0.899088   -0.906655       3.729791  3.390625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(df_final) * 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df = df_final.iloc[:train_size, [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_df = df_final.iloc[:train_size, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_df = df_final.iloc[train_size:, [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_df = df_final.iloc[train_size:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074, 4) (3074,) (1318, 4) (1318,)\n"
     ]
    }
   ],
   "source": [
    "tns_X_train = X_train_df.as_matrix(columns=None)\n",
    "tns_y_train = y_train_df.as_matrix(columns=None)\n",
    "tns_X_test = X_test_df.as_matrix(columns=None)\n",
    "tns_y_test = y_test_df.as_matrix(columns=None)\n",
    "print(tns_X_train.shape, tns_y_train.shape, tns_X_test.shape, tns_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 223.8821 - val_loss: 173.5744\n",
      "Epoch 2/100\n",
      " - 2s - loss: 34.4206 - val_loss: 605.2360\n",
      "Epoch 3/100\n",
      " - 2s - loss: 9.9900 - val_loss: 118.1167\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.4428 - val_loss: 26.7248\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.1673 - val_loss: 14.5633\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.8376 - val_loss: 0.9536\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.6820 - val_loss: 9.2721\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.4846 - val_loss: 2.6291\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.9963 - val_loss: 1.0624\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.4239 - val_loss: 0.9197\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.7566 - val_loss: 0.5387\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.5765 - val_loss: 0.4875\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.4954 - val_loss: 2.6395\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.3331 - val_loss: 3.1520\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.3463 - val_loss: 0.9523\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.3582 - val_loss: 1.5935\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.3374 - val_loss: 8.5619\n",
      "Epoch 00017: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 30s - loss: 212.0071 - val_loss: 955.0883\n",
      "Epoch 2/100\n",
      " - 2s - loss: 29.0807 - val_loss: 564.0577\n",
      "Epoch 3/100\n",
      " - 2s - loss: 11.2789 - val_loss: 133.4776\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.7255 - val_loss: 41.9261\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.0609 - val_loss: 26.4244\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.7800 - val_loss: 11.5636\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.7513 - val_loss: 10.8196\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.5048 - val_loss: 10.3987\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.4508 - val_loss: 4.8443\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.4438 - val_loss: 7.5347\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.4373 - val_loss: 1.4229\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.4907 - val_loss: 2.6411\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.5218 - val_loss: 3.1158\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.2476 - val_loss: 4.2661\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.2443 - val_loss: 5.5052\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.3225 - val_loss: 0.8963\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.3714 - val_loss: 0.5824\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.3893 - val_loss: 4.6618\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.1686 - val_loss: 2.0145\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.2186 - val_loss: 0.6573\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.2374 - val_loss: 0.5218\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.1268 - val_loss: 1.9497\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.2635 - val_loss: 1.1064\n",
      "Epoch 24/100\n",
      " - 2s - loss: 1.1131 - val_loss: 1.5877\n",
      "Epoch 25/100\n",
      " - 2s - loss: 1.2833 - val_loss: 1.0418\n",
      "Epoch 26/100\n",
      " - 2s - loss: 1.2850 - val_loss: 1.1138\n",
      "Epoch 00026: early stopping\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 30s - loss: 193.1291 - val_loss: 1127.3789\n",
      "Epoch 2/100\n",
      " - 2s - loss: 30.5312 - val_loss: 565.7290\n",
      "Epoch 3/100\n",
      " - 2s - loss: 7.8670 - val_loss: 64.9248\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.0224 - val_loss: 12.1998\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.7186 - val_loss: 16.5667\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.5971 - val_loss: 13.9621\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.5475 - val_loss: 2.0336\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.4148 - val_loss: 3.1788\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.4655 - val_loss: 1.3319\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.3449 - val_loss: 0.5915\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.3371 - val_loss: 1.1467\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.8554 - val_loss: 0.8155\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.5920 - val_loss: 2.6252\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.3086 - val_loss: 1.4889\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.3421 - val_loss: 0.9588\n",
      "Epoch 00015: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 30s - loss: 205.1276 - val_loss: 350.7704\n",
      "Epoch 2/100\n",
      " - 2s - loss: 31.1198 - val_loss: 773.1125\n",
      "Epoch 3/100\n",
      " - 2s - loss: 10.2443 - val_loss: 242.9575\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.8353 - val_loss: 60.8500\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.2010 - val_loss: 19.2902\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.7342 - val_loss: 9.7596\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.7139 - val_loss: 14.5262\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.8804 - val_loss: 20.0813\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.9600 - val_loss: 6.5666\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.5531 - val_loss: 7.1928\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.6026 - val_loss: 1.1790\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.6316 - val_loss: 13.1732\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.4255 - val_loss: 1.8337\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.5020 - val_loss: 4.0213\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.5403 - val_loss: 4.8903\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.4252 - val_loss: 3.1624\n",
      "Epoch 00016: early stopping\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 199.5189 - val_loss: 1663.3908\n",
      "Epoch 2/100\n",
      " - 2s - loss: 30.6073 - val_loss: 739.7551\n",
      "Epoch 3/100\n",
      " - 2s - loss: 9.6878 - val_loss: 105.0973\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.0278 - val_loss: 4.6031\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.2273 - val_loss: 3.5543\n",
      "Epoch 6/100\n",
      " - 2s - loss: 2.0244 - val_loss: 1.0475\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.8652 - val_loss: 1.0670\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.5098 - val_loss: 3.2599\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.6185 - val_loss: 0.6632\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.4365 - val_loss: 0.9689\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.3970 - val_loss: 3.7108\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.6055 - val_loss: 0.8576\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.3426 - val_loss: 0.6912\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.2761 - val_loss: 0.7809\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint outside the loop\n",
    "checkpointer = ModelCheckpoint(filepath=\"tns/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    tns_model = Sequential()\n",
    "    # Build network\n",
    "    tns_model.add(Dense(130, input_dim = tns_X_train.shape[1], activation='relu')) # Hidden 1\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(80, activation='relu')) # Hidden 2\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(30, activation='relu')) # Hidden 3\n",
    "    tns_model.add(Dense(1)) # Output\n",
    "\n",
    "    tns_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    tns_model.fit(tns_X_train, tns_y_train, validation_data = (tns_X_test, tns_y_test), callbacks=[monitor, checkpointer], \n",
    "                  verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6982330752187035\n",
      "R2 score 0.9993657067543181\n",
      "MSE::  0.4875294273293676\n"
     ]
    }
   ],
   "source": [
    "tns_model.load_weights('tns/weights.hdf5')\n",
    "tns_pred = tns_model.predict(tns_X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(tns_y_test, tns_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(tns_y_test, tns_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(tns_y_test, tns_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression chart.\n",
    "import matplotlib.pyplot as plt\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEtb/B5p09aqNcBgAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19468a29f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the chart\n",
    "chart_regression(tns_pred.flatten(), tns_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_train_df = df_final.iloc[:train_size]\n",
    "lstm_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1317, 5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_test_df = df_final.iloc[train_size+1:]\n",
    "lstm_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_X_train = lstm_train_df.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_X_test = lstm_test_df.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(SEQUENCE_SIZE, data):\n",
    "    lstm_X = []\n",
    "    lstm_y = []\n",
    "\n",
    "    for i in range(len(data)-SEQUENCE_SIZE-1):\n",
    "        #print(i)\n",
    "        window = data[i:(i+SEQUENCE_SIZE)]\n",
    "        \n",
    "        after_window = data[i+SEQUENCE_SIZE, 4]\n",
    "        \n",
    "        #window = [[x] for x in window]\n",
    "                \n",
    "        lstm_X.append(window)\n",
    "        \n",
    "        lstm_y.append(after_window)\n",
    "        \n",
    "    return np.array(lstm_X),np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3066, 7, 5)\n",
      "Shape of y_train: (3066,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_SIZE = 7\n",
    "\n",
    "lstm_X_train, lstm_y_train = to_sequences(SEQUENCE_SIZE, list_X_train)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(lstm_X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(lstm_y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test: (1309, 7, 5)\n",
      "Shape of y_test: (1309,)\n"
     ]
    }
   ],
   "source": [
    "lstm_X_test, lstm_y_test = to_sequences(SEQUENCE_SIZE, list_X_test)\n",
    "\n",
    "print(\"Shape of x_test: {}\".format(lstm_X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(lstm_y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 36.1890 - val_loss: 241.0106\n",
      "Epoch 2/100\n",
      " - 6s - loss: 13.0166 - val_loss: 384.8536\n",
      "Epoch 3/100\n",
      " - 7s - loss: 5.6167 - val_loss: 372.8344\n",
      "Epoch 4/100\n",
      " - 8s - loss: 6.6765 - val_loss: 436.5003\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.7897 - val_loss: 364.0614\n",
      "Epoch 6/100\n",
      " - 7s - loss: 3.8868 - val_loss: 277.1533\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 47.3441 - val_loss: 307.7120\n",
      "Epoch 2/100\n",
      " - 7s - loss: 10.6463 - val_loss: 351.4552\n",
      "Epoch 3/100\n",
      " - 7s - loss: 5.2170 - val_loss: 350.5377\n",
      "Epoch 4/100\n",
      " - 7s - loss: 4.0612 - val_loss: 293.9534\n",
      "Epoch 5/100\n",
      " - 7s - loss: 4.2812 - val_loss: 376.8109\n",
      "Epoch 6/100\n",
      " - 6s - loss: 3.6916 - val_loss: 563.1247\n",
      "Epoch 7/100\n",
      " - 8s - loss: 3.6197 - val_loss: 209.5149\n",
      "Epoch 8/100\n",
      " - 7s - loss: 3.1921 - val_loss: 204.4415\n",
      "Epoch 9/100\n",
      " - 7s - loss: 2.7583 - val_loss: 334.4006\n",
      "Epoch 10/100\n",
      " - 7s - loss: 2.8290 - val_loss: 158.4695\n",
      "Epoch 11/100\n",
      " - 6s - loss: 2.2766 - val_loss: 295.6018\n",
      "Epoch 12/100\n",
      " - 7s - loss: 2.2765 - val_loss: 368.2378\n",
      "Epoch 13/100\n",
      " - 7s - loss: 2.4017 - val_loss: 256.3950\n",
      "Epoch 14/100\n",
      " - 8s - loss: 2.7653 - val_loss: 263.9206\n",
      "Epoch 15/100\n",
      " - 6s - loss: 2.1069 - val_loss: 556.3247\n",
      "Epoch 00015: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 44.1734 - val_loss: 382.5184\n",
      "Epoch 2/100\n",
      " - 7s - loss: 9.0558 - val_loss: 499.3358\n",
      "Epoch 3/100\n",
      " - 7s - loss: 7.4207 - val_loss: 415.0374\n",
      "Epoch 4/100\n",
      " - 7s - loss: 5.2238 - val_loss: 170.1505\n",
      "Epoch 5/100\n",
      " - 8s - loss: 3.7169 - val_loss: 232.2567\n",
      "Epoch 6/100\n",
      " - 9s - loss: 3.1079 - val_loss: 359.9130\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.8251 - val_loss: 207.9568\n",
      "Epoch 8/100\n",
      " - 6s - loss: 2.6571 - val_loss: 287.1651\n",
      "Epoch 9/100\n",
      " - 7s - loss: 2.6464 - val_loss: 281.5017\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 29.6657 - val_loss: 302.3459\n",
      "Epoch 2/100\n",
      " - 7s - loss: 7.5494 - val_loss: 423.2669\n",
      "Epoch 3/100\n",
      " - 7s - loss: 3.8295 - val_loss: 585.0647\n",
      "Epoch 4/100\n",
      " - 7s - loss: 3.6076 - val_loss: 473.5523\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.2094 - val_loss: 276.2261\n",
      "Epoch 6/100\n",
      " - 8s - loss: 3.0988 - val_loss: 600.8938\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.7725 - val_loss: 441.0785\n",
      "Epoch 8/100\n",
      " - 7s - loss: 2.5459 - val_loss: 338.4699\n",
      "Epoch 9/100\n",
      " - 7s - loss: 2.6725 - val_loss: 375.4720\n",
      "Epoch 10/100\n",
      " - 7s - loss: 2.4845 - val_loss: 415.8688\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 42.1197 - val_loss: 200.2059\n",
      "Epoch 2/100\n",
      " - 8s - loss: 8.9392 - val_loss: 327.1272\n",
      "Epoch 3/100\n",
      " - 8s - loss: 5.0351 - val_loss: 223.1801\n",
      "Epoch 4/100\n",
      " - 8s - loss: 5.6254 - val_loss: 248.0225\n",
      "Epoch 5/100\n",
      " - 8s - loss: 4.3219 - val_loss: 357.5877\n",
      "Epoch 6/100\n",
      " - 7s - loss: 3.3175 - val_loss: 436.2175\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(256, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(100, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.588467954826672\n",
      "R2 score 0.7943254625791336\n",
      "MSE::  158.469525449698\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4VMX6wPHvkEIgJISQhBYgoRM6\nhA4qItWKFRQFEUW8KnrtV73W+7NebFdFFDsCggrYRRBpSgk1dEJNSEiD9J75/XF22U3YJJtkN7tJ\n3s/z5Nmzc9q7R9l358ycGaW1RgghhCitgasDEEII4Z4kQQghhLBJEoQQQgibJEEIIYSwSRKEEEII\nmyRBCCGEsEkShBBCCJskQQghhLBJEoQQQgibPF0dQHUEBQXpsLAwV4chhBC1SlRUVLLWOrii7Wp1\ngggLC2Pbtm2uDkMIIWoVpdQJe7aTW0xCCCFskgQhhBDCJkkQQgghbKrVbRC2FBQUEBsbS25urqtD\nqVN8fHwIDQ3Fy8vL1aEIIWpInUsQsbGx+Pn5ERYWhlLK1eHUCVprUlJSiI2NJTw83NXhCCFqSJ27\nxZSbm0vz5s0lOTiQUormzZtLrUyIeqbOJQhAkoMTyDUVov5xWoJQSn2slEpUSkVblb2mlDqglNqt\nlPpOKRVgte4JpdQRpdRBpdQ4Z8UlhBC13Vu/H2bz0RSnn8eZNYhPgfGlylYBPbXWvYFDwBMASqkI\nYDLQw7TPe0opDyfGVuccP36cr776qtL7TZ8+nWXLljkhIiGEMxxNyuSN3w+x+Viq08/ltAShtV4H\npJYq+01rXWh6+zcQalq+Glistc7TWh8DjgCDnBVbXVTVBCGEqF3e/SMGLw/F5EFtnX4uV7ZBzAB+\nNi23AU5ZrYs1ldVaX375JYMGDaJv377MmjWLEydO0LlzZ5KTkykuLmbkyJH89ttvHD9+nG7dujFt\n2jR69+7N9ddfT3Z2NgBRUVFcfPHFDBgwgHHjxhEfHw/AkSNHuOyyy+jTpw/9+/cnJiaGxx9/nPXr\n19O3b1/eeOMNioqKeOSRRxg4cCC9e/fmgw8+AIweSffeey8RERFcfvnlJCYmuuwaCSEqZ8XOOL7Z\nHsvkge0I8fNx+vlc0s1VKfUkUAgsNBfZ2EyXse9dwF0A7dq1K/c8z32/l32n06seqA0Rrf155soe\n5W6zf/9+lixZwsaNG/Hy8uKee+7hzz//5LHHHuPuu+9m8ODBREREMHbsWI4fP87BgwdZsGABw4cP\nZ8aMGbz33nvMmTOH++67jxUrVhAcHMySJUt48skn+fjjj7nlllt4/PHHmTRpErm5uRQXF/Pyyy/z\n+uuv88MPPwAwf/58mjZtytatW8nLy2P48OGMHTuWHTt2cPDgQfbs2cOZM2eIiIhgxowZDr1GQgjH\nW7EzjjmLd9KlRRMeGtulRs5Z4wlCKTUNuAIYrbU2J4FYwLq+FAqctrW/1no+MB8gMjLSZhJxtdWr\nVxMVFcXAgQMByMnJISQkhGeffZalS5cyb948du7ceX77tm3bMnz4cACmTp3K22+/zfjx44mOjmbM\nmDEAFBUV0apVKzIyMoiLi2PSpEmA8QCbLb/99hu7d+8+376QlpbG4cOHWbduHVOmTMHDw4PWrVtz\n6aWXOu06CCGqr6ComLdXH+adNUfo2zaAj6cPJKCxd42cu0YThFJqPPAYcLHWOttq1UrgK6XUXKA1\n0BnYUt3zVfRL31m01kybNo2XXnqpRHl2djaxsbEAZGZm4ufnB1zYhVQphdaaHj168Ndff5VYl55u\nX41Ia80777zDuHElO4T99NNP0mVViFoiK6+QR5bt4qc9CVzWvQWvXNeLQN+aSQ7g3G6ui4C/gK5K\nqVil1B3A/wA/YJVSaqdSah6A1nov8DWwD/gF+IfWushZsTnb6NGjWbZs2fn7+6mpqZw4cYLHHnuM\nW265heeff54777zz/PYnT548nwgWLVrEiBEj6Nq1K0lJSefLCwoK2Lt3L/7+/oSGhrJ8+XIA8vLy\nyM7Oxs/Pj4yMjPPHHDduHO+//z4FBQUAHDp0iKysLC666CIWL15MUVER8fHx/PHHHzVyTYQQ9lux\nM45J722k3/Or+CU6gUfHd+WjaZE0b9KwRuNwWg1Caz3FRvGCcrb/D/AfZ8VTkyIiInjxxRcZO3Ys\nxcXFeHl5MXfuXLZu3crGjRvx8PDgm2++4ZNPPmHUqFF0796dzz77jFmzZtG5c2dmz56Nt7c3y5Yt\n4/777yctLY3CwkIeeOABevTowRdffMGsWbP497//jZeXF0uXLqV37954enrSp08fpk+fzpw5czh+\n/Dj9+/dHa01wcDDLly9n0qRJrFmzhl69etGlSxcuvvhiV18uIQRGrf/HPfEs2nKSjUdSaBPQiNtH\nhDE2oiUD2jdzSUzK0gxQ+0RGRurSEwbt37+f7t27uyiiyjt+/DhXXHEF0dHRFW/sYrXt2gpRG5xK\nzWb5jjh+2ZvA3tPpBPs15I4R4cwcEY6nh3Nu8iilorTWkRVtV+cG6xNCiNogt6CIlbtO8+IP+0jP\nLaRfuwBeuKYnkwe2xctJiaGyJEG4WFhYWK2oPQghHCM6Lu18jSH2bA5hzRuz8t4RhAX5ujq0C0iC\nEEKIGpCUkcfcVQdZtOUUng0UQzs2518TuzO6ewgNPd1zZCFJEEII4UQpmXl8vS2WBRuOkZyZx8jO\nQfz3hj6E+Dv/SejqkgQhhBBOcCo1mw/WxfD1tljyC4sZ0iGQ927pz6DwQFeHZjdJEEII4QBaa1bu\nOs2fh5JISMtl6/FUCoo01/Zvw+yLO9K5hZ+rQ6w092gqF+Vq0qQJAKdPn+b6668vd9s333zz/GB/\nABMnTuTcuXNOjU+I+u5AQjr3LNzOnMU7WXcomez8Im4e1I5Nj1/K3Bv71srkAFKDcJmioiI8PCrX\nMNW6desK52548803mTp1Ko0bNwaMoTWEEM6xJzaN577fy7YTZwG4fkAor13fu84MZyM1CCcoawjv\nsLAwnn/+eUaMGMHSpUuJiYlh/PjxDBgwgJEjR3LgwAEAjh07xtChQxk4cCBPP/10ieP27NkTMBLM\nww8/TK9evejduzfvvPMOb7/9NqdPn2bUqFGMGjUKMLrRJicnAzB37lx69uxJz549efPNN88fs3v3\n7tx555306NGDsWPHkpOTU5OXS4ha51hyFg99vYsr/7eBffHpPHV5d7Y9dRmv39CnziQHqOs1iJ8f\nh4Q9jj1my14w4eUKN7M1hDcYo69u2LABMMZsmjdvHp07d2bz5s3cc889rFmzhjlz5jB79mxuu+02\n3n33XZvHnz9/PseOHWPHjh14enqSmppKYGAgc+fO5Y8//iAoKKjE9lFRUXzyySds3rwZrTWDBw/m\n4osvplmzZhw+fJhFixbx4YcfcuONN/LNN98wderUal4oIeqmc9n53P7JFo6nZDOhZ0ueubIHLZu6\nf4+kqpAahJOUHsLbnBRuuukmwBjNddOmTdxwww3nJxUyTwi0ceNGpkwxhrK69dZbbR7/999/5+67\n78bT08jxgYHl94zYsGEDkyZNwtfXlyZNmnDttdeyfv16AMLDw+nbty8AAwYM4Pjx49X45ELUXUeT\nMrl1gZEcPpk+kPenDqizyQHqeg3Cjl/6zmJrCG8AX1/jacni4mICAgJKzAtR3v6laa0rVZUtb8yt\nhg0tI0R6eHjILSYhyvDdjjj2xKXx4jU9GdUtxNXhOJ3UIJzE1hDe1vz9/QkPD2fp0qWA8QW+a9cu\nAIYPH87ixYsBWLhwIbaMHTuWefPmUVhoTPGdmmpM/1162G+ziy66iOXLl5OdnU1WVhbfffcdI0eO\ndMAnFaL+OHQmgxC/hkwd0t7VodQISRBOYh7Cu3fv3qSmpjJ79uwLtlm4cCELFiygT58+9OjRgxUr\nVgDw1ltv8e677zJw4EDS0tJsHn/mzJm0a9eO3r1706dPH7766isA7rrrLiZMmHC+kdqsf//+TJ8+\nnUGDBjF48GBmzpxJv379HPyphai7Nh1J5te9Z2jTrJGrQ6kxMty3E9SmIbwrwx2urRA1TWvNe2tj\nmLc2hqaNvfh8xiA6BDdxdVjVYu9w31KDEEKIcqw9lMRrvx4kNLAxC2cOrvXJoTLqdiO1i8gQ3kLU\nHd9EGfPIf3fPMHy83HPUVWepkzWI2nzbzF3JNRX1UXRcGj/sjmfywLb1LjlAHUwQPj4+pKSkyBea\nA2mtSUlJwcen7vb3FqK06Lg0pn+yBYCbB7dzcTSuUeduMYWGhhIbG0tSUpKrQ6lTfHx8CA0NdXUY\nQtSIwqJi7lm4ndyCYr69Zxi9QwNcHZJL1LkE4eXlRXh4uKvDEELUYkujYjmZms3DY7vQv10zV4fj\nMnUuQQghRFWl5xYwb20MCzYcY1BYIP8Y1cnVIbmUJAghhADWHkzkwSU7OZtdwKiuwbx0bd0Ztruq\nJEEIIeq9V385wHtrY+gQ7MvbU/oxsnOwq0NyC5IghBD12hd/n+C9tTFc3CWYN27qS6Cvt6tDchuS\nIIQQ9db++HRe+GEfke2bMf+2ATT0rH/POpSnzj0HIYQQ9pqzeAdeDRQvX9dLkoMNkiCEEPXS/HUx\nHDqTyeMTu9MpxM/V4bglSRBCiHonK6+QV385SK82TZk8sK2rw3FbkiCEEPXOxiPJFBZrHh7XFS8P\n+Rosi1wZIUS9s3jrKVr6+zC0Q3NXh+LWJEEIIeqV2LPZrDmQyKhuIXh7yldgeZx2dZRSHyulEpVS\n0VZlgUqpVUqpw6bXZqZypZR6Wyl1RCm1WynV31lxCSHqr4S0XEb/908ARnYOcnE07s+Z6fNTYHyp\nsseB1VrrzsBq03uACUBn099dwPtOjEsIUU+9+usBCoqKWTAtkgk9W7o6HLfntAShtV4HpJYqvhr4\nzLT8GXCNVfnn2vA3EKCUauWs2IQQ9dPW46lM6NmK0d1b1PtxluxR0zfgWmit4wFMryGm8jbAKavt\nYk1lQghRbdn5hfzjq+2cSs2hRxt/V4djv58fhz9eguJiSD4MS6ZCWizkpkMNTIrmLkNt2ErlNj+9\nUuoujNtQtGtXP2d5EkLYLzEjl399u4fVBxKZM7ozM4a7eL6Y3HTQxdCogkmIkg/DZtPd9rRTsHOh\nsbz/e+N16L0w7j/Oi5Oar0GcMd86Mr0mmspjAeunVUKB07YOoLWer7WO1FpHBgfLiItCiLLFp+Vw\n3fub+H1/Io+N78aDY7q4fm7puRHwSvuKt/tfpGXZnBys+Tr/+6+mE8RKYJppeRqwwqr8NlNvpiFA\nmvlWlBBCVMX3u04z9KU1nErN4Z0p/bj74o6uDSg3Df56D/IzLlx3Zh+s+Af8PQ9yzkJC9IXblNYk\npOJtqslpt5iUUouAS4AgpVQs8AzwMvC1UuoO4CRwg2nzn4CJwBEgG7jdWXEJIeo2rTXv/xnDgvXH\nCGrSkI+nR7rHnNLfPwB7v7W8LyoED9NX8OdXQ5bphsovj9l3vNqcILTWU8pYNdrGthr4h7NiEULU\nH7/uPcOrvxxkRKcgHhrbxXXJIfEAhHSzvE85XHL90bXQIgK+nmZJDpXR2PnPcbhLI7UQQlTbL9EJ\n3LMwio7BviyYHlmzQ3h/egXkZcCsP2HfSvj6VrjxC+h+pZEMEvaU3H7hdZU/R9N2kHbSWG7UrNoh\nV0QShBCi9ijIgSO/G1+6paw5cIY5i3fQOzSAL2cOrvn5HY6vN8WYayQHsLw6SuR06DEJYrdBMzsa\nuqtJBiIRQtQevz5pPAtwasv5oqJizZu/H2LGp9to06wRH02LpEnDGv7tm3rUsvxqB8cd16819LrR\nWG7RE4beB4EdoPeNjjtHOaQGIYSoPc6dMF5z0wBIyczjhg/+4mhSFpd0DeadKf3w8/GquXjys4zX\nt/tZygqyHHf8m7402if2fA23LAXPmp0vWxKEEKJWSsnMY8anWzmalMWL1/TklsHtam74jIwEiPoU\n1r1mPPRmrweioSAbgrtCWhxs/xwGTIO53Utu17yz0ajt4QldJ8CzaQ4N316SIIQQtYbWxrALX205\nybunNnI6LYdnr4xg6hDn348HjBrDuZOw5kU48EPl9vUNgQCr54GbtoFRTxjL924DTx/49HKjpvDd\n3UZ5gxqsDdkgCUII4fa01vwcnUCLk2cZAPxx4AyBIV35v2t7cXGXGhxR4ZcnYPtnFW9XWpMWMHN1\n2euDOhuvD+w2Xq//2KihBHcrc5eaIAlCCOHW/jyUxFu/H2L7yXMs9CkC4IOpkTToOqLmg0k6WPl9\nhvwDLn0KvBvbv09gOIx5rvLncjBJEEIItxR7Npu5vx3i2x1x+Pt48uI1PRl6uDnEQIMGLhqqu6Ff\n5ffpN7VyycGNSIIQQridxVtO8tRyYzyiGyNDeeqKCPx9vOCIKTHUwFDXNnk1siz7BEDuOTv28XFe\nPE4mz0EIIdzKxiPJPP7tHlo29eGXBy7i1ev7GMnBHXg2tCzftvzC9aOfgZCIkmVetbP2AJIghBBu\n5Ex6Lq+u3Mp9jX7lh3uH0ymkiatDMmgNB36CPUuN98+mQZNSU5b2ngzD51x4G8pTahBCCFEtyZl5\nTHhrPVNS5/GQ/oyAuD9dHZLF4VWwuNT4o9a1ieFz4Jr3oIEHXP8JDLrLsk5qEEIIUTVFxZqvNp/k\nktfWkpqVzyVtTWMoFeW5NjBr1iOxXvU/49W6ZjDmeSM5gPF8wyVPWNZ5uMntsSqQBCGEcJnUrHxu\nmLeJf323h2C/hiy9eygt/c2/zF3UU8kmq1iadzJey7t11MCq/09NPd3tBJIghBA1Lju/kLmrDjHs\n5dVsP3mOq/q05vd/XszAsEDL0BWqBr+eiouMv1X/htRjkHEGfnwYCvPh0K9w+DfLtuZbSw0awMA7\nYfpPFx6vgYunNXUQ6eYqhKgxuQVFfLcjjv/7cT8ZeYVc3rsVtw8Lo2/bADzMzzaYE4TNL9kyfo0X\nFcI3M2DEg9C6n+1tyvN8ILTqA/G7jJFiT/5llG/98MJtzU89A1z+uu3jKXPstbf2AJIghBA1JK+w\niIlvredochZ92gbw9OXdiQwLvHDD84Pf2fpyLeP5h7PHYN8KOLMX7ouyL6DYKPjoUrh7o/E+fpfx\nWlRQ/n72PCwnNQghhLDfsqhYjiZnce+oTsy5rDNeHmXcQjI/BFeVW0yVeYDOPNjeh5eWLI/bVvnz\nltbAE/xDLYPx1VKSIIQQTvfr3gSe/C6aDkG+3De6U9nJAazaIOy4PZOfDaf+hqZtK962tEJTLyln\n9JZSCv651/HHrWGSIIQQTnUkMYN/r4imc0gTPppmxzzRlWmk/uFB2L0YpiyxL5h9K41up42D4O93\n7dunHpMEIYRwiqJizTdRsbzwwz4aejXgjZv60r65b8U7VqYGkWwaXTUv3b6gzHNET3jNvu1Lu/Lt\nqu1XS0mCEEI4XGJ6Lg8t3cX6w8lEtPLnw2mRtAloVPGO1uypQZi3sWdWt3VWScHeWeB8QyBsBOz9\n1ng/YJp9+9URkiCEEA618Ugyjyzdxem0XO65pCP/HNMFz/LaHEortxdTqTJzgiguKlmeFmc8r+Ab\nZClb86KNc1RAqTrTI6kqJEEIIRxGa82DS3ZSrDVv3tSXa/q1qcJBKjHH8/kEUapr6humEVXLmsu5\nonOE9IBEUyOz+ano3pPtj6uOkCephRAOs/FICokZeTw4pkvVkgNYfXnb0WXVnCAqenahzHOUIfJ2\n8wksD71Z10bqCalBCCEc5vO/jgNwVZ/WVT+I+cu73C9xc/Iw3XIqfYvJ2tE/4VipkWFXPV329pc+\nBW0GWO3/h/F68u9y4qmbJEEIIRzi8JkMftt3hpsHt8OvOhP8mB92Ky9BlH6Yrijf9nYJ0fD5VZU7\n/0WPQPxu0/EVpMcZy454gK6WkVtMQohqyy8s5snl0TT29mDO6M4V71Aee2oQpbvCFpbxsNu84VWL\n4XwPqto9llJ1SYIQQlTbdzti2XIslYfHdqWFfzVnUDufIMprgyhVgyjMqd45AQbPhrCRxrJ1zyVv\n06x2wx+o/jlqGUkQQohqOX0uh9d/O0T3Vv7cPjys/I1TYspvLwD7EkTpp63LqkHYEtgRJtoYhbX/\nrTD9h5LHtV4edKf956gjJEEIIarlw/VHScrI48VreqDKe/r57HF4pz+seaGCI9rTBlEqQRxfb1+w\njYPgthVlfNlbxa6sahDFhcarR0PqG5ckCKXUg0qpvUqpaKXUIqWUj1IqXCm1WSl1WCm1RCnl7YrY\nhBD2m7vqEJ9sPM6Eni0Z0N7G0N3WMhON1+Mbyt/O3kbqnYsgI8F4bx6qu6KusaOfhgA7BvYzJzql\nLAnCUxKE0yml2gD3A5Fa656ABzAZeAV4Q2vdGTgL3FHTsQkh7PfiD/t4e/VhBoUF8toNfRx3YHsa\nqfPSYfndlofZzFKPwrNNy96vsIzeTqVZN1Kbn7GQBFFjPIFGSilPoDEQD1wKLDOt/wy4xkWxCSEq\n8Pu+M3y04RhBTbz53839aNLQgT3m7XlQrjJtDtbKG9rbr6Vl2boNwnw7yqP+3dSwK0EopebYU2YP\nrXUc8DpwEiMxpAFRwDmttakuRyxQxccwhRDOEp+Ww79XRHPnF9toE9CIb2cPJ6SqvZaOrYOtH11Y\nbk8NYudXlT+fX2vofVPZ6xtb3SKzvsU04VV4Otm+0WXrGHtrELaGMJxelRMqpZoBVwPhQGvAF5hg\nY1ObPx+UUncppbYppbYlJSVVJQQhRBUUFWuue28Ti7acZPLAdvx4/wjaNW9chSOZvmg/uxJ+fOjC\n1fa0QZzeXvnT3votNAmxb1vrHlRKGXNI1EPl1guVUlOAm4FwpdRKq1V+QEoVz3kZcExrnWQ6x7fA\nMCBAKeVpqkWEAqdt7ay1ng/MB4iMjKzE/IJCiMoqLtZsP3mW9YeT+eNgIqfTcnlrcl+u7luNCn5F\nv8TtGmqjEvpOhctfB69KDjcuKhxqYxPGbaAg4L9W5RnA7iqe8yQwRCnVGMgBRgPbgD+A64HFGDWW\nFVU8vhCimrTWvLc2hk82HiM502jY7dbSj1ev6131cZbMv8rPnoDXOpVclxYLTVoYv9Stn4OI3wUr\n7oVpKyE3DY6ssv98A2cat7AGTJPkUEXlJgit9QngBDDUUSfUWm9WSi0DtgOFwA6MGsGPwGKl1Ium\nsgWOOqcQwn6bYpJ5ank0R5Oy6NnGn8fGdyMyLJDwIDtmgyuXKUFkJpQsfi4QdBFE3gFXzLUkiLx0\nWPEPSNgDcyOgINv+UykPuPy/xl91Yq3nQ23Y1fVAKZWB5Yp5A15Altbavyon1Vo/AzxTqvgoMKgq\nxxNCVF9adgGPLNvFb/vO0NLfhxev6cktg9uV//CbI2jTk9XbFsDYFzj/VfPDg5Zt7EkOzcKMh/H6\nToWJr1YvJp8A4zWikgP91TF2JQittZ/1e6XUNciXuRB1QlpOAYu2nOT9tTGk5RQwc0Q4D4/rio+X\ng2dSK3dsJZPfnrJvO1sGzYLgLhB2EXhWs0tqowB45KjxWo9VqfOy1nq5UupxRwcjhKhZ8Wk53PLR\nZo4mZTGsY3Men9CN3qFO+lLUFYzBBLDtY/CvoAG860Q4+JPlvfIwjl1cAJ0usz+e3jcZD8GZ55su\nzbe5/ceqo+y9xXSt1dsGQCR2TfckhHBHeYVFfL7pBP9ddRAPpfjqzsEM6+jkGdMqGqTPzDz/Qln6\n3QpXvg2vmxq6h8+BDXPLnhOiLNfON17LShDC7hrElVbLhcBxjGcZhBC1zI6TZ/m/n/az9fhZerbx\n5/Ub+tCtZZWaE8tXmA/Ry6DPFKNrqz01iLIEdYWh90CjQOg20Si7fyckH4I40zMRRYVl7y+qxN42\niNsr3koI4e4S03O57v1NFGt44eoe3Do0zHknW/carHvV6GLaYxIUV/G5hpuXQpexF5YHhht/OWeN\n9/6tqh6rsMneW0wdgLeAIRi3lv4CHtRaH3VibEIIByksKub73af54M+jFGtYevdQBoZVMPpqdZlv\nFeVlGq9VqUHMWgetKhgIsPdN0Lg5dBxd+eOLctl7i+kr4F1gkun9ZGARMNgZQQkhHOdoUib//HoX\nO0+dw9fbg3dv7u+85FCQA3uWQb+plmGyG5i+ZuxtgwC44VNIPw0te1e8rVLQeUylQxUVszdBKK31\nF1bvv1RK3euMgIQQjpOZV8jtn24lOSOPZ6+MYPKgdo7vvmpt3Wuw/r/Q0O/CBFGZGkSPSRVvI5zO\n3gTxh6lb62KMW0w3AT8qpQIBtNapTopPCFFFZ9JzuW3BFmLP5jBv6gDGRLRw/knNw3AvnWY0KANk\nJcKx9fb1Mhp8NxTmOi8+USn2JgjzGLmzSpXPwEgYHRwWkRCiWnILiliy9RQv/byf3IJi3prct2aS\nQ1EB/PU/y/sc0+/GX/9l/zEmvOLYmOwx6ilo0aPmz1sL2JsgumutS6R1pZRP6TIhhGtk5RWy/nAS\n20+eY8XOOM6k59GzjT8vX9ubnm3KmWHNkZIPVW//SBdNInnxI645by1gb4LYBPS3o0wIUcNW7Izj\nhR/2kZyZj5eHYkD7Zjw0tiuT+rXBy6OGJo0szIOUI1Xb18sXCrKgdV/HxiSqraL5IFpizOzWSCnV\nD8vQhv4YU4UKIVwgLbuAn6LjWbL1FDtPnaNnG39eu6EPQzs0d24jdFk+uBiS9ld+vwf3wdqXYMcX\njpv/QThMRTWIcRgzx4UCc63KM4BK3FgUQjjCyl2nWXsgkZ+i48ktKMbPx5NnroxgirN7J5Xl5GZA\nX5gcPH1sNzZf+hSsedHyvmkby/zPVR2kTzhNRfNBfAZ8ppS6Tmv9TQ3FJIQoZVNMMku3xfLdjjga\neXlwUedg7rqoA33aBtTcbSRbPrbxhDNAm0g4scHyPrg7jH0RwkdC0iHY87VlnXk4calBuB172yB6\nKqUuaObXWj/v4HiEEFbScgp4dNkuft17Bm/PBlzVpzWv39AHb08XJgV7eJT6aukzGTqbRlq94o2S\nCaJNJER9CkFdaiw8YR97E0Sm1bIPcAVQhRuOQgh7/bY3gYeX7iIrv4hZF3Xggcu60MjbBbeRqqKB\nV8n3w+dYrSv1GfpNhXZDIai9Ao02AAAfzUlEQVTUNKTC5ewdrK/EvH1KqdeBlU6JSAjBip1xPLJ0\nN22aNWLeNT0Z1snJQ3E7mkepCXusZ6VTpgQR1NWyTpKDW6rShEEYPZjk4TghnGDFzjjmLN5JrzZN\n+Xj6QIL9Gro6pMrz8Cp7nac3TF4EoZE1F4+oEntHc92DZYKgBkAI8IKzghKivjqYkMFbqw8T2qwR\nS+8e6pqeSdayUozhur1L9WrPSDB6KpXFq1H5xzXP6SDcmr01iCuAZsBIIAD4SWsd5bSohKhnok6k\nsvDvk3y7Iw5vzwa8eHVP1yaHglzIToE3IqBFT5i90SjPTjW6qW5bUP7+fi2dH6NwOnsTxNXAncC3\nGA/LfaKU+lBr/Y7TIhOiDisu1mw7cZa1BxOJOnGWzcdSaejZgKlD2vHPMV0J9PWu+CDO9PVtcPhX\nY/lMtKX892dh+2cV7z/8ATh3yphRTtRa9iaImcAQrXUWgFLqFYxJgyRBCFEJW46lsnxnHJuPphCT\nlAVAj9b+/HNMF2aODKexd1WbBashMxGivzFGUo3fCT4BluRg9mxTozz3nH3HbBQA1y+AJiEQKM2V\ntZXd80EA1oO5F2EZdkMIUY6M3AKWbD3FV5tPcjQ5C2+PBgwMb8asizpySbdgQvzKuZfvTOnxsO1j\n2PIB5KZBl3Ew/5Kyt7eVHDwbQWFOybIr37Isj3/JIaEK17A3QXwCbFZKfWd6fw1QwU1IIeqv4mLN\n30dT+HD9UdYeSkJr6NM2gOev7sHVfdrQtHE5vXxqwrF18NmVJcuqMtTFLV+XPI5fKxgwvVqhCfdh\n73MQc5VSa4ERGDWH27XWO5wZmBC1zdmsfLYeT+Xvo6ms2BlHSlY+zX29uWtkB8ZEtKB/u2Y0aODi\nivfupcZzB6c2X7hu1+LKH6+BF0z+Cg78CDsXQodLqhuhcCN23/DUWm8HtjsxFiFqnYzcAj7deJzV\nBxLZezqNgiKNl4diWMcgrunXmgk9W7m+q6q1b2car+EXXbhu3auVP15DP2g/FMJGwNnjcPFj1QpP\nuBcXtIgJUfsVF2tWH0jk0WW7OJtdQHiQLzOGh3NZRAt6tWnqXknB7PAqy/KxdZXf39MHxjwPuxbB\n6R0weDa07Gms82kKt//kmDiF25AEIUQlpOcW8E1ULEu2nuJAQgYdgn2Ze2NfLukajFJu3m/j4M+2\nyyNnGI3VFWneCQbPgvjdRoJoP8yx8Qm3IwlCCDvlFxYz45OtbDtxlg5Bvvz3hj5c3ttNbiGd+As+\nGQ/3bYfmHW1vU9bDbQ39Kz5+u2Fww6fG8rgXwTcIuoyvUqii9pAEIYQdzqTncsdnW4mOS+eFq3sw\ndUh796oxRH1qvB5bV3aCKEuTkAvLnjwD/2lhLM/eBC2sRvtv1AzGPFelMEXtIglCiApEnUjlgSU7\nOZWaw/2jO3PLYDdLDsVFsNvUA+nUFmP4bPNgeV9eD5kJcPsvZe9feh6GJxPAywfu3miMwSQPutVb\nkiCEKMfe02ncumAL3p4NeO+W/kzs1crVIV0oI96yvOsrKC6E6z403h8xNUy/1Kbs/T194NoP4ds7\nIaC9ZaA9cwO0qLdcMi2VUipAKbVMKXVAKbVfKTVUKRWolFqllDpsem3mitiEsPbvFXspKtZ8O3uY\neyWHzR8Yw18UFcK5kyXXndhY/r6hA0u+b9zcaIAGKCpwXIyi1nPVvIVvAb9orbsBfTBmp3scWK21\n7gysNr0XwmWKijU7T51j6pD2dAhu4upwLKK/hZ8fNZYzEyB+V8n13r6QlQyryxiR//pPSr4P7gpe\npuG8iwsdG6uo1Wr8FpNSyh+4CJgOoLXOB/KVUlcDl5g2+wxYC8hTN8JlftwTT1Gxplebpq4NJC7K\nGCjP3Pj85yuWdW9cMFU85GXCa+U0VAe0hUePwavhRu+kBh5GmwNAsdQghIUr2iA6AEkYQ4b3AaKA\nOUALrXU8gNY6Xillo2uFEDXjeHIWjy3bTdvARlze24m3lmLWGJPy9L6h7G0+vNR4beBl6j1UQQN5\nxumKz9s4EObsNrqrgjHoHhi3rIQwccUtJk+gP/C+1rofkEUlbicppe5SSm1TSm1LSkpyVoyinvvr\naAo5BUV8dNtAvDyc+M/ki0mW4S9KS4mBhD2W98UFxnwMykY8LexsUA6JsCw3a2/cjgJLw7TcYhJW\nXFGDiAVitdbm0cKWYSSIM0qpVqbaQysg0dbOWuv5wHyAyMjIKgw/KUTFDp/JxMerAZ1DarjtIWEP\n/PQInPzL9vqifEjce2F5YHjJiX3K0v1K2+XmBNHCxi0rUW/VeA1Ca50AnFJKdTUVjQb2ASuBaaay\nacCKmo5NCLPNx1LoFNKkeqOvntpq9DRKibG9/sy+C8vmjSg7OZSnTaR922Wn2i738ILpP8EtSyt/\nblFnueo5iPuAhUopb+AocDtGsvpaKXUHcBIo56asEM6jtWZffDozhodXZWfQxUbD765FRlnMGttP\nN6fHXbhvZfiGQMTVED4Sul0JGQng3xpWPW2sbxQIOaUSwsiHyj5e2PDKnV/UeS5JEFrrnYCtnzyj\nazoWIUorKNJoTdXmhX53sJEg7tsGVPCFX7otoSC77G0j74D9KyHL1O72RKzRsOxh9U94wsvGqzlB\nDL4b1v5fyeP4u9GzHMLtueo5CCHcVl6hMbtuQ88q/PNIPggph41lc42grGE5GpQa5C8v48Jtht0H\nM1fDFXPhoUOWcu8mJZNDieOahtkY+RA8nWKMqyREFUiCEKKU3IJioIwE8cOD8OV1FR9Eayw1CKsE\nUVwMm+dDzrmSPYaOrYOkgxcep8sECDVVthtYxVPeWFB3roZL/mUkEA9PyzMOQlSSjMUkRCmWGoSN\nYbztmTcBjCErbNUg4nfCz4/AoV8gZrWlvPT80GYepeauHv8K7P++/HO36mP8lRbQvuK4hbAiNQgh\nSskrNNUgvMr55/HFteUfpCAbmzWI7BTj1To52NJjkrFfcNeS5UPuhtt/LH9fWx47Aff8Xfn9RL0m\nNQghSsk7f4upnImAYlbD78/BhrkQ2BFGPAj9b7WsX/uypUtp8mH4+XHof1vJB9/KMms9tOrt2H58\njQIceDBRX0iCEKKUPw8ZPYVaB1Rw737DXOM1NQZW3mv8mW1+37L897sXlpk19Idh9xsPue1bbpSZ\nn24WwsUkQQhh5Ux6Lv9bc5jLuregd6jpV/ezTaHTGMvcCo4SEgF3bzB6M239yJIgfOTXvnAP0gYh\nhMnhMxlc/vZ68ouKefLy7iVXOjI5+Icar1e9Y+nq2ijQeG3dD3ybO+5cQlSDJAhR7xUWFfNLdDxT\nPtxMZl4h/7u5P+FBpts8xcWVP+BFj1iWI+8wXntPhlFPGss3fmYMtx1q9axouyHG65B/VP58QjiJ\n3GIS9ZbWmrdWH2blrtMcTcoixK8hn94+iCEdrH7BF+XZf8C+U6H9MOh3C6x7zSi79CmIvB1a9jKS\nTbcroEXEhfv6t4ZnzpX/fIMQNUwShKhXcvKLWLz1JIfOZLLxSDInU7PpFNKE/0zqyY2RbS8c2nvV\nMxUf9J/7wcPbMrcCwJgXjJneGgcaf2A86GYrOZhJchBuRhKEqPOy8gpZFhXLj7vj2R+fTkZeIV4e\nisHhzZk+LIzpw8LKHrV1ywcXlg29F9oOgh1fGjUC/9YXbjP8fsd+CCFcQBKEqJOKijUbjySz5kAi\ni7acJK+wmB6t/ZnYqxXjerbg0m4tqnbgyYug02Xg6W2MpCpEHSYJQtQZp1KzWRoVy65T59hx8izp\nuYUoBSM7BzNndGcGtG9W/ZN0m1j9YwhRS0iCELXe0aRM3vz9ML/vP0N2fhHdWvoxvmdLhnUMYlTX\nEJo29qr4ILaUnp/h8v9WP1ghahFJEKJWyskv4u+jKfy+/wwLN5/Ey0Nxea9WzL6kE11b+lX/BEUF\nsNmq/eH+HRDYofrHFaIWkQQhao20nALWHUrijwOJ/LI3gez8Irw9GnBZ9xCevDzC8uyCI2z/HH4z\nPbdw3QJJDqJekgQh3F52fiGzvohi45FkijX4+3hyZe/WXNGnFQPDAvHxKmdQPUfwaerc4wvhpiRB\nCLe34XAy6w8nM31YGON7tmRgWCAeZXVLdRTrpCAJQtRTkiCE2/to/TF8vT3418TueFdlGtCqKC6y\nLEuCEPWUjMUk3Na57Hzu/iKKLcdTmTYsrOaSA5QcYqNpaM2dVwg3IjUI4ZZy8ouY/eV2/jqaws2D\n23H/6M41G0ChVYKQ+RlEPSUJQrgNrTXJmflsiknm3T+OcOhMJo+N78bsSzrWfDBFBTV/TiHcjCQI\n4VJ5hUWs3p/IT3viWX84mbQc44u5dVMfFkyLZHT3Kg6JUV3mW0zjX3HN+YVwA5IgRNmSDkFwF4cf\ntqhYs+90OusOJ/H5X8c5k55Hc19vxka0oHsrfyJa+9OvXUD5c0I7S2G+kRzMNYiBM2s+BiHchCQI\nYdueZfDNHTBlCXQd77DDnj6Xww3z/iLuXA4AXVv48cSE7lzVp3XZI6rWpC+vhePrjbmiPbzBQ/6J\niPpL/u8XtiXsNl6T9jssQaw7lMQDS3aSllPAC1f3YFzPloT4+Tjk2JVSXAy7FhkD7xXkGp+x3TDw\n8jGSA0Bees3HJYSbkQQhnKK4WHMgIYONR5LZfvIsp8/lsCs2jaAm3iy9eyj92zlgZFWz3HQoLrRM\nzFNiXRr8+DBMeAV+exrid0JwV4j+BnaNtCQEgMYyF7QQ1iRBCNtKj2RqQ1Gx5vS5HI6nZHEqNYfY\ns9kkpOVyLCWL6Lg0CoqMY4Q1b0xos8bMHBHOzYPb0SG4SdXjys8Cz0bG7Gxm7wyArER4Nq1k/EoZ\nYyrt+dr4MzsTbbxaJweA7JSqxyVEHSQJQlTAaBfIyitk7+l0thxL4UBCBgcTMjiRkk1+UfH5LT0b\nKFr4+9CyqQ8zhofTuYUfwzs1p1XTRo4JpSAX/q+1MaPbuP9YklhWovG6/QvwDYaGfvCpzNsgRHVJ\nghA25RQU0whYvPUUb61fTXxa7vl1rZv60KNNUy7tFkJ4kC/tm/vSrnljWvr72B4jKeccFOSAf6vq\nBVWQbbxumQ9+LeG3p4yGZLOV91bv+GZPp8ALzaHXDY45nhC1lCQIcd6p1Gx+3ZvAgYQMeuw9ye0Y\nI6kO6dCcjsG+dAxuwrBOQTRtZJqAZ/Xz0KQvdLyq/AO/1dtoC7C+BVQVBUbPJ4ryjeRgXq6MTmOM\noTOiPrlwXY9JcNU7Rs+lx0+ClzxBLeo3lyUIpZQHsA2I01pfoZQKBxYDgcB24FatdSX/9YvK0lqz\n/eQ53v3jCOsOJVFYrAn2a8gov4aQATOGh8OIvrZ3Xm+aYa2iL/7caiYGgP3fw5KpVd//6WSI3QoB\n7aFpG6PROmEP5JyF1v2NAflUA0vbhgzQJ4RLaxBzgP2Av+n9K8AbWuvFSql5wB3A+64Krq47kpjJ\ngg3H+PNgIqfTcvFr6MmMEeHcNrQ9oc0aw29rYRNGQ6+rFeRWPjkEtIdpK6FpW2hgeuCu/TDLes+G\nEBrpuBiFqINckiCUUqHA5cB/gH8qpRRwKXCzaZPPgGeRBOEQBUXFxJ7N4WBCBj/uiWfjkWRSs/Lx\n8lBc1r0Fs0cFcXmvVgT6Wt3Pt6MXU5nOnYI3e8K1H0FvB9zHj99Z/vpL/gUdR8GvT8ItX4OnD3g5\nqGFciHrMVTWIN4FHAfPkwc2Bc1rrQtP7WKCNKwKrS7TWvP9nDO+sPkJOgTG/QZOGnoyJaEG/dgGM\n69GSFv4VPahWhRpE4j7jdfdixySIwtyS73teD9HLjGEwLv+vpXzmquqfSwhxXo0nCKXUFUCi1jpK\nKXWJudjGpjZ/wiql7gLuAmjXrp1TYqwrFm05xau/HGRA+2ZMGdSO8CBferbxd/4YR+bax5HfIS+j\n+sf76ZGS7695D65fUP3jCiHK5YoaxHDgKqXURMAHow3iTSBAKeVpqkWEAqdt7ay1ng/MB4iMjKzG\nfZC67de9CTz3/V4GhQWy+K4hjh/nyN5bUH++Wr3zbHoHkg8Zy0/EGQ3Jng2rd0whhF1qPEForZ8A\nngAw1SAe1lrfopRaClyP0ZNpGrCipmOrK778+wTPfb+X7q38eWtK3+olh7IaqcudL8EqeZi7ppoV\nF8OZPRD1GXSdCM3aw8+PQWYiZCVBZgJMeNXYLyTC0p3Vpyk0rMYT2EKISnOn5yAeAxYrpV4EdgBy\nD6EKjiRm8tTyaLq19OOLOwZbnllwtGIbCSL6G/j9WRj3f5Yy6wSz8ytYPtvyflsZ/4l/fvTCskY2\nxlkSQjiVSxOE1notsNa0fBQY5Mp4ajutNd/tiAXgvzf2cV5yAKPraWkr74f8TON5g/OsEoR1cqis\nBu70W0aI+kH+1dUBhUXFbIxJYf66GDYeSaFDsC+dQpxwOybnLDRqBod/h4XXlVxXXGQkB4CNbzn2\nvINnw4Bpjj2mEKJCkiBqqfTcAo4mZXEkMZPP/zrO7tg0/Bp68syVEUwd0h4vjwYVHgOAzR9Ap8ug\neVnzPis4tg7OHoeV9xlFvW8qucm6143kYcuWD+yLw9qVb8P39xvLviEw4eXKH0MIUW2SINyY1pqk\njDxikrI4mpxJTGIW8Wk57I5NOz8jG0CwX0Oev7oHN0a2xcergi6sRYXGMwS9bjSeL/j5UfBrDQ/t\nt6xvYHWMk3/Bb0+WPMbuJSXfr3mhGp/ShgHTLAnivijHHlsIYTdJEG4kr7CIv4+msuFwEtFx6ew4\ndZbcAstw2j5eDWgT0IjurfyZOqQ9HYJ96RjsS1hzXzxt1Ri2fgTNwowagtlf/4Pfn4HvZsHsTUZZ\nTqopgAx4KRTGPA8n/zbKDvzg2A/pGwxDZkPTdtAkxIhx/0pj3T2bL5zJzcf/wmMIIWqEJAgXysor\nZOORZH6OTuDQmQxikjLJLSjG27MBnYKbMGVQO8Ka+9Ih2JcOwU1o5e9TuS6rPz5kvJoH0/vtadj0\ntmX98Q3Ga2Gu0QPJw/R8wap/V+6DzNkFb/WxvB96L7TsBUFdjJFTzx6HBWPghk+NEVOtdbjYSBJr\n/gMh3Uqua9mrcnEIIRxK6eqMueNikZGRetu2bY4/8O/PQvwuuPU7hx9aa83W42d5a/UhthxLpaBI\n07SRF33aBtA5pAnDOzVnaIcgGnk74GnnZ00jkl78GFz0qDHHQVUEtIdzJ0qW9ZgEe03X59k0Y6a3\nwjxY9TSMfdFozLaWnWp7StCy5GcbPZc8vSveVghRKUqpKK11haNVSoKwxfzFWt35CzB6GP269wzx\naTnsO53O5mOpxJ3LIaiJN9f1D+WiLsFEhjVz/PAXWsNzAY451qz18MFIy/uuE2HKIuOhN10EHk7s\nTiuEcDh7E4TcYnKwvMIiYhKzOJyYwb7T6Xyy6Tj5hUY7QnNfb/q1a8adI8O5pl8bAho78ddx2qmq\n7XfTlyWH1n7mnNGFFaDHtUYbwRhTo3SDBoCdvaWEELWOJIgq0FpzICGDPXFpnEnLJSkzj7izOcQk\nZXIyNZtiU6WsgYJhHYO4ITKUS7qG4NfQ0/FjIpXlwE+V32fmamOOhKcSIepTaD/ceBLawxMePQYN\n/Y1lIUS9IP/ay5GdX8j++AzSTx+m0bHf+KPZdew7nc6euDTOZVuGmmjayIuW/j5EtPbnqj6t6RDc\nhM4tmhAa0Jimjd349su9UcaUnS0iSpZ7NoTBs0qWVab9QAhRJ0iCsFKQlkDcwW2Emd73fW4V+UXF\nrPOeQ7sGSfyjoBtBQSFM6NmSvm0DGBTenFZNfSp+9sCZMhPh9c5w81LoMtYoeyXc0nW1LI2DIKiT\n8+MTQtRa9T5BxKflMG9tDDtOneOtpDsIVwnn190+PIyBYYG0WZ4P+bDtyUtRjvwl/U4khHSHm76o\n+jHidxmvWz4wEkRRYcnk8HQyfHoFnPq75H7Tf6z6OYUQ9UK9TRBn0nP5eMMxlkXFkpKVz9AOzUsk\nB4AnJnY3FlYa7QbK3Fhr9vVt0HYwDP1H1YJIOWz8VVX6aYhZY3qjIOaPksnh0qeMHka3LIWMBFg0\nGVJjjHWlnzkQQohS6mWCyC0oYtYXUew8dY7I9s34cFok/ds1M2bBLi0uCnLPGculh7jet8L4q2qC\nqIy8TKNtwLpL6YKxlt5KcVHwxTUl97nINBObj7/xd/92owtvUFfnxyuEqPXqZYJYufM0u2LP8faU\nflzVp3X5G394qWW5KN9xQaQeszpuodE76OAvsMg0EN6tyyGgndFz6KeHjEQEENwdBt0JOxeW7Mpa\nus3h3jKeD7lzDTQLd9znEELUWfUyQdwQGUqXln70bWv1INkrdnxpFhU6JoB1r5cc4M7WE86lawNm\nSfvhx3+WfezO4+CSxyGos+31bQbYH6cQol6rlwlCKWVJDplJcPaY7V4/pZ8yL68GUZhn/NkaXC5m\njTEe0Q8Pwqin4I8Xqxx7uWZvghY9nHNsIUS9Uy8TBGCM9bPyXti30vb0mQC6uOR76+2saxPPNoXQ\ngcZMaubhOcy3jQC+sBqgzpHJYdAso/2jIMe4HeXd2HHHFkLUe/U3Qax62hjBtDzmGdLMCnKNtoPt\nn8OGuSXXmafZjFljSQh3rYX5lzggWODmr40eU/mZ8NVkGDgDImc45thCCGFD/R2szzwgn6vNXGPU\nNHYsNIa91kUQ2AFSjxrrr/8Elt0Os/+68IlnIYSoAhmsz13NXA3R38Lf78IDe4xbQwCt+sDEVyFu\nOzRtC6+bnnLueS10HgsNnTDHtBBClKN+JghH1pqG3Qeb3ilZdvPXcPBn2PkVFOUZZc+cMwa+A2jd\n3+hpZKtBu01/43Xi60aiAEkOQgiXqJ8J4ti66u0/ax2c3gn9phrzNw+bA/kZ8HY/uG4BdBln/F35\nJsRug9M7LMkBjGGyK5pKc9Cd1YtRCCGqqX4miMaB0OtGY0rM0r2KJi+C5h1BeRjDYCyaDKP/DR1G\nwZb50GW8cTuoldUUm02CgWB4KunCGdBCI40/IYSoZepvIzVAYT5kJkCTlkavpg6joOv4ktvknIWG\nTU2T4wghRO0njdT28PS2NBJPeMX2NqXnVhZCiHpCfhYLIYSwSRKEEEIImyRBCCGEsEkShBBCCJsk\nQQghhLBJEoQQQgibJEEIIYSwSRKEEEIIm2r1k9RKqSTgRBV3DwKSHRhOTaqtsdfWuEFid4XaGje4\nf+zttdbBFW1UqxNEdSilttnzqLk7qq2x19a4QWJ3hdoaN9Tu2K3JLSYhhBA2SYIQQghhU31OEPNd\nHUA11NbYa2vcILG7Qm2NG2p37OfV2zYIIYQQ5avPNQghhBDlqJcJQik1Xil1UCl1RCn1uKvjsaaU\naquU+kMptV8ptVcpNcdUHqiUWqWUOmx6bWYqV0qpt02fZbdSqr9rPwEopTyUUjuUUj+Y3ocrpTab\nYl+ilPI2lTc0vT9iWh/mwpgDlFLLlFIHTNd+aG255kqpB03/r0QrpRYppXzc9ZorpT5WSiUqpaKt\nyip9nZVS00zbH1ZKTXNR3K+Z/n/ZrZT6TikVYLXuCVPcB5VS46zK3fa7xyatdb36AzyAGKAD4A3s\nAiJcHZdVfK2A/qZlP+AQEAG8CjxuKn8ceMW0PBH4GVDAEGCzG3yGfwJfAT+Y3n8NTDYtzwNmm5bv\nAeaZlicDS1wY82fATNOyNxBQG6450AY4BjSyutbT3fWaAxcB/YFoq7JKXWcgEDhqem1mWm7mgrjH\nAp6m5Ves4o4wfa80BMJN3zce7v7dY/NzuzqAGv/AMBT41er9E8ATro6rnHhXAGOAg0ArU1kr4KBp\n+QNgitX257dzUbyhwGrgUuAH0z/uZKt/SOevP/ArMNS07GnaTrkgZn/Tl6wqVe7219yUIE6Zviw9\nTdd8nDtfcyCs1Bdtpa4zMAX4wKq8xHY1FXepdZOAhablEt8p5mte2757tNb18haT+R+UWaypzO2Y\nqv/9gM1AC611PIDpNcS0mbt9njeBR4Fi0/vmwDmtdaHpvXV852M3rU8zbV/TOgBJwCemW2MfKaV8\nqQXXXGsdB7wOnATiMa5hFO5/za1V9jq7zfW3MgOjtgO1K+5y1ccEoWyUuV1XLqVUE+Ab4AGtdXp5\nm9ooc8nnUUpdASRqraOsi21squ1YV5M8MW4fvK+17gdkYdzqKIu7xI3pfv3VGLcyWgO+wAQbm7rb\nNbdHWbG61WdQSj0JFAILzUU2NnO7uO1RHxNELNDW6n0ocNpFsdiklPLCSA4LtdbfmorPKKVamda3\nAhJN5e70eYYDVymljgOLMW4zvQkEKKU8TdtYx3c+dtP6pkBqTQZsFUes1nqz6f0yjIRRG675ZcAx\nrXWS1roA+BYYhvtfc2uVvc5uc/1NDeRXALdo030jakHc9qqPCWIr0NnUy8Mbo6FupYtjOk8ppYAF\nwH6t9VyrVSsBc2+NaRhtE+by20w9PoYAaebqek3TWj+htQ7VWodhXNc1WutbgD+A602blY7d/Jmu\nN21f47+otNYJwCmlVFdT0WhgH7XgmmPcWhqilGps+n/HHLtbX/NSKnudfwXGKqWamWpQY01lNUop\nNR54DLhKa51ttWolMNnUYywc6Axswc2/e2xydSOIK/4wekccwuhR8KSr4ykV2wiMauduYKfpbyLG\nfeLVwGHTa6BpewW8a/ose4BIV38GU1yXYOnF1AHjH8gRYCnQ0FTuY3p/xLS+gwvj7QtsM1335Ri9\nY2rFNQeeAw4A0cAXGL1n3PKaA4sw2koKMH5R31GV64xxz/+I6e92F8V9BKNNwfzvdJ7V9k+a4j4I\nTLAqd9vvHlt/8iS1EEIIm+rjLSYhhBB2kAQhhBDCJkkQQgghbJIEIYQQwiZJEEIIIWySBCGEEMIm\nSRBCCCFskgQhhBDCpv8HOJ8n1tZ6I44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19489c722e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the chart\n",
    "chart_regression(lstm_pred.flatten(), lstm_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_X_train = lstm_X_train.reshape(lstm_X_train.shape[0], 1, SEQUENCE_SIZE, 5)\n",
    "cnn_X_test = lstm_X_test.reshape(lstm_X_test.shape[0], 1, SEQUENCE_SIZE, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=(1, SEQUENCE_SIZE, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 1, 7, 32)          1472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 1, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 500)               128500    \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 517,993\n",
      "Trainable params: 517,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),activation='relu',input_shape=input_shape, padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),activation='relu',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(128,kernel_size=(3, 3), strides=(1, 1),activation='relu',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(256,kernel_size=(3, 3), strides=(1, 1),activation='relu',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(500, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 118.0314 - val_loss: 210.1251\n",
      "Epoch 2/100\n",
      " - 3s - loss: 4.1687 - val_loss: 9.1381\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.7747 - val_loss: 5.9600\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.3981 - val_loss: 5.5483\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3846 - val_loss: 5.4891\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.3640 - val_loss: 4.9345\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.3548 - val_loss: 6.0107\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.3508 - val_loss: 4.7815\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.3367 - val_loss: 5.2647\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.3267 - val_loss: 5.4316\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 9.3225 - val_loss: 41.5078\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.3360 - val_loss: 5.1849\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.4144 - val_loss: 5.0953\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.3162 - val_loss: 4.5214\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3157 - val_loss: 4.3854\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.3056 - val_loss: 4.3156\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2997 - val_loss: 4.3150\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2957 - val_loss: 5.0322\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.2929 - val_loss: 4.1825\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2834 - val_loss: 4.8434\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.3183 - val_loss: 6.7767\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 4.5519 - val_loss: 12.3769\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.6999 - val_loss: 6.2093\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3024 - val_loss: 4.0423\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2711 - val_loss: 3.8641\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2689 - val_loss: 3.7858\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2778 - val_loss: 3.7774\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2685 - val_loss: 4.0950\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2449 - val_loss: 3.6811\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.2471 - val_loss: 4.0288\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2462 - val_loss: 3.5558\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.2465 - val_loss: 4.3853\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.2615 - val_loss: 3.2355\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.3566 - val_loss: 6.5487\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.2608 - val_loss: 3.6415\n",
      "Epoch 00014: early stopping\n",
      "3\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 7.0583 - val_loss: 54.4711\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.8778 - val_loss: 7.8900\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3422 - val_loss: 3.3431\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.3200 - val_loss: 4.5399\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2214 - val_loss: 3.7802\n",
      "Epoch 00005: early stopping\n",
      "4\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 5.5641 - val_loss: 23.6275\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.5429 - val_loss: 3.7215\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2493 - val_loss: 3.7048\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2448 - val_loss: 5.3690\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2294 - val_loss: 3.3808\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2202 - val_loss: 3.6437\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2235 - val_loss: 4.7755\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"cnn/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)   \n",
    "    cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, verbose=1, mode='auto')\n",
    "    cnn_model.fit(cnn_X_train, lstm_y_train, batch_size=128, validation_data=(cnn_X_test, lstm_y_test), \n",
    "                  callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7987426916926026\n",
      "R2 score 0.9958007391150178\n",
      "MSE::  3.2354752709175494\n"
     ]
    }
   ],
   "source": [
    "cnn_model.load_weights('cnn/weights.hdf5')\n",
    "\n",
    "cnn_pred = cnn_model.predict(cnn_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, cnn_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, cnn_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1949915e6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the chart\n",
    "chart_regression(cnn_pred.flatten(), lstm_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tunning for Fully-connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 34s - loss: 284.2375 - val_loss: 4804.5072\n",
      "Epoch 2/100\n",
      " - 1s - loss: 226.6877 - val_loss: 4612.1116\n",
      "Epoch 3/100\n",
      " - 1s - loss: 197.7845 - val_loss: 4429.9155\n",
      "Epoch 4/100\n",
      " - 1s - loss: 175.5704 - val_loss: 4279.0201\n",
      "Epoch 5/100\n",
      " - 1s - loss: 159.4964 - val_loss: 4149.0163\n",
      "Epoch 6/100\n",
      " - 1s - loss: 147.5454 - val_loss: 4035.7496\n",
      "Epoch 7/100\n",
      " - 1s - loss: 138.7893 - val_loss: 3937.3419\n",
      "Epoch 8/100\n",
      " - 1s - loss: 132.6996 - val_loss: 3854.5916\n",
      "Epoch 9/100\n",
      " - 1s - loss: 128.4355 - val_loss: 3785.6940\n",
      "Epoch 10/100\n",
      " - 1s - loss: 125.6167 - val_loss: 3727.4955\n",
      "Epoch 11/100\n",
      " - 1s - loss: 123.6957 - val_loss: 3678.7514\n",
      "Epoch 12/100\n",
      " - 1s - loss: 122.5414 - val_loss: 3640.9059\n",
      "Epoch 13/100\n",
      " - 1s - loss: 121.8390 - val_loss: 3613.0949\n",
      "Epoch 14/100\n",
      " - 1s - loss: 121.3940 - val_loss: 3589.0651\n",
      "Epoch 15/100\n",
      " - 1s - loss: 121.0879 - val_loss: 3568.0915\n",
      "Epoch 16/100\n",
      " - 1s - loss: 120.9431 - val_loss: 3556.6978\n",
      "Epoch 17/100\n",
      " - 1s - loss: 109.0972 - val_loss: 3499.0477\n",
      "Epoch 18/100\n",
      " - 1s - loss: 84.2500 - val_loss: 3357.1380\n",
      "Epoch 19/100\n",
      " - 1s - loss: 73.2617 - val_loss: 3225.4397\n",
      "Epoch 20/100\n",
      " - 1s - loss: 64.4225 - val_loss: 3105.0191\n",
      "Epoch 21/100\n",
      " - 1s - loss: 56.9241 - val_loss: 2996.9428\n",
      "Epoch 22/100\n",
      " - 1s - loss: 49.3099 - val_loss: 2863.9565\n",
      "Epoch 23/100\n",
      " - 1s - loss: 42.0239 - val_loss: 2752.8923\n",
      "Epoch 24/100\n",
      " - 1s - loss: 36.3931 - val_loss: 2655.8351\n",
      "Epoch 25/100\n",
      " - 1s - loss: 31.6866 - val_loss: 2569.1508\n",
      "Epoch 26/100\n",
      " - 1s - loss: 27.5878 - val_loss: 2485.4512\n",
      "Epoch 27/100\n",
      " - 1s - loss: 24.0947 - val_loss: 2412.1328\n",
      "Epoch 28/100\n",
      " - 1s - loss: 21.1224 - val_loss: 2344.8855\n",
      "Epoch 29/100\n",
      " - 1s - loss: 18.5237 - val_loss: 2281.0652\n",
      "Epoch 30/100\n",
      " - 1s - loss: 16.2571 - val_loss: 2221.7769\n",
      "Epoch 31/100\n",
      " - 1s - loss: 14.2615 - val_loss: 2167.4441\n",
      "Epoch 32/100\n",
      " - 1s - loss: 12.4879 - val_loss: 2114.9621\n",
      "Epoch 33/100\n",
      " - 1s - loss: 10.9225 - val_loss: 2064.7666\n",
      "Epoch 34/100\n",
      " - 1s - loss: 9.6363 - val_loss: 2020.3093\n",
      "Epoch 35/100\n",
      " - 1s - loss: 8.3870 - val_loss: 1977.6824\n",
      "Epoch 36/100\n",
      " - 1s - loss: 7.3968 - val_loss: 1937.8779\n",
      "Epoch 37/100\n",
      " - 1s - loss: 6.5495 - val_loss: 1901.5336\n",
      "Epoch 38/100\n",
      " - 1s - loss: 5.7825 - val_loss: 1867.5116\n",
      "Epoch 39/100\n",
      " - 1s - loss: 5.0971 - val_loss: 1833.1441\n",
      "Epoch 40/100\n",
      " - 1s - loss: 4.5323 - val_loss: 1803.2056\n",
      "Epoch 41/100\n",
      " - 1s - loss: 4.0526 - val_loss: 1774.7642\n",
      "Epoch 42/100\n",
      " - 1s - loss: 3.6114 - val_loss: 1747.8456\n",
      "Epoch 43/100\n",
      " - 1s - loss: 3.2323 - val_loss: 1722.2173\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.8981 - val_loss: 1698.0341\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.5780 - val_loss: 1675.1002\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.3049 - val_loss: 1650.4215\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.1029 - val_loss: 1629.5597\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.8365 - val_loss: 1610.2428\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.6601 - val_loss: 1590.1691\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.4834 - val_loss: 1571.7850\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.3501 - val_loss: 1555.0276\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.1828 - val_loss: 1537.5238\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.0705 - val_loss: 1521.5666\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.9606 - val_loss: 1503.1796\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8651 - val_loss: 1489.5679\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.7820 - val_loss: 1476.4532\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.7351 - val_loss: 1463.9184\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.6663 - val_loss: 1452.6297\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.6190 - val_loss: 1441.0374\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.5520 - val_loss: 1431.4500\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.5326 - val_loss: 1421.1609\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.5090 - val_loss: 1412.0620\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4754 - val_loss: 1404.3270\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4266 - val_loss: 1396.1684\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4103 - val_loss: 1388.6004\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4049 - val_loss: 1382.3086\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3770 - val_loss: 1374.5585\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3902 - val_loss: 1369.1912\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3491 - val_loss: 1363.9064\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3487 - val_loss: 1359.3711\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3332 - val_loss: 1354.3570\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3425 - val_loss: 1349.7361\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3233 - val_loss: 1344.9755\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3056 - val_loss: 1340.5426\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3157 - val_loss: 1337.0064\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2990 - val_loss: 1333.3053\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3032 - val_loss: 1329.7173\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2915 - val_loss: 1325.9630\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2751 - val_loss: 1322.7670\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2750 - val_loss: 1319.3893\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2723 - val_loss: 1316.0285\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2627 - val_loss: 1313.3017\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2727 - val_loss: 1310.8086\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2719 - val_loss: 1306.7279\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2656 - val_loss: 1303.3983\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2483 - val_loss: 1301.3856\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2738 - val_loss: 1298.9710\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2478 - val_loss: 1296.4260\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2401 - val_loss: 1293.9834\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2347 - val_loss: 1292.8016\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2379 - val_loss: 1290.2363\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2376 - val_loss: 1287.9283\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2385 - val_loss: 1286.3584\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2520 - val_loss: 1284.8643\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2296 - val_loss: 1283.6708\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2239 - val_loss: 1281.6262\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2212 - val_loss: 1280.6268\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2167 - val_loss: 1278.9668\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2162 - val_loss: 1276.9892\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2162 - val_loss: 1275.8209\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 295.0211 - val_loss: 4859.8864\n",
      "Epoch 2/100\n",
      " - 1s - loss: 237.4411 - val_loss: 4677.6896\n",
      "Epoch 3/100\n",
      " - 1s - loss: 208.5989 - val_loss: 4510.7885\n",
      "Epoch 4/100\n",
      " - 1s - loss: 185.8913 - val_loss: 4362.0924\n",
      "Epoch 5/100\n",
      " - 1s - loss: 168.7245 - val_loss: 4231.3822\n",
      "Epoch 6/100\n",
      " - 1s - loss: 153.5451 - val_loss: 4071.5052\n",
      "Epoch 7/100\n",
      " - 1s - loss: 140.5469 - val_loss: 3947.4897\n",
      "Epoch 8/100\n",
      " - 1s - loss: 132.8261 - val_loss: 3849.9746\n",
      "Epoch 9/100\n",
      " - 1s - loss: 127.7925 - val_loss: 3768.8024\n",
      "Epoch 10/100\n",
      " - 1s - loss: 124.9189 - val_loss: 3710.9211\n",
      "Epoch 11/100\n",
      " - 1s - loss: 123.2025 - val_loss: 3662.4184\n",
      "Epoch 12/100\n",
      " - 1s - loss: 122.0852 - val_loss: 3622.6858\n",
      "Epoch 13/100\n",
      " - 1s - loss: 121.4986 - val_loss: 3594.2630\n",
      "Epoch 14/100\n",
      " - 1s - loss: 121.1752 - val_loss: 3576.3688\n",
      "Epoch 15/100\n",
      " - 1s - loss: 118.2634 - val_loss: 3552.4975\n",
      "Epoch 16/100\n",
      " - 1s - loss: 105.0620 - val_loss: 3476.8315\n",
      "Epoch 17/100\n",
      " - 1s - loss: 82.1205 - val_loss: 3331.1617\n",
      "Epoch 18/100\n",
      " - 1s - loss: 71.4715 - val_loss: 3202.2578\n",
      "Epoch 19/100\n",
      " - 1s - loss: 62.6367 - val_loss: 3078.4689\n",
      "Epoch 20/100\n",
      " - 1s - loss: 54.8155 - val_loss: 2964.2932\n",
      "Epoch 21/100\n",
      " - 1s - loss: 48.1899 - val_loss: 2864.1146\n",
      "Epoch 22/100\n",
      " - 1s - loss: 42.5035 - val_loss: 2768.3991\n",
      "Epoch 23/100\n",
      " - 1s - loss: 37.4810 - val_loss: 2681.6135\n",
      "Epoch 24/100\n",
      " - 1s - loss: 33.1621 - val_loss: 2600.7089\n",
      "Epoch 25/100\n",
      " - 1s - loss: 29.2236 - val_loss: 2524.9601\n",
      "Epoch 26/100\n",
      " - 1s - loss: 25.7813 - val_loss: 2452.3708\n",
      "Epoch 27/100\n",
      " - 1s - loss: 22.7681 - val_loss: 2386.4196\n",
      "Epoch 28/100\n",
      " - 1s - loss: 20.1015 - val_loss: 2323.6499\n",
      "Epoch 29/100\n",
      " - 1s - loss: 17.7321 - val_loss: 2264.7911\n",
      "Epoch 30/100\n",
      " - 1s - loss: 15.5984 - val_loss: 2207.1297\n",
      "Epoch 31/100\n",
      " - 1s - loss: 13.7337 - val_loss: 2155.0134\n",
      "Epoch 32/100\n",
      " - 1s - loss: 12.0952 - val_loss: 2106.4662\n",
      "Epoch 33/100\n",
      " - 1s - loss: 10.6500 - val_loss: 2059.7779\n",
      "Epoch 34/100\n",
      " - 1s - loss: 9.3909 - val_loss: 2017.1462\n",
      "Epoch 35/100\n",
      " - 1s - loss: 8.2391 - val_loss: 1974.4333\n",
      "Epoch 36/100\n",
      " - 1s - loss: 7.3024 - val_loss: 1936.5435\n",
      "Epoch 37/100\n",
      " - 1s - loss: 6.4355 - val_loss: 1900.9986\n",
      "Epoch 38/100\n",
      " - 1s - loss: 5.7521 - val_loss: 1867.8373\n",
      "Epoch 39/100\n",
      " - 1s - loss: 5.0876 - val_loss: 1836.2657\n",
      "Epoch 40/100\n",
      " - 1s - loss: 4.5388 - val_loss: 1806.8772\n",
      "Epoch 41/100\n",
      " - 1s - loss: 4.0432 - val_loss: 1778.6046\n",
      "Epoch 42/100\n",
      " - 1s - loss: 3.6450 - val_loss: 1752.3482\n",
      "Epoch 43/100\n",
      " - 1s - loss: 3.2352 - val_loss: 1726.6423\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 2.8922 - val_loss: 1701.9992\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.6177 - val_loss: 1678.9038\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.3405 - val_loss: 1657.0294\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.1074 - val_loss: 1634.9400\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.8701 - val_loss: 1614.4396\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.6625 - val_loss: 1595.6697\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.5257 - val_loss: 1577.5520\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.3442 - val_loss: 1559.5487\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.2169 - val_loss: 1542.7186\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.0958 - val_loss: 1524.6734\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.9828 - val_loss: 1510.1014\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8647 - val_loss: 1495.8484\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.7864 - val_loss: 1482.5048\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.7640 - val_loss: 1468.9137\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.6523 - val_loss: 1457.2716\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.6276 - val_loss: 1446.0781\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.5974 - val_loss: 1435.5345\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.5539 - val_loss: 1425.5321\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4953 - val_loss: 1416.0324\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4548 - val_loss: 1407.1410\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4305 - val_loss: 1398.9288\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4255 - val_loss: 1391.6127\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4055 - val_loss: 1384.4685\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3745 - val_loss: 1378.1582\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3744 - val_loss: 1372.1215\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3517 - val_loss: 1366.2884\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3486 - val_loss: 1361.0119\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3236 - val_loss: 1355.9225\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3256 - val_loss: 1350.7340\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3300 - val_loss: 1346.5009\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3036 - val_loss: 1342.5054\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3025 - val_loss: 1338.4247\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3221 - val_loss: 1335.2455\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2956 - val_loss: 1331.4051\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2773 - val_loss: 1327.3278\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2750 - val_loss: 1324.1354\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2738 - val_loss: 1321.0471\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2728 - val_loss: 1317.4335\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2676 - val_loss: 1313.6384\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2623 - val_loss: 1310.5852\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2722 - val_loss: 1308.2463\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2568 - val_loss: 1305.4608\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2563 - val_loss: 1302.9549\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2558 - val_loss: 1300.1217\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2326 - val_loss: 1297.3923\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2291 - val_loss: 1294.3380\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2340 - val_loss: 1292.4078\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2376 - val_loss: 1290.0939\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2456 - val_loss: 1288.2004\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2313 - val_loss: 1286.0564\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2298 - val_loss: 1285.5184\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2287 - val_loss: 1283.4251\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2173 - val_loss: 1282.2084\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2301 - val_loss: 1281.0079\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2244 - val_loss: 1279.4921\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2232 - val_loss: 1279.7496\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2126 - val_loss: 1277.2087\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 261.2842 - val_loss: 4630.3052\n",
      "Epoch 2/100\n",
      " - 1s - loss: 198.8146 - val_loss: 4421.6987\n",
      "Epoch 3/100\n",
      " - 1s - loss: 173.8697 - val_loss: 4254.2339\n",
      "Epoch 4/100\n",
      " - 1s - loss: 156.2055 - val_loss: 4110.5698\n",
      "Epoch 5/100\n",
      " - 1s - loss: 143.5803 - val_loss: 3983.9343\n",
      "Epoch 6/100\n",
      " - 1s - loss: 134.8569 - val_loss: 3878.6998\n",
      "Epoch 7/100\n",
      " - 1s - loss: 129.3195 - val_loss: 3796.1221\n",
      "Epoch 8/100\n",
      " - 1s - loss: 125.8074 - val_loss: 3729.4396\n",
      "Epoch 9/100\n",
      " - 1s - loss: 123.6613 - val_loss: 3670.9914\n",
      "Epoch 10/100\n",
      " - 1s - loss: 122.3525 - val_loss: 3634.4049\n",
      "Epoch 11/100\n",
      " - 1s - loss: 121.6029 - val_loss: 3600.6757\n",
      "Epoch 12/100\n",
      " - 1s - loss: 121.0817 - val_loss: 3576.4337\n",
      "Epoch 13/100\n",
      " - 1s - loss: 107.5904 - val_loss: 3491.3987\n",
      "Epoch 14/100\n",
      " - 1s - loss: 83.1959 - val_loss: 3338.4996\n",
      "Epoch 15/100\n",
      " - 1s - loss: 72.1210 - val_loss: 3200.8894\n",
      "Epoch 16/100\n",
      " - 1s - loss: 63.0589 - val_loss: 3077.8700\n",
      "Epoch 17/100\n",
      " - 1s - loss: 55.0432 - val_loss: 2960.3619\n",
      "Epoch 18/100\n",
      " - 1s - loss: 48.1724 - val_loss: 2855.4753\n",
      "Epoch 19/100\n",
      " - 1s - loss: 42.2943 - val_loss: 2756.7274\n",
      "Epoch 20/100\n",
      " - 1s - loss: 37.0826 - val_loss: 2667.6926\n",
      "Epoch 21/100\n",
      " - 1s - loss: 32.5491 - val_loss: 2582.1088\n",
      "Epoch 22/100\n",
      " - 1s - loss: 28.5698 - val_loss: 2502.6031\n",
      "Epoch 23/100\n",
      " - 1s - loss: 25.1579 - val_loss: 2430.0598\n",
      "Epoch 24/100\n",
      " - 1s - loss: 22.1239 - val_loss: 2361.8534\n",
      "Epoch 25/100\n",
      " - 1s - loss: 19.3912 - val_loss: 2298.1778\n",
      "Epoch 26/100\n",
      " - 1s - loss: 17.0230 - val_loss: 2237.5303\n",
      "Epoch 27/100\n",
      " - 1s - loss: 14.8708 - val_loss: 2181.9383\n",
      "Epoch 28/100\n",
      " - 1s - loss: 13.0794 - val_loss: 2128.5327\n",
      "Epoch 29/100\n",
      " - 1s - loss: 11.3674 - val_loss: 2077.1397\n",
      "Epoch 30/100\n",
      " - 1s - loss: 9.9499 - val_loss: 2031.0690\n",
      "Epoch 31/100\n",
      " - 1s - loss: 8.7225 - val_loss: 1986.9378\n",
      "Epoch 32/100\n",
      " - 1s - loss: 7.6564 - val_loss: 1946.0420\n",
      "Epoch 33/100\n",
      " - 1s - loss: 6.6969 - val_loss: 1906.5289\n",
      "Epoch 34/100\n",
      " - 1s - loss: 5.8992 - val_loss: 1871.2033\n",
      "Epoch 35/100\n",
      " - 1s - loss: 5.2355 - val_loss: 1838.1579\n",
      "Epoch 36/100\n",
      " - 1s - loss: 4.6309 - val_loss: 1806.8509\n",
      "Epoch 37/100\n",
      " - 1s - loss: 4.1382 - val_loss: 1777.5868\n",
      "Epoch 38/100\n",
      " - 1s - loss: 3.6711 - val_loss: 1750.2713\n",
      "Epoch 39/100\n",
      " - 1s - loss: 3.2766 - val_loss: 1723.9248\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.9212 - val_loss: 1698.8541\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.5840 - val_loss: 1673.2434\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.2980 - val_loss: 1650.7892\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.0365 - val_loss: 1628.9523\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.8233 - val_loss: 1608.7324\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.6372 - val_loss: 1588.2746\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.4710 - val_loss: 1569.6310\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.3292 - val_loss: 1551.8789\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.1806 - val_loss: 1533.4801\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.0138 - val_loss: 1516.7874\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.9770 - val_loss: 1501.8129\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.8387 - val_loss: 1487.1384\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.7746 - val_loss: 1473.5649\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.7048 - val_loss: 1461.0954\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.6327 - val_loss: 1448.7598\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.6043 - val_loss: 1437.7074\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5264 - val_loss: 1426.9119\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4972 - val_loss: 1417.0079\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4909 - val_loss: 1408.1455\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4548 - val_loss: 1399.2863\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4424 - val_loss: 1391.3412\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4139 - val_loss: 1384.0064\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3731 - val_loss: 1377.2749\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3812 - val_loss: 1371.3391\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3515 - val_loss: 1364.8578\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3541 - val_loss: 1358.3775\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3317 - val_loss: 1351.2658\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3438 - val_loss: 1346.8342\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3378 - val_loss: 1342.8191\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3278 - val_loss: 1338.6242\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2971 - val_loss: 1335.0810\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2922 - val_loss: 1330.8420\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3071 - val_loss: 1327.3913\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2858 - val_loss: 1324.0182\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2908 - val_loss: 1320.5902\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2889 - val_loss: 1318.4700\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2944 - val_loss: 1315.4559\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2757 - val_loss: 1312.7823\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2441 - val_loss: 1309.4805\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2848 - val_loss: 1305.7294\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2597 - val_loss: 1303.5660\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2708 - val_loss: 1301.0500\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2529 - val_loss: 1298.5365\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2442 - val_loss: 1296.3100\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2561 - val_loss: 1294.5284\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2405 - val_loss: 1292.3717\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2421 - val_loss: 1290.4648\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2432 - val_loss: 1288.9445\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2429 - val_loss: 1288.1364\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2339 - val_loss: 1286.1946\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2650 - val_loss: 1286.1274\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2526 - val_loss: 1284.4445\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2302 - val_loss: 1281.9936\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2336 - val_loss: 1280.9292\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2360 - val_loss: 1279.3108\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2434 - val_loss: 1278.1338\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2396 - val_loss: 1278.0292\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2245 - val_loss: 1275.2705\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2154 - val_loss: 1273.5251\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2229 - val_loss: 1273.0460\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2298 - val_loss: 1273.4800\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 257.7175 - val_loss: 4650.9860\n",
      "Epoch 2/100\n",
      " - 1s - loss: 201.9829 - val_loss: 4442.0520\n",
      "Epoch 3/100\n",
      " - 1s - loss: 175.8677 - val_loss: 4271.9887\n",
      "Epoch 4/100\n",
      " - 1s - loss: 158.1242 - val_loss: 4129.8428\n",
      "Epoch 5/100\n",
      " - 1s - loss: 145.5276 - val_loss: 4007.9903\n",
      "Epoch 6/100\n",
      " - 1s - loss: 136.7451 - val_loss: 3905.3889\n",
      "Epoch 7/100\n",
      " - 1s - loss: 130.5224 - val_loss: 3817.0431\n",
      "Epoch 8/100\n",
      " - 1s - loss: 126.6319 - val_loss: 3745.5359\n",
      "Epoch 9/100\n",
      " - 1s - loss: 124.2010 - val_loss: 3691.6514\n",
      "Epoch 10/100\n",
      " - 1s - loss: 122.7258 - val_loss: 3647.5588\n",
      "Epoch 11/100\n",
      " - 1s - loss: 121.1350 - val_loss: 3613.2556\n",
      "Epoch 12/100\n",
      " - 1s - loss: 98.8648 - val_loss: 3487.8573\n",
      "Epoch 13/100\n",
      " - 1s - loss: 86.5855 - val_loss: 3363.7472\n",
      "Epoch 14/100\n",
      " - 1s - loss: 75.8710 - val_loss: 3242.9142\n",
      "Epoch 15/100\n",
      " - 1s - loss: 66.8372 - val_loss: 3131.6860\n",
      "Epoch 16/100\n",
      " - 1s - loss: 58.7859 - val_loss: 3021.4933\n",
      "Epoch 17/100\n",
      " - 1s - loss: 51.9703 - val_loss: 2920.3526\n",
      "Epoch 18/100\n",
      " - 1s - loss: 46.0611 - val_loss: 2825.9774\n",
      "Epoch 19/100\n",
      " - 1s - loss: 40.7205 - val_loss: 2736.8575\n",
      "Epoch 20/100\n",
      " - 1s - loss: 36.1560 - val_loss: 2654.7479\n",
      "Epoch 21/100\n",
      " - 1s - loss: 31.9318 - val_loss: 2574.1058\n",
      "Epoch 22/100\n",
      " - 1s - loss: 28.2148 - val_loss: 2501.7007\n",
      "Epoch 23/100\n",
      " - 1s - loss: 24.9425 - val_loss: 2432.4203\n",
      "Epoch 24/100\n",
      " - 1s - loss: 22.0691 - val_loss: 2366.6446\n",
      "Epoch 25/100\n",
      " - 1s - loss: 19.5608 - val_loss: 2305.9909\n",
      "Epoch 26/100\n",
      " - 1s - loss: 17.3380 - val_loss: 2250.5428\n",
      "Epoch 27/100\n",
      " - 1s - loss: 15.3298 - val_loss: 2196.4040\n",
      "Epoch 28/100\n",
      " - 1s - loss: 13.5347 - val_loss: 2146.5127\n",
      "Epoch 29/100\n",
      " - 1s - loss: 11.9207 - val_loss: 2095.1320\n",
      "Epoch 30/100\n",
      " - 1s - loss: 10.5198 - val_loss: 2051.0408\n",
      "Epoch 31/100\n",
      " - 1s - loss: 9.2330 - val_loss: 2006.3407\n",
      "Epoch 32/100\n",
      " - 1s - loss: 8.1244 - val_loss: 1967.0076\n",
      "Epoch 33/100\n",
      " - 1s - loss: 7.2225 - val_loss: 1929.4591\n",
      "Epoch 34/100\n",
      " - 1s - loss: 6.3380 - val_loss: 1892.9051\n",
      "Epoch 35/100\n",
      " - 1s - loss: 5.6542 - val_loss: 1860.2051\n",
      "Epoch 36/100\n",
      " - 1s - loss: 5.0438 - val_loss: 1830.1554\n",
      "Epoch 37/100\n",
      " - 1s - loss: 4.5219 - val_loss: 1800.0460\n",
      "Epoch 38/100\n",
      " - 1s - loss: 4.0007 - val_loss: 1772.1304\n",
      "Epoch 39/100\n",
      " - 1s - loss: 3.5831 - val_loss: 1745.8818\n",
      "Epoch 40/100\n",
      " - 1s - loss: 3.2481 - val_loss: 1720.5936\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.8456 - val_loss: 1694.7096\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.5360 - val_loss: 1671.9928\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.2839 - val_loss: 1649.4010\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.0578 - val_loss: 1628.9243\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.8332 - val_loss: 1608.7448\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.6421 - val_loss: 1589.5129\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.4634 - val_loss: 1571.2928\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.3308 - val_loss: 1553.9140\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.2043 - val_loss: 1537.4125\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.0824 - val_loss: 1521.3915\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.9703 - val_loss: 1506.7332\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.8833 - val_loss: 1492.2463\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.7709 - val_loss: 1477.7586\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.7094 - val_loss: 1465.1349\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.6555 - val_loss: 1453.1878\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5859 - val_loss: 1441.9242\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.5370 - val_loss: 1428.7376\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4913 - val_loss: 1419.0929\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4906 - val_loss: 1410.4264\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4393 - val_loss: 1402.2620\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4111 - val_loss: 1394.5552\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4234 - val_loss: 1386.9244\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4096 - val_loss: 1380.2936\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3871 - val_loss: 1373.9253\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3601 - val_loss: 1367.8276\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3419 - val_loss: 1362.8222\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3821 - val_loss: 1358.2978\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3512 - val_loss: 1353.1516\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3404 - val_loss: 1348.1867\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3063 - val_loss: 1344.1536\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3061 - val_loss: 1339.4176\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3099 - val_loss: 1336.0625\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3029 - val_loss: 1332.2412\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3118 - val_loss: 1328.5118\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3139 - val_loss: 1325.3211\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2823 - val_loss: 1321.6378\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3021 - val_loss: 1319.1305\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2640 - val_loss: 1316.2758\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2821 - val_loss: 1312.0177\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2777 - val_loss: 1309.4037\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2757 - val_loss: 1306.9911\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2685 - val_loss: 1305.1410\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2709 - val_loss: 1302.9482\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2523 - val_loss: 1300.3683\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2525 - val_loss: 1298.5677\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2572 - val_loss: 1296.5399\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2343 - val_loss: 1293.0607\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2387 - val_loss: 1290.1431\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2486 - val_loss: 1287.1115\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2450 - val_loss: 1285.7507\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2548 - val_loss: 1283.2844\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2306 - val_loss: 1281.5811\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2289 - val_loss: 1280.8456\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2273 - val_loss: 1279.5452\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2392 - val_loss: 1278.1795\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2391 - val_loss: 1277.7721\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2232 - val_loss: 1276.4067\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2293 - val_loss: 1274.5485\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2329 - val_loss: 1274.3064\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2115 - val_loss: 1272.3610\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 247.1215 - val_loss: 4555.3776\n",
      "Epoch 2/100\n",
      " - 1s - loss: 188.5274 - val_loss: 4346.0695\n",
      "Epoch 3/100\n",
      " - 1s - loss: 164.6882 - val_loss: 4172.4083\n",
      "Epoch 4/100\n",
      " - 1s - loss: 147.5935 - val_loss: 4013.6166\n",
      "Epoch 5/100\n",
      " - 1s - loss: 136.3134 - val_loss: 3890.0443\n",
      "Epoch 6/100\n",
      " - 1s - loss: 129.5585 - val_loss: 3790.8177\n",
      "Epoch 7/100\n",
      " - 1s - loss: 125.4184 - val_loss: 3714.8124\n",
      "Epoch 8/100\n",
      " - 1s - loss: 123.0896 - val_loss: 3653.2126\n",
      "Epoch 9/100\n",
      " - 1s - loss: 121.8518 - val_loss: 3612.7886\n",
      "Epoch 10/100\n",
      " - 1s - loss: 121.1818 - val_loss: 3582.8834\n",
      "Epoch 11/100\n",
      " - 1s - loss: 110.2932 - val_loss: 3508.3816\n",
      "Epoch 12/100\n",
      " - 1s - loss: 84.1119 - val_loss: 3341.5329\n",
      "Epoch 13/100\n",
      " - 1s - loss: 71.9306 - val_loss: 3197.5067\n",
      "Epoch 14/100\n",
      " - 1s - loss: 62.2886 - val_loss: 3062.2197\n",
      "Epoch 15/100\n",
      " - 1s - loss: 53.9782 - val_loss: 2940.1799\n",
      "Epoch 16/100\n",
      " - 1s - loss: 46.7688 - val_loss: 2828.7006\n",
      "Epoch 17/100\n",
      " - 1s - loss: 40.4422 - val_loss: 2724.4391\n",
      "Epoch 18/100\n",
      " - 1s - loss: 35.2034 - val_loss: 2629.3258\n",
      "Epoch 19/100\n",
      " - 1s - loss: 30.6490 - val_loss: 2541.0737\n",
      "Epoch 20/100\n",
      " - 1s - loss: 26.7356 - val_loss: 2460.7718\n",
      "Epoch 21/100\n",
      " - 1s - loss: 23.1804 - val_loss: 2385.1247\n",
      "Epoch 22/100\n",
      " - 1s - loss: 20.2074 - val_loss: 2316.9775\n",
      "Epoch 23/100\n",
      " - 1s - loss: 17.6270 - val_loss: 2252.4985\n",
      "Epoch 24/100\n",
      " - 1s - loss: 15.3673 - val_loss: 2190.9378\n",
      "Epoch 25/100\n",
      " - 1s - loss: 13.2397 - val_loss: 2133.0145\n",
      "Epoch 26/100\n",
      " - 1s - loss: 11.5275 - val_loss: 2080.5251\n",
      "Epoch 27/100\n",
      " - 1s - loss: 10.0711 - val_loss: 2031.3849\n",
      "Epoch 28/100\n",
      " - 1s - loss: 8.7372 - val_loss: 1986.5269\n",
      "Epoch 29/100\n",
      " - 1s - loss: 7.6438 - val_loss: 1942.9724\n",
      "Epoch 30/100\n",
      " - 1s - loss: 6.7016 - val_loss: 1903.8208\n",
      "Epoch 31/100\n",
      " - 1s - loss: 5.8739 - val_loss: 1866.9212\n",
      "Epoch 32/100\n",
      " - 1s - loss: 5.1709 - val_loss: 1832.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      " - 1s - loss: 4.5560 - val_loss: 1798.4038\n",
      "Epoch 34/100\n",
      " - 1s - loss: 4.0354 - val_loss: 1768.0315\n",
      "Epoch 35/100\n",
      " - 1s - loss: 3.5944 - val_loss: 1740.4853\n",
      "Epoch 36/100\n",
      " - 1s - loss: 3.1685 - val_loss: 1713.7804\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.8534 - val_loss: 1688.5745\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.5218 - val_loss: 1664.5159\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.2349 - val_loss: 1642.0417\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.0670 - val_loss: 1619.8926\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.8235 - val_loss: 1599.4517\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.6193 - val_loss: 1579.3809\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.4257 - val_loss: 1559.3076\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.2819 - val_loss: 1542.1516\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.1556 - val_loss: 1524.8713\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.0722 - val_loss: 1509.3834\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.9300 - val_loss: 1493.9609\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.8600 - val_loss: 1479.6666\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.7704 - val_loss: 1466.4798\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.7191 - val_loss: 1454.3374\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.6986 - val_loss: 1442.6081\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.6052 - val_loss: 1431.1810\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5958 - val_loss: 1421.2763\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5710 - val_loss: 1412.0777\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5362 - val_loss: 1403.2013\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4884 - val_loss: 1394.7782\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4744 - val_loss: 1387.5601\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4570 - val_loss: 1380.9260\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4344 - val_loss: 1373.9170\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3983 - val_loss: 1367.7542\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3939 - val_loss: 1361.9936\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3815 - val_loss: 1356.5508\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3786 - val_loss: 1351.7205\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3663 - val_loss: 1346.4629\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3751 - val_loss: 1342.3766\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3612 - val_loss: 1338.2363\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3365 - val_loss: 1334.0558\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3305 - val_loss: 1330.1670\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3231 - val_loss: 1327.2354\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3148 - val_loss: 1323.3400\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3131 - val_loss: 1320.6174\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3142 - val_loss: 1317.3138\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2964 - val_loss: 1314.6509\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2852 - val_loss: 1311.4320\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2956 - val_loss: 1309.1609\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2908 - val_loss: 1307.5522\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2902 - val_loss: 1304.3813\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2801 - val_loss: 1301.5792\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2856 - val_loss: 1299.3621\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2721 - val_loss: 1297.9269\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2596 - val_loss: 1294.9321\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2718 - val_loss: 1292.5288\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2675 - val_loss: 1290.5668\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2533 - val_loss: 1288.5223\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2563 - val_loss: 1287.3233\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2610 - val_loss: 1284.9967\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2445 - val_loss: 1283.8123\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2472 - val_loss: 1282.8761\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2641 - val_loss: 1282.9817\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2673 - val_loss: 1282.4058\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2444 - val_loss: 1279.6976\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2550 - val_loss: 1278.1862\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2373 - val_loss: 1277.7904\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2605 - val_loss: 1275.7933\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2345 - val_loss: 1274.3684\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2252 - val_loss: 1274.5756\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2275 - val_loss: 1273.1644\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2420 - val_loss: 1272.7787\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2391 - val_loss: 1272.3272\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2283 - val_loss: 1269.2040\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, sigmoid & adam\n",
    "checkpointer = ModelCheckpoint(filepath=\"tns/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    tns_model = Sequential()\n",
    "    # Build network\n",
    "    tns_model.add(Dense(130, input_dim = tns_X_train.shape[1], activation='relu')) # Hidden 1\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(30, activation='sigmoid')) # Hidden 3\n",
    "    tns_model.add(Dense(1)) # Output\n",
    "\n",
    "    tns_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    tns_model.fit(tns_X_train, tns_y_train, validation_data = (tns_X_test, tns_y_test), callbacks=[monitor, checkpointer], \n",
    "                  verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid, sigmoid & adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35.62588914563727\n",
      "R2 score -0.6512798307955006\n",
      "MSE::  1269.2039774172354\n"
     ]
    }
   ],
   "source": [
    "tns_model.load_weights('tns/weights.hdf5')\n",
    "tns_pred = tns_model.predict(tns_X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(tns_y_test, tns_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(tns_y_test, tns_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(tns_y_test, tns_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 330.3539 - val_loss: 5223.8912\n",
      "Epoch 2/100\n",
      " - 1s - loss: 320.0943 - val_loss: 5189.6256\n",
      "Epoch 3/100\n",
      " - 1s - loss: 313.7126 - val_loss: 5161.5099\n",
      "Epoch 4/100\n",
      " - 1s - loss: 308.0162 - val_loss: 5134.6836\n",
      "Epoch 5/100\n",
      " - 1s - loss: 302.5948 - val_loss: 5108.5802\n",
      "Epoch 6/100\n",
      " - 1s - loss: 297.3375 - val_loss: 5083.1043\n",
      "Epoch 7/100\n",
      " - 1s - loss: 292.2481 - val_loss: 5058.0871\n",
      "Epoch 8/100\n",
      " - 1s - loss: 287.3427 - val_loss: 5033.5395\n",
      "Epoch 9/100\n",
      " - 1s - loss: 282.5453 - val_loss: 5009.2041\n",
      "Epoch 10/100\n",
      " - 1s - loss: 277.8628 - val_loss: 4985.2684\n",
      "Epoch 11/100\n",
      " - 1s - loss: 273.3107 - val_loss: 4961.6215\n",
      "Epoch 12/100\n",
      " - 1s - loss: 268.8461 - val_loss: 4937.9424\n",
      "Epoch 13/100\n",
      " - 1s - loss: 264.4559 - val_loss: 4914.7058\n",
      "Epoch 14/100\n",
      " - 1s - loss: 260.1929 - val_loss: 4891.6860\n",
      "Epoch 15/100\n",
      " - 1s - loss: 256.0190 - val_loss: 4868.8993\n",
      "Epoch 16/100\n",
      " - 1s - loss: 251.9295 - val_loss: 4846.2846\n",
      "Epoch 17/100\n",
      " - 1s - loss: 247.9321 - val_loss: 4824.0089\n",
      "Epoch 18/100\n",
      " - 1s - loss: 244.0276 - val_loss: 4801.8597\n",
      "Epoch 19/100\n",
      " - 1s - loss: 240.1635 - val_loss: 4779.5948\n",
      "Epoch 20/100\n",
      " - 1s - loss: 236.3898 - val_loss: 4757.6439\n",
      "Epoch 21/100\n",
      " - 1s - loss: 232.7373 - val_loss: 4736.1334\n",
      "Epoch 22/100\n",
      " - 1s - loss: 229.1519 - val_loss: 4714.7113\n",
      "Epoch 23/100\n",
      " - 1s - loss: 225.6144 - val_loss: 4693.1892\n",
      "Epoch 24/100\n",
      " - 1s - loss: 222.1902 - val_loss: 4672.1212\n",
      "Epoch 25/100\n",
      " - 1s - loss: 218.7714 - val_loss: 4651.0168\n",
      "Epoch 26/100\n",
      " - 1s - loss: 215.4160 - val_loss: 4629.8823\n",
      "Epoch 27/100\n",
      " - 1s - loss: 212.1992 - val_loss: 4609.1378\n",
      "Epoch 28/100\n",
      " - 1s - loss: 209.0920 - val_loss: 4588.9413\n",
      "Epoch 29/100\n",
      " - 1s - loss: 206.0102 - val_loss: 4568.4907\n",
      "Epoch 30/100\n",
      " - 1s - loss: 203.0138 - val_loss: 4548.4335\n",
      "Epoch 31/100\n",
      " - 1s - loss: 200.1026 - val_loss: 4528.4890\n",
      "Epoch 32/100\n",
      " - 1s - loss: 197.2632 - val_loss: 4508.8053\n",
      "Epoch 33/100\n",
      " - 1s - loss: 194.4812 - val_loss: 4489.3170\n",
      "Epoch 34/100\n",
      " - 1s - loss: 191.7473 - val_loss: 4469.5693\n",
      "Epoch 35/100\n",
      " - 1s - loss: 189.0679 - val_loss: 4450.1614\n",
      "Epoch 36/100\n",
      " - 1s - loss: 186.4879 - val_loss: 4431.2488\n",
      "Epoch 37/100\n",
      " - 1s - loss: 183.9512 - val_loss: 4411.9820\n",
      "Epoch 38/100\n",
      " - 1s - loss: 181.4546 - val_loss: 4393.0842\n",
      "Epoch 39/100\n",
      " - 1s - loss: 179.0250 - val_loss: 4374.1031\n",
      "Epoch 40/100\n",
      " - 1s - loss: 176.6863 - val_loss: 4355.5545\n",
      "Epoch 41/100\n",
      " - 1s - loss: 174.3977 - val_loss: 4337.1503\n",
      "Epoch 42/100\n",
      " - 1s - loss: 172.1660 - val_loss: 4318.7259\n",
      "Epoch 43/100\n",
      " - 1s - loss: 170.0103 - val_loss: 4300.8771\n",
      "Epoch 44/100\n",
      " - 1s - loss: 167.8863 - val_loss: 4282.5846\n",
      "Epoch 45/100\n",
      " - 1s - loss: 165.8031 - val_loss: 4264.4192\n",
      "Epoch 46/100\n",
      " - 1s - loss: 163.8144 - val_loss: 4246.7904\n",
      "Epoch 47/100\n",
      " - 1s - loss: 161.8893 - val_loss: 4229.6118\n",
      "Epoch 48/100\n",
      " - 1s - loss: 160.0107 - val_loss: 4212.0628\n",
      "Epoch 49/100\n",
      " - 1s - loss: 158.1606 - val_loss: 4194.5240\n",
      "Epoch 50/100\n",
      " - 1s - loss: 156.3921 - val_loss: 4177.3457\n",
      "Epoch 51/100\n",
      " - 1s - loss: 154.6916 - val_loss: 4160.7668\n",
      "Epoch 52/100\n",
      " - 1s - loss: 153.0445 - val_loss: 4143.9901\n",
      "Epoch 53/100\n",
      " - 1s - loss: 151.4375 - val_loss: 4127.5200\n",
      "Epoch 54/100\n",
      " - 1s - loss: 149.8426 - val_loss: 4110.4916\n",
      "Epoch 55/100\n",
      " - 1s - loss: 148.3463 - val_loss: 4094.3362\n",
      "Epoch 56/100\n",
      " - 1s - loss: 146.9011 - val_loss: 4078.2844\n",
      "Epoch 57/100\n",
      " - 1s - loss: 145.4781 - val_loss: 4061.9896\n",
      "Epoch 58/100\n",
      " - 1s - loss: 144.1412 - val_loss: 4046.5434\n",
      "Epoch 59/100\n",
      " - 1s - loss: 142.8538 - val_loss: 4031.0996\n",
      "Epoch 60/100\n",
      " - 1s - loss: 141.5802 - val_loss: 4015.4738\n",
      "Epoch 61/100\n",
      " - 1s - loss: 140.3512 - val_loss: 3999.8980\n",
      "Epoch 62/100\n",
      " - 1s - loss: 139.1947 - val_loss: 3985.0495\n",
      "Epoch 63/100\n",
      " - 1s - loss: 138.0894 - val_loss: 3970.1601\n",
      "Epoch 64/100\n",
      " - 1s - loss: 137.0332 - val_loss: 3955.7408\n",
      "Epoch 65/100\n",
      " - 1s - loss: 136.0166 - val_loss: 3941.1108\n",
      "Epoch 66/100\n",
      " - 1s - loss: 135.0327 - val_loss: 3926.7545\n",
      "Epoch 67/100\n",
      " - 1s - loss: 134.0993 - val_loss: 3912.6308\n",
      "Epoch 68/100\n",
      " - 1s - loss: 133.1916 - val_loss: 3898.6252\n",
      "Epoch 69/100\n",
      " - 1s - loss: 132.3131 - val_loss: 3884.3706\n",
      "Epoch 70/100\n",
      " - 1s - loss: 131.5148 - val_loss: 3871.1683\n",
      "Epoch 71/100\n",
      " - 1s - loss: 130.7609 - val_loss: 3858.1853\n",
      "Epoch 72/100\n",
      " - 1s - loss: 130.0396 - val_loss: 3845.1653\n",
      "Epoch 73/100\n",
      " - 1s - loss: 129.3601 - val_loss: 3832.7812\n",
      "Epoch 74/100\n",
      " - 1s - loss: 128.7093 - val_loss: 3820.2666\n",
      "Epoch 75/100\n",
      " - 1s - loss: 128.0922 - val_loss: 3807.9265\n",
      "Epoch 76/100\n",
      " - 1s - loss: 127.4878 - val_loss: 3795.1829\n",
      "Epoch 77/100\n",
      " - 1s - loss: 126.9361 - val_loss: 3783.2962\n",
      "Epoch 78/100\n",
      " - 1s - loss: 126.4387 - val_loss: 3772.2975\n",
      "Epoch 79/100\n",
      " - 1s - loss: 125.9658 - val_loss: 3761.1897\n",
      "Epoch 80/100\n",
      " - 1s - loss: 125.5280 - val_loss: 3750.3097\n",
      "Epoch 81/100\n",
      " - 1s - loss: 125.1127 - val_loss: 3739.8289\n",
      "Epoch 82/100\n",
      " - 1s - loss: 124.7325 - val_loss: 3729.7971\n",
      "Epoch 83/100\n",
      " - 1s - loss: 124.3730 - val_loss: 3719.8440\n",
      "Epoch 84/100\n",
      " - 1s - loss: 124.0175 - val_loss: 3709.3879\n",
      "Epoch 85/100\n",
      " - 1s - loss: 123.7207 - val_loss: 3699.6472\n",
      "Epoch 86/100\n",
      " - 1s - loss: 123.4363 - val_loss: 3690.6242\n",
      "Epoch 87/100\n",
      " - 1s - loss: 123.1829 - val_loss: 3681.9208\n",
      "Epoch 88/100\n",
      " - 1s - loss: 122.9272 - val_loss: 3673.2692\n",
      "Epoch 89/100\n",
      " - 1s - loss: 122.7173 - val_loss: 3665.4898\n",
      "Epoch 90/100\n",
      " - 1s - loss: 122.5222 - val_loss: 3657.0609\n",
      "Epoch 91/100\n",
      " - 1s - loss: 122.3352 - val_loss: 3649.5866\n",
      "Epoch 92/100\n",
      " - 1s - loss: 122.1720 - val_loss: 3642.0938\n",
      "Epoch 93/100\n",
      " - 1s - loss: 122.0082 - val_loss: 3633.7573\n",
      "Epoch 94/100\n",
      " - 1s - loss: 121.8740 - val_loss: 3627.4367\n",
      "Epoch 95/100\n",
      " - 1s - loss: 121.7466 - val_loss: 3620.4787\n",
      "Epoch 96/100\n",
      " - 1s - loss: 121.6394 - val_loss: 3614.1381\n",
      "Epoch 97/100\n",
      " - 1s - loss: 121.5445 - val_loss: 3608.2896\n",
      "Epoch 98/100\n",
      " - 1s - loss: 121.4492 - val_loss: 3602.3424\n",
      "Epoch 99/100\n",
      " - 1s - loss: 121.3657 - val_loss: 3596.1133\n",
      "Epoch 100/100\n",
      " - 1s - loss: 121.2899 - val_loss: 3590.4409\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 327.8498 - val_loss: 5213.6721\n",
      "Epoch 2/100\n",
      " - 1s - loss: 318.6702 - val_loss: 5184.3876\n",
      "Epoch 3/100\n",
      " - 1s - loss: 312.7542 - val_loss: 5157.3061\n",
      "Epoch 4/100\n",
      " - 1s - loss: 307.2317 - val_loss: 5131.2268\n",
      "Epoch 5/100\n",
      " - 1s - loss: 301.9292 - val_loss: 5105.5446\n",
      "Epoch 6/100\n",
      " - 1s - loss: 296.7630 - val_loss: 5080.3358\n",
      "Epoch 7/100\n",
      " - 1s - loss: 291.7825 - val_loss: 5055.7704\n",
      "Epoch 8/100\n",
      " - 1s - loss: 286.9193 - val_loss: 5031.4654\n",
      "Epoch 9/100\n",
      " - 1s - loss: 282.1877 - val_loss: 5007.2839\n",
      "Epoch 10/100\n",
      " - 1s - loss: 277.5487 - val_loss: 4983.5958\n",
      "Epoch 11/100\n",
      " - 1s - loss: 273.0224 - val_loss: 4959.9488\n",
      "Epoch 12/100\n",
      " - 1s - loss: 268.5438 - val_loss: 4936.4960\n",
      "Epoch 13/100\n",
      " - 1s - loss: 264.2088 - val_loss: 4913.3403\n",
      "Epoch 14/100\n",
      " - 1s - loss: 259.9081 - val_loss: 4890.1522\n",
      "Epoch 15/100\n",
      " - 1s - loss: 255.7158 - val_loss: 4867.2709\n",
      "Epoch 16/100\n",
      " - 1s - loss: 251.6285 - val_loss: 4844.6202\n",
      "Epoch 17/100\n",
      " - 1s - loss: 247.6171 - val_loss: 4822.3265\n",
      "Epoch 18/100\n",
      " - 1s - loss: 243.7395 - val_loss: 4800.2963\n",
      "Epoch 19/100\n",
      " - 1s - loss: 239.9295 - val_loss: 4778.3580\n",
      "Epoch 20/100\n",
      " - 1s - loss: 236.1989 - val_loss: 4756.6964\n",
      "Epoch 21/100\n",
      " - 1s - loss: 232.5467 - val_loss: 4735.1168\n",
      "Epoch 22/100\n",
      " - 1s - loss: 228.9889 - val_loss: 4713.8381\n",
      "Epoch 23/100\n",
      " - 1s - loss: 225.4762 - val_loss: 4692.3865\n",
      "Epoch 24/100\n",
      " - 1s - loss: 222.0566 - val_loss: 4671.4655\n",
      "Epoch 25/100\n",
      " - 1s - loss: 218.6982 - val_loss: 4650.5767\n",
      "Epoch 26/100\n",
      " - 1s - loss: 215.4306 - val_loss: 4629.6938\n",
      "Epoch 27/100\n",
      " - 1s - loss: 212.2268 - val_loss: 4609.2428\n",
      "Epoch 28/100\n",
      " - 1s - loss: 209.0755 - val_loss: 4588.7162\n",
      "Epoch 29/100\n",
      " - 1s - loss: 206.0135 - val_loss: 4568.4522\n",
      "Epoch 30/100\n",
      " - 1s - loss: 203.0267 - val_loss: 4548.3624\n",
      "Epoch 31/100\n",
      " - 1s - loss: 200.1061 - val_loss: 4528.4466\n",
      "Epoch 32/100\n",
      " - 1s - loss: 197.2349 - val_loss: 4508.5211\n",
      "Epoch 33/100\n",
      " - 1s - loss: 194.4116 - val_loss: 4488.6594\n",
      "Epoch 34/100\n",
      " - 1s - loss: 191.6419 - val_loss: 4468.8440\n",
      "Epoch 35/100\n",
      " - 1s - loss: 188.9642 - val_loss: 4449.3134\n",
      "Epoch 36/100\n",
      " - 1s - loss: 186.3066 - val_loss: 4429.8819\n",
      "Epoch 37/100\n",
      " - 1s - loss: 183.7903 - val_loss: 4410.8301\n",
      "Epoch 38/100\n",
      " - 1s - loss: 181.2946 - val_loss: 4391.7111\n",
      "Epoch 39/100\n",
      " - 1s - loss: 178.8982 - val_loss: 4373.1901\n",
      "Epoch 40/100\n",
      " - 1s - loss: 176.5587 - val_loss: 4354.7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      " - 1s - loss: 174.2554 - val_loss: 4335.8005\n",
      "Epoch 42/100\n",
      " - 1s - loss: 172.0014 - val_loss: 4317.2722\n",
      "Epoch 43/100\n",
      " - 1s - loss: 169.8347 - val_loss: 4299.2694\n",
      "Epoch 44/100\n",
      " - 1s - loss: 167.7468 - val_loss: 4281.5528\n",
      "Epoch 45/100\n",
      " - 1s - loss: 165.7230 - val_loss: 4263.5009\n",
      "Epoch 46/100\n",
      " - 1s - loss: 163.7215 - val_loss: 4246.0182\n",
      "Epoch 47/100\n",
      " - 1s - loss: 161.7869 - val_loss: 4228.3702\n",
      "Epoch 48/100\n",
      " - 1s - loss: 159.9195 - val_loss: 4211.0565\n",
      "Epoch 49/100\n",
      " - 1s - loss: 158.1044 - val_loss: 4193.8934\n",
      "Epoch 50/100\n",
      " - 1s - loss: 156.3426 - val_loss: 4176.8887\n",
      "Epoch 51/100\n",
      " - 1s - loss: 154.6296 - val_loss: 4159.7981\n",
      "Epoch 52/100\n",
      " - 1s - loss: 152.9710 - val_loss: 4143.1578\n",
      "Epoch 53/100\n",
      " - 1s - loss: 151.3625 - val_loss: 4126.7047\n",
      "Epoch 54/100\n",
      " - 1s - loss: 149.7781 - val_loss: 4109.8079\n",
      "Epoch 55/100\n",
      " - 1s - loss: 148.2743 - val_loss: 4093.5627\n",
      "Epoch 56/100\n",
      " - 1s - loss: 146.8337 - val_loss: 4077.6186\n",
      "Epoch 57/100\n",
      " - 1s - loss: 145.4425 - val_loss: 4061.6534\n",
      "Epoch 58/100\n",
      " - 1s - loss: 144.0830 - val_loss: 4045.8846\n",
      "Epoch 59/100\n",
      " - 1s - loss: 142.7659 - val_loss: 4030.2324\n",
      "Epoch 60/100\n",
      " - 1s - loss: 141.5253 - val_loss: 4014.8992\n",
      "Epoch 61/100\n",
      " - 1s - loss: 140.3033 - val_loss: 3999.2339\n",
      "Epoch 62/100\n",
      " - 1s - loss: 139.1446 - val_loss: 3984.2235\n",
      "Epoch 63/100\n",
      " - 1s - loss: 138.0059 - val_loss: 3969.0145\n",
      "Epoch 64/100\n",
      " - 1s - loss: 136.9119 - val_loss: 3953.9354\n",
      "Epoch 65/100\n",
      " - 1s - loss: 135.9048 - val_loss: 3939.3796\n",
      "Epoch 66/100\n",
      " - 1s - loss: 134.9306 - val_loss: 3925.3556\n",
      "Epoch 67/100\n",
      " - 1s - loss: 134.0014 - val_loss: 3911.3463\n",
      "Epoch 68/100\n",
      " - 1s - loss: 133.1253 - val_loss: 3897.2229\n",
      "Epoch 69/100\n",
      " - 1s - loss: 132.2902 - val_loss: 3884.1339\n",
      "Epoch 70/100\n",
      " - 1s - loss: 131.5035 - val_loss: 3870.9841\n",
      "Epoch 71/100\n",
      " - 1s - loss: 130.7497 - val_loss: 3858.0831\n",
      "Epoch 72/100\n",
      " - 1s - loss: 130.0388 - val_loss: 3845.2757\n",
      "Epoch 73/100\n",
      " - 1s - loss: 129.3594 - val_loss: 3832.6655\n",
      "Epoch 74/100\n",
      " - 1s - loss: 128.7178 - val_loss: 3820.4361\n",
      "Epoch 75/100\n",
      " - 1s - loss: 128.1141 - val_loss: 3808.3034\n",
      "Epoch 76/100\n",
      " - 1s - loss: 127.5140 - val_loss: 3795.9392\n",
      "Epoch 77/100\n",
      " - 1s - loss: 126.9735 - val_loss: 3784.7736\n",
      "Epoch 78/100\n",
      " - 1s - loss: 126.4667 - val_loss: 3772.9582\n",
      "Epoch 79/100\n",
      " - 1s - loss: 125.9935 - val_loss: 3761.7738\n",
      "Epoch 80/100\n",
      " - 1s - loss: 125.5594 - val_loss: 3750.8117\n",
      "Epoch 81/100\n",
      " - 1s - loss: 125.1236 - val_loss: 3740.0161\n",
      "Epoch 82/100\n",
      " - 1s - loss: 124.7397 - val_loss: 3729.8663\n",
      "Epoch 83/100\n",
      " - 1s - loss: 124.3858 - val_loss: 3719.5932\n",
      "Epoch 84/100\n",
      " - 1s - loss: 124.0515 - val_loss: 3710.2940\n",
      "Epoch 85/100\n",
      " - 1s - loss: 123.7497 - val_loss: 3700.7410\n",
      "Epoch 86/100\n",
      " - 1s - loss: 123.4475 - val_loss: 3691.2451\n",
      "Epoch 87/100\n",
      " - 1s - loss: 123.1823 - val_loss: 3682.0201\n",
      "Epoch 88/100\n",
      " - 1s - loss: 122.9228 - val_loss: 3672.5070\n",
      "Epoch 89/100\n",
      " - 1s - loss: 122.6912 - val_loss: 3664.1301\n",
      "Epoch 90/100\n",
      " - 1s - loss: 122.5008 - val_loss: 3656.4891\n",
      "Epoch 91/100\n",
      " - 1s - loss: 122.3087 - val_loss: 3648.1681\n",
      "Epoch 92/100\n",
      " - 1s - loss: 122.1349 - val_loss: 3640.1087\n",
      "Epoch 93/100\n",
      " - 1s - loss: 121.9928 - val_loss: 3633.4477\n",
      "Epoch 94/100\n",
      " - 1s - loss: 121.8561 - val_loss: 3626.5441\n",
      "Epoch 95/100\n",
      " - 1s - loss: 121.7419 - val_loss: 3620.1956\n",
      "Epoch 96/100\n",
      " - 1s - loss: 121.6401 - val_loss: 3614.5598\n",
      "Epoch 97/100\n",
      " - 1s - loss: 121.5495 - val_loss: 3609.0108\n",
      "Epoch 98/100\n",
      " - 1s - loss: 121.4655 - val_loss: 3603.2782\n",
      "Epoch 99/100\n",
      " - 1s - loss: 121.3908 - val_loss: 3597.8345\n",
      "Epoch 100/100\n",
      " - 1s - loss: 121.3234 - val_loss: 3593.2229\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 329.5991 - val_loss: 5220.1373\n",
      "Epoch 2/100\n",
      " - 1s - loss: 319.8671 - val_loss: 5189.5340\n",
      "Epoch 3/100\n",
      " - 1s - loss: 313.7396 - val_loss: 5161.8991\n",
      "Epoch 4/100\n",
      " - 1s - loss: 308.0781 - val_loss: 5135.3176\n",
      "Epoch 5/100\n",
      " - 1s - loss: 302.7908 - val_loss: 5109.9597\n",
      "Epoch 6/100\n",
      " - 1s - loss: 297.6505 - val_loss: 5084.9266\n",
      "Epoch 7/100\n",
      " - 1s - loss: 292.6481 - val_loss: 5060.1917\n",
      "Epoch 8/100\n",
      " - 1s - loss: 287.8116 - val_loss: 5035.8911\n",
      "Epoch 9/100\n",
      " - 1s - loss: 283.0766 - val_loss: 5012.0914\n",
      "Epoch 10/100\n",
      " - 1s - loss: 278.3967 - val_loss: 4987.8890\n",
      "Epoch 11/100\n",
      " - 1s - loss: 273.8574 - val_loss: 4964.5195\n",
      "Epoch 12/100\n",
      " - 1s - loss: 269.4227 - val_loss: 4941.1743\n",
      "Epoch 13/100\n",
      " - 1s - loss: 265.0816 - val_loss: 4918.1218\n",
      "Epoch 14/100\n",
      " - 1s - loss: 260.8482 - val_loss: 4895.3806\n",
      "Epoch 15/100\n",
      " - 1s - loss: 256.6915 - val_loss: 4872.7901\n",
      "Epoch 16/100\n",
      " - 1s - loss: 252.6241 - val_loss: 4850.1796\n",
      "Epoch 17/100\n",
      " - 1s - loss: 248.6206 - val_loss: 4827.8756\n",
      "Epoch 18/100\n",
      " - 1s - loss: 244.7133 - val_loss: 4805.8233\n",
      "Epoch 19/100\n",
      " - 1s - loss: 240.8828 - val_loss: 4783.8451\n",
      "Epoch 20/100\n",
      " - 1s - loss: 237.1362 - val_loss: 4762.0512\n",
      "Epoch 21/100\n",
      " - 1s - loss: 233.4733 - val_loss: 4740.5033\n",
      "Epoch 22/100\n",
      " - 1s - loss: 229.8854 - val_loss: 4719.0507\n",
      "Epoch 23/100\n",
      " - 1s - loss: 226.3728 - val_loss: 4697.9596\n",
      "Epoch 24/100\n",
      " - 1s - loss: 222.9122 - val_loss: 4676.6111\n",
      "Epoch 25/100\n",
      " - 1s - loss: 219.5497 - val_loss: 4655.7680\n",
      "Epoch 26/100\n",
      " - 1s - loss: 216.2521 - val_loss: 4634.9074\n",
      "Epoch 27/100\n",
      " - 1s - loss: 213.0209 - val_loss: 4614.3916\n",
      "Epoch 28/100\n",
      " - 1s - loss: 209.8408 - val_loss: 4593.7400\n",
      "Epoch 29/100\n",
      " - 1s - loss: 206.7774 - val_loss: 4573.3610\n",
      "Epoch 30/100\n",
      " - 1s - loss: 203.7392 - val_loss: 4553.0854\n",
      "Epoch 31/100\n",
      " - 1s - loss: 200.8068 - val_loss: 4533.2701\n",
      "Epoch 32/100\n",
      " - 1s - loss: 197.8959 - val_loss: 4513.2447\n",
      "Epoch 33/100\n",
      " - 1s - loss: 195.0963 - val_loss: 4493.4281\n",
      "Epoch 34/100\n",
      " - 1s - loss: 192.3231 - val_loss: 4473.7739\n",
      "Epoch 35/100\n",
      " - 1s - loss: 189.5880 - val_loss: 4454.1789\n",
      "Epoch 36/100\n",
      " - 1s - loss: 187.0021 - val_loss: 4435.0377\n",
      "Epoch 37/100\n",
      " - 1s - loss: 184.4262 - val_loss: 4415.5592\n",
      "Epoch 38/100\n",
      " - 1s - loss: 181.9488 - val_loss: 4396.8093\n",
      "Epoch 39/100\n",
      " - 1s - loss: 179.5348 - val_loss: 4378.1039\n",
      "Epoch 40/100\n",
      " - 1s - loss: 177.1948 - val_loss: 4359.6974\n",
      "Epoch 41/100\n",
      " - 1s - loss: 174.8691 - val_loss: 4340.9131\n",
      "Epoch 42/100\n",
      " - 1s - loss: 172.6112 - val_loss: 4322.5853\n",
      "Epoch 43/100\n",
      " - 1s - loss: 170.4154 - val_loss: 4304.0154\n",
      "Epoch 44/100\n",
      " - 1s - loss: 168.3089 - val_loss: 4286.2653\n",
      "Epoch 45/100\n",
      " - 1s - loss: 166.2400 - val_loss: 4268.2807\n",
      "Epoch 46/100\n",
      " - 1s - loss: 164.1874 - val_loss: 4249.9843\n",
      "Epoch 47/100\n",
      " - 1s - loss: 162.2472 - val_loss: 4232.6712\n",
      "Epoch 48/100\n",
      " - 1s - loss: 160.3381 - val_loss: 4214.9556\n",
      "Epoch 49/100\n",
      " - 1s - loss: 158.5228 - val_loss: 4197.7965\n",
      "Epoch 50/100\n",
      " - 1s - loss: 156.7315 - val_loss: 4180.6587\n",
      "Epoch 51/100\n",
      " - 1s - loss: 155.0139 - val_loss: 4163.9642\n",
      "Epoch 52/100\n",
      " - 1s - loss: 153.3569 - val_loss: 4147.1986\n",
      "Epoch 53/100\n",
      " - 1s - loss: 151.7177 - val_loss: 4130.2504\n",
      "Epoch 54/100\n",
      " - 1s - loss: 150.1733 - val_loss: 4114.1894\n",
      "Epoch 55/100\n",
      " - 1s - loss: 148.6737 - val_loss: 4097.9004\n",
      "Epoch 56/100\n",
      " - 1s - loss: 147.2218 - val_loss: 4081.9852\n",
      "Epoch 57/100\n",
      " - 1s - loss: 145.8188 - val_loss: 4066.0114\n",
      "Epoch 58/100\n",
      " - 1s - loss: 144.4724 - val_loss: 4050.3614\n",
      "Epoch 59/100\n",
      " - 1s - loss: 143.1652 - val_loss: 4034.7531\n",
      "Epoch 60/100\n",
      " - 1s - loss: 141.8603 - val_loss: 4018.9561\n",
      "Epoch 61/100\n",
      " - 1s - loss: 140.6141 - val_loss: 4003.3666\n",
      "Epoch 62/100\n",
      " - 1s - loss: 139.4581 - val_loss: 3988.2571\n",
      "Epoch 63/100\n",
      " - 1s - loss: 138.3575 - val_loss: 3973.7252\n",
      "Epoch 64/100\n",
      " - 1s - loss: 137.2913 - val_loss: 3958.9176\n",
      "Epoch 65/100\n",
      " - 1s - loss: 136.2714 - val_loss: 3944.8075\n",
      "Epoch 66/100\n",
      " - 1s - loss: 135.2854 - val_loss: 3930.5233\n",
      "Epoch 67/100\n",
      " - 1s - loss: 134.3530 - val_loss: 3916.8679\n",
      "Epoch 68/100\n",
      " - 1s - loss: 133.4483 - val_loss: 3902.5055\n",
      "Epoch 69/100\n",
      " - 1s - loss: 132.5553 - val_loss: 3888.3912\n",
      "Epoch 70/100\n",
      " - 1s - loss: 131.7193 - val_loss: 3874.3759\n",
      "Epoch 71/100\n",
      " - 1s - loss: 130.9474 - val_loss: 3861.5725\n",
      "Epoch 72/100\n",
      " - 1s - loss: 130.1907 - val_loss: 3848.0456\n",
      "Epoch 73/100\n",
      " - 1s - loss: 129.5022 - val_loss: 3835.5062\n",
      "Epoch 74/100\n",
      " - 1s - loss: 128.8342 - val_loss: 3822.6910\n",
      "Epoch 75/100\n",
      " - 1s - loss: 128.2055 - val_loss: 3810.1326\n",
      "Epoch 76/100\n",
      " - 1s - loss: 127.6051 - val_loss: 3797.9813\n",
      "Epoch 77/100\n",
      " - 1s - loss: 127.0530 - val_loss: 3785.9777\n",
      "Epoch 78/100\n",
      " - 1s - loss: 126.5393 - val_loss: 3774.6049\n",
      "Epoch 79/100\n",
      " - 1s - loss: 126.0682 - val_loss: 3763.9005\n",
      "Epoch 80/100\n",
      " - 1s - loss: 125.6294 - val_loss: 3753.3596\n",
      "Epoch 81/100\n",
      " - 1s - loss: 125.2121 - val_loss: 3742.2265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      " - 1s - loss: 124.8168 - val_loss: 3731.8845\n",
      "Epoch 83/100\n",
      " - 1s - loss: 124.4564 - val_loss: 3722.0232\n",
      "Epoch 84/100\n",
      " - 1s - loss: 124.1189 - val_loss: 3711.8349\n",
      "Epoch 85/100\n",
      " - 1s - loss: 123.7804 - val_loss: 3701.8028\n",
      "Epoch 86/100\n",
      " - 1s - loss: 123.4782 - val_loss: 3692.2587\n",
      "Epoch 87/100\n",
      " - 1s - loss: 123.2115 - val_loss: 3683.3767\n",
      "Epoch 88/100\n",
      " - 1s - loss: 122.9593 - val_loss: 3673.7330\n",
      "Epoch 89/100\n",
      " - 1s - loss: 122.7241 - val_loss: 3665.6188\n",
      "Epoch 90/100\n",
      " - 1s - loss: 122.5215 - val_loss: 3656.6679\n",
      "Epoch 91/100\n",
      " - 1s - loss: 122.3149 - val_loss: 3648.2868\n",
      "Epoch 92/100\n",
      " - 1s - loss: 122.1537 - val_loss: 3640.9804\n",
      "Epoch 93/100\n",
      " - 1s - loss: 122.0073 - val_loss: 3634.0914\n",
      "Epoch 94/100\n",
      " - 1s - loss: 121.8632 - val_loss: 3626.6918\n",
      "Epoch 95/100\n",
      " - 1s - loss: 121.7479 - val_loss: 3620.7473\n",
      "Epoch 96/100\n",
      " - 1s - loss: 121.6309 - val_loss: 3613.4330\n",
      "Epoch 97/100\n",
      " - 1s - loss: 121.5290 - val_loss: 3607.4497\n",
      "Epoch 98/100\n",
      " - 1s - loss: 121.4521 - val_loss: 3602.6095\n",
      "Epoch 99/100\n",
      " - 1s - loss: 121.3768 - val_loss: 3597.1791\n",
      "Epoch 100/100\n",
      " - 1s - loss: 121.3119 - val_loss: 3592.5817\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 331.8969 - val_loss: 5229.2474\n",
      "Epoch 2/100\n",
      " - 1s - loss: 318.3714 - val_loss: 5176.3115\n",
      "Epoch 3/100\n",
      " - 1s - loss: 310.7791 - val_loss: 5146.8451\n",
      "Epoch 4/100\n",
      " - 1s - loss: 304.9322 - val_loss: 5119.4330\n",
      "Epoch 5/100\n",
      " - 1s - loss: 299.4594 - val_loss: 5093.1767\n",
      "Epoch 6/100\n",
      " - 1s - loss: 294.2369 - val_loss: 5067.6470\n",
      "Epoch 7/100\n",
      " - 1s - loss: 289.1451 - val_loss: 5042.3269\n",
      "Epoch 8/100\n",
      " - 1s - loss: 284.2651 - val_loss: 5017.6456\n",
      "Epoch 9/100\n",
      " - 1s - loss: 279.4598 - val_loss: 4993.1154\n",
      "Epoch 10/100\n",
      " - 1s - loss: 274.8194 - val_loss: 4969.3204\n",
      "Epoch 11/100\n",
      " - 1s - loss: 270.2979 - val_loss: 4945.7014\n",
      "Epoch 12/100\n",
      " - 1s - loss: 265.8303 - val_loss: 4921.9637\n",
      "Epoch 13/100\n",
      " - 1s - loss: 261.4710 - val_loss: 4898.6737\n",
      "Epoch 14/100\n",
      " - 1s - loss: 257.2708 - val_loss: 4875.8531\n",
      "Epoch 15/100\n",
      " - 1s - loss: 253.1646 - val_loss: 4853.2958\n",
      "Epoch 16/100\n",
      " - 1s - loss: 249.1335 - val_loss: 4830.6359\n",
      "Epoch 17/100\n",
      " - 1s - loss: 245.1652 - val_loss: 4808.4291\n",
      "Epoch 18/100\n",
      " - 1s - loss: 241.3132 - val_loss: 4786.2047\n",
      "Epoch 19/100\n",
      " - 1s - loss: 237.5467 - val_loss: 4764.5037\n",
      "Epoch 20/100\n",
      " - 1s - loss: 233.8053 - val_loss: 4742.5162\n",
      "Epoch 21/100\n",
      " - 1s - loss: 230.1580 - val_loss: 4720.6907\n",
      "Epoch 22/100\n",
      " - 1s - loss: 226.6239 - val_loss: 4699.4155\n",
      "Epoch 23/100\n",
      " - 1s - loss: 223.1753 - val_loss: 4678.2892\n",
      "Epoch 24/100\n",
      " - 1s - loss: 219.7845 - val_loss: 4657.2539\n",
      "Epoch 25/100\n",
      " - 1s - loss: 216.4708 - val_loss: 4636.4321\n",
      "Epoch 26/100\n",
      " - 1s - loss: 213.2264 - val_loss: 4615.6643\n",
      "Epoch 27/100\n",
      " - 1s - loss: 210.0598 - val_loss: 4595.1573\n",
      "Epoch 28/100\n",
      " - 1s - loss: 206.9648 - val_loss: 4574.7714\n",
      "Epoch 29/100\n",
      " - 1s - loss: 203.9422 - val_loss: 4554.3939\n",
      "Epoch 30/100\n",
      " - 1s - loss: 200.9867 - val_loss: 4534.3675\n",
      "Epoch 31/100\n",
      " - 1s - loss: 198.1050 - val_loss: 4514.4921\n",
      "Epoch 32/100\n",
      " - 1s - loss: 195.2916 - val_loss: 4494.9678\n",
      "Epoch 33/100\n",
      " - 1s - loss: 192.5064 - val_loss: 4475.0716\n",
      "Epoch 34/100\n",
      " - 1s - loss: 189.8118 - val_loss: 4455.6250\n",
      "Epoch 35/100\n",
      " - 1s - loss: 187.1955 - val_loss: 4436.4404\n",
      "Epoch 36/100\n",
      " - 1s - loss: 184.6457 - val_loss: 4417.1344\n",
      "Epoch 37/100\n",
      " - 1s - loss: 182.1000 - val_loss: 4397.8626\n",
      "Epoch 38/100\n",
      " - 1s - loss: 179.6404 - val_loss: 4378.8525\n",
      "Epoch 39/100\n",
      " - 1s - loss: 177.2757 - val_loss: 4360.4345\n",
      "Epoch 40/100\n",
      " - 1s - loss: 174.9653 - val_loss: 4341.8389\n",
      "Epoch 41/100\n",
      " - 1s - loss: 172.7212 - val_loss: 4323.4031\n",
      "Epoch 42/100\n",
      " - 1s - loss: 170.5113 - val_loss: 4304.8176\n",
      "Epoch 43/100\n",
      " - 1s - loss: 168.3816 - val_loss: 4286.9014\n",
      "Epoch 44/100\n",
      " - 1s - loss: 166.3322 - val_loss: 4269.0119\n",
      "Epoch 45/100\n",
      " - 1s - loss: 164.3026 - val_loss: 4251.2128\n",
      "Epoch 46/100\n",
      " - 1s - loss: 162.3631 - val_loss: 4233.5662\n",
      "Epoch 47/100\n",
      " - 1s - loss: 160.4593 - val_loss: 4216.3066\n",
      "Epoch 48/100\n",
      " - 1s - loss: 158.6285 - val_loss: 4198.9145\n",
      "Epoch 49/100\n",
      " - 1s - loss: 156.8448 - val_loss: 4181.8328\n",
      "Epoch 50/100\n",
      " - 1s - loss: 155.1259 - val_loss: 4164.8557\n",
      "Epoch 51/100\n",
      " - 1s - loss: 153.4531 - val_loss: 4148.1186\n",
      "Epoch 52/100\n",
      " - 1s - loss: 151.8202 - val_loss: 4131.3276\n",
      "Epoch 53/100\n",
      " - 1s - loss: 150.2429 - val_loss: 4114.7242\n",
      "Epoch 54/100\n",
      " - 1s - loss: 148.7324 - val_loss: 4098.4125\n",
      "Epoch 55/100\n",
      " - 1s - loss: 147.2731 - val_loss: 4082.5522\n",
      "Epoch 56/100\n",
      " - 1s - loss: 145.8358 - val_loss: 4066.4422\n",
      "Epoch 57/100\n",
      " - 1s - loss: 144.4605 - val_loss: 4050.3556\n",
      "Epoch 58/100\n",
      " - 1s - loss: 143.1105 - val_loss: 4034.1891\n",
      "Epoch 59/100\n",
      " - 1s - loss: 141.8510 - val_loss: 4018.7734\n",
      "Epoch 60/100\n",
      " - 1s - loss: 140.5979 - val_loss: 4003.2040\n",
      "Epoch 61/100\n",
      " - 1s - loss: 139.4261 - val_loss: 3987.7660\n",
      "Epoch 62/100\n",
      " - 1s - loss: 138.3184 - val_loss: 3973.4133\n",
      "Epoch 63/100\n",
      " - 1s - loss: 137.2312 - val_loss: 3958.2068\n",
      "Epoch 64/100\n",
      " - 1s - loss: 136.2113 - val_loss: 3944.1600\n",
      "Epoch 65/100\n",
      " - 1s - loss: 135.2406 - val_loss: 3929.5942\n",
      "Epoch 66/100\n",
      " - 1s - loss: 134.3047 - val_loss: 3915.9557\n",
      "Epoch 67/100\n",
      " - 1s - loss: 133.4098 - val_loss: 3902.0207\n",
      "Epoch 68/100\n",
      " - 1s - loss: 132.5591 - val_loss: 3888.4116\n",
      "Epoch 69/100\n",
      " - 1s - loss: 131.7511 - val_loss: 3875.4100\n",
      "Epoch 70/100\n",
      " - 1s - loss: 130.9543 - val_loss: 3861.5835\n",
      "Epoch 71/100\n",
      " - 1s - loss: 130.2223 - val_loss: 3848.5744\n",
      "Epoch 72/100\n",
      " - 1s - loss: 129.5346 - val_loss: 3835.9752\n",
      "Epoch 73/100\n",
      " - 1s - loss: 128.8341 - val_loss: 3822.7061\n",
      "Epoch 74/100\n",
      " - 1s - loss: 128.2212 - val_loss: 3810.6484\n",
      "Epoch 75/100\n",
      " - 1s - loss: 127.6092 - val_loss: 3797.9616\n",
      "Epoch 76/100\n",
      " - 1s - loss: 127.0686 - val_loss: 3786.3810\n",
      "Epoch 77/100\n",
      " - 1s - loss: 126.5672 - val_loss: 3775.3448\n",
      "Epoch 78/100\n",
      " - 1s - loss: 126.0984 - val_loss: 3764.4576\n",
      "Epoch 79/100\n",
      " - 1s - loss: 125.6529 - val_loss: 3753.6936\n",
      "Epoch 80/100\n",
      " - 1s - loss: 125.2111 - val_loss: 3741.9885\n",
      "Epoch 81/100\n",
      " - 1s - loss: 124.8038 - val_loss: 3731.4019\n",
      "Epoch 82/100\n",
      " - 1s - loss: 124.4197 - val_loss: 3721.2251\n",
      "Epoch 83/100\n",
      " - 1s - loss: 124.0769 - val_loss: 3710.9064\n",
      "Epoch 84/100\n",
      " - 1s - loss: 123.7750 - val_loss: 3701.7867\n",
      "Epoch 85/100\n",
      " - 1s - loss: 123.4844 - val_loss: 3692.8523\n",
      "Epoch 86/100\n",
      " - 1s - loss: 123.2113 - val_loss: 3683.2746\n",
      "Epoch 87/100\n",
      " - 1s - loss: 122.9678 - val_loss: 3674.8266\n",
      "Epoch 88/100\n",
      " - 1s - loss: 122.7552 - val_loss: 3666.6752\n",
      "Epoch 89/100\n",
      " - 1s - loss: 122.5569 - val_loss: 3658.5364\n",
      "Epoch 90/100\n",
      " - 1s - loss: 122.3602 - val_loss: 3650.1526\n",
      "Epoch 91/100\n",
      " - 1s - loss: 122.1747 - val_loss: 3641.8473\n",
      "Epoch 92/100\n",
      " - 1s - loss: 122.0336 - val_loss: 3635.6679\n",
      "Epoch 93/100\n",
      " - 1s - loss: 121.9044 - val_loss: 3628.6989\n",
      "Epoch 94/100\n",
      " - 1s - loss: 121.7754 - val_loss: 3622.0886\n",
      "Epoch 95/100\n",
      " - 1s - loss: 121.6585 - val_loss: 3615.2452\n",
      "Epoch 96/100\n",
      " - 1s - loss: 121.5626 - val_loss: 3609.1646\n",
      "Epoch 97/100\n",
      " - 1s - loss: 121.4787 - val_loss: 3604.8203\n",
      "Epoch 98/100\n",
      " - 1s - loss: 121.3946 - val_loss: 3598.9076\n",
      "Epoch 99/100\n",
      " - 1s - loss: 121.3183 - val_loss: 3592.6352\n",
      "Epoch 100/100\n",
      " - 1s - loss: 121.2637 - val_loss: 3588.0289\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 328.5810 - val_loss: 5216.1657\n",
      "Epoch 2/100\n",
      " - 1s - loss: 318.5512 - val_loss: 5181.8062\n",
      "Epoch 3/100\n",
      " - 1s - loss: 312.0110 - val_loss: 5153.2044\n",
      "Epoch 4/100\n",
      " - 1s - loss: 306.2893 - val_loss: 5126.2869\n",
      "Epoch 5/100\n",
      " - 1s - loss: 300.8764 - val_loss: 5100.2639\n",
      "Epoch 6/100\n",
      " - 1s - loss: 295.6588 - val_loss: 5074.7390\n",
      "Epoch 7/100\n",
      " - 1s - loss: 290.6396 - val_loss: 5049.9437\n",
      "Epoch 8/100\n",
      " - 1s - loss: 285.7581 - val_loss: 5025.5597\n",
      "Epoch 9/100\n",
      " - 1s - loss: 281.0138 - val_loss: 5001.3039\n",
      "Epoch 10/100\n",
      " - 1s - loss: 276.3689 - val_loss: 4977.4229\n",
      "Epoch 11/100\n",
      " - 1s - loss: 271.8443 - val_loss: 4953.6508\n",
      "Epoch 12/100\n",
      " - 1s - loss: 267.4141 - val_loss: 4930.4559\n",
      "Epoch 13/100\n",
      " - 1s - loss: 263.0874 - val_loss: 4907.3347\n",
      "Epoch 14/100\n",
      " - 1s - loss: 258.8444 - val_loss: 4884.4047\n",
      "Epoch 15/100\n",
      " - 1s - loss: 254.6703 - val_loss: 4861.3616\n",
      "Epoch 16/100\n",
      " - 1s - loss: 250.5622 - val_loss: 4838.6757\n",
      "Epoch 17/100\n",
      " - 1s - loss: 246.6017 - val_loss: 4816.4972\n",
      "Epoch 18/100\n",
      " - 1s - loss: 242.6919 - val_loss: 4794.1317\n",
      "Epoch 19/100\n",
      " - 1s - loss: 238.8897 - val_loss: 4772.3573\n",
      "Epoch 20/100\n",
      " - 1s - loss: 235.1751 - val_loss: 4750.6283\n",
      "Epoch 21/100\n",
      " - 1s - loss: 231.5459 - val_loss: 4729.0531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      " - 1s - loss: 227.9845 - val_loss: 4707.6989\n",
      "Epoch 23/100\n",
      " - 1s - loss: 224.4887 - val_loss: 4686.3927\n",
      "Epoch 24/100\n",
      " - 1s - loss: 221.0787 - val_loss: 4665.2242\n",
      "Epoch 25/100\n",
      " - 1s - loss: 217.7465 - val_loss: 4644.4069\n",
      "Epoch 26/100\n",
      " - 1s - loss: 214.4798 - val_loss: 4623.6900\n",
      "Epoch 27/100\n",
      " - 1s - loss: 211.2112 - val_loss: 4602.5139\n",
      "Epoch 28/100\n",
      " - 1s - loss: 208.0499 - val_loss: 4581.9043\n",
      "Epoch 29/100\n",
      " - 1s - loss: 205.0250 - val_loss: 4561.8427\n",
      "Epoch 30/100\n",
      " - 1s - loss: 202.0791 - val_loss: 4541.8518\n",
      "Epoch 31/100\n",
      " - 1s - loss: 199.1769 - val_loss: 4522.2242\n",
      "Epoch 32/100\n",
      " - 1s - loss: 196.3443 - val_loss: 4502.3222\n",
      "Epoch 33/100\n",
      " - 1s - loss: 193.5824 - val_loss: 4482.7310\n",
      "Epoch 34/100\n",
      " - 1s - loss: 190.8815 - val_loss: 4463.4862\n",
      "Epoch 35/100\n",
      " - 1s - loss: 188.2314 - val_loss: 4444.0385\n",
      "Epoch 36/100\n",
      " - 1s - loss: 185.6150 - val_loss: 4424.5982\n",
      "Epoch 37/100\n",
      " - 1s - loss: 183.0713 - val_loss: 4405.4540\n",
      "Epoch 38/100\n",
      " - 1s - loss: 180.5803 - val_loss: 4386.1000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 178.1884 - val_loss: 4367.5611\n",
      "Epoch 40/100\n",
      " - 1s - loss: 175.8431 - val_loss: 4348.6218\n",
      "Epoch 41/100\n",
      " - 1s - loss: 173.5863 - val_loss: 4330.5175\n",
      "Epoch 42/100\n",
      " - 1s - loss: 171.3729 - val_loss: 4312.1457\n",
      "Epoch 43/100\n",
      " - 1s - loss: 169.2103 - val_loss: 4294.0962\n",
      "Epoch 44/100\n",
      " - 1s - loss: 167.1281 - val_loss: 4276.0823\n",
      "Epoch 45/100\n",
      " - 1s - loss: 165.0785 - val_loss: 4257.8554\n",
      "Epoch 46/100\n",
      " - 1s - loss: 163.1127 - val_loss: 4240.3153\n",
      "Epoch 47/100\n",
      " - 1s - loss: 161.1666 - val_loss: 4222.6431\n",
      "Epoch 48/100\n",
      " - 1s - loss: 159.2868 - val_loss: 4205.1021\n",
      "Epoch 49/100\n",
      " - 1s - loss: 157.4949 - val_loss: 4187.9991\n",
      "Epoch 50/100\n",
      " - 1s - loss: 155.7615 - val_loss: 4171.2575\n",
      "Epoch 51/100\n",
      " - 1s - loss: 154.0464 - val_loss: 4154.1136\n",
      "Epoch 52/100\n",
      " - 1s - loss: 152.3946 - val_loss: 4137.4027\n",
      "Epoch 53/100\n",
      " - 1s - loss: 150.8108 - val_loss: 4120.8169\n",
      "Epoch 54/100\n",
      " - 1s - loss: 149.2714 - val_loss: 4104.3937\n",
      "Epoch 55/100\n",
      " - 1s - loss: 147.7910 - val_loss: 4088.0298\n",
      "Epoch 56/100\n",
      " - 1s - loss: 146.3681 - val_loss: 4072.2552\n",
      "Epoch 57/100\n",
      " - 1s - loss: 144.9520 - val_loss: 4056.0149\n",
      "Epoch 58/100\n",
      " - 1s - loss: 143.6169 - val_loss: 4040.1550\n",
      "Epoch 59/100\n",
      " - 1s - loss: 142.3474 - val_loss: 4025.2069\n",
      "Epoch 60/100\n",
      " - 1s - loss: 141.1109 - val_loss: 4009.7253\n",
      "Epoch 61/100\n",
      " - 1s - loss: 139.9026 - val_loss: 3994.0614\n",
      "Epoch 62/100\n",
      " - 1s - loss: 138.7742 - val_loss: 3979.1802\n",
      "Epoch 63/100\n",
      " - 1s - loss: 137.6507 - val_loss: 3964.4006\n",
      "Epoch 64/100\n",
      " - 1s - loss: 136.6162 - val_loss: 3949.6808\n",
      "Epoch 65/100\n",
      " - 1s - loss: 135.6242 - val_loss: 3935.2494\n",
      "Epoch 66/100\n",
      " - 1s - loss: 134.6708 - val_loss: 3921.3643\n",
      "Epoch 67/100\n",
      " - 1s - loss: 133.7584 - val_loss: 3907.3931\n",
      "Epoch 68/100\n",
      " - 1s - loss: 132.8907 - val_loss: 3893.5782\n",
      "Epoch 69/100\n",
      " - 1s - loss: 132.0577 - val_loss: 3880.3398\n",
      "Epoch 70/100\n",
      " - 1s - loss: 131.2509 - val_loss: 3866.5849\n",
      "Epoch 71/100\n",
      " - 1s - loss: 130.4969 - val_loss: 3853.5271\n",
      "Epoch 72/100\n",
      " - 1s - loss: 129.7767 - val_loss: 3840.5137\n",
      "Epoch 73/100\n",
      " - 1s - loss: 129.1050 - val_loss: 3827.6807\n",
      "Epoch 74/100\n",
      " - 1s - loss: 128.4415 - val_loss: 3814.7471\n",
      "Epoch 75/100\n",
      " - 1s - loss: 127.8354 - val_loss: 3802.4025\n",
      "Epoch 76/100\n",
      " - 1s - loss: 127.2755 - val_loss: 3790.9167\n",
      "Epoch 77/100\n",
      " - 1s - loss: 126.7554 - val_loss: 3779.7257\n",
      "Epoch 78/100\n",
      " - 1s - loss: 126.2604 - val_loss: 3768.0551\n",
      "Epoch 79/100\n",
      " - 1s - loss: 125.7944 - val_loss: 3757.0991\n",
      "Epoch 80/100\n",
      " - 1s - loss: 125.3631 - val_loss: 3746.3941\n",
      "Epoch 81/100\n",
      " - 1s - loss: 124.9628 - val_loss: 3735.5490\n",
      "Epoch 82/100\n",
      " - 1s - loss: 124.5808 - val_loss: 3725.2206\n",
      "Epoch 83/100\n",
      " - 1s - loss: 124.2085 - val_loss: 3714.5217\n",
      "Epoch 84/100\n",
      " - 1s - loss: 123.8509 - val_loss: 3703.8668\n",
      "Epoch 85/100\n",
      " - 1s - loss: 123.5661 - val_loss: 3694.7860\n",
      "Epoch 86/100\n",
      " - 1s - loss: 123.3001 - val_loss: 3686.0159\n",
      "Epoch 87/100\n",
      " - 1s - loss: 123.0383 - val_loss: 3677.1485\n",
      "Epoch 88/100\n",
      " - 1s - loss: 122.8167 - val_loss: 3668.8536\n",
      "Epoch 89/100\n",
      " - 1s - loss: 122.6133 - val_loss: 3661.3768\n",
      "Epoch 90/100\n",
      " - 1s - loss: 122.4228 - val_loss: 3652.6841\n",
      "Epoch 91/100\n",
      " - 1s - loss: 122.2337 - val_loss: 3644.2713\n",
      "Epoch 92/100\n",
      " - 1s - loss: 122.0788 - val_loss: 3638.0567\n",
      "Epoch 93/100\n",
      " - 1s - loss: 121.9405 - val_loss: 3630.7181\n",
      "Epoch 94/100\n",
      " - 1s - loss: 121.8003 - val_loss: 3623.5202\n",
      "Epoch 95/100\n",
      " - 1s - loss: 121.6809 - val_loss: 3616.8607\n",
      "Epoch 96/100\n",
      " - 1s - loss: 121.5841 - val_loss: 3611.3512\n",
      "Epoch 97/100\n",
      " - 1s - loss: 121.4954 - val_loss: 3605.4917\n",
      "Epoch 98/100\n",
      " - 1s - loss: 121.4178 - val_loss: 3600.0692\n",
      "Epoch 99/100\n",
      " - 1s - loss: 121.3353 - val_loss: 3594.0333\n",
      "Epoch 100/100\n",
      " - 1s - loss: 106.2195 - val_loss: 3573.9922\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, softmax & adam\n",
    "checkpointer = ModelCheckpoint(filepath=\"tns/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    tns_model = Sequential()\n",
    "    # Build network\n",
    "    tns_model.add(Dense(130, input_dim = tns_X_train.shape[1], activation='relu')) # Hidden 1\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(30, activation='softmax')) # Hidden 3\n",
    "    tns_model.add(Dense(1)) # Output\n",
    "\n",
    "    tns_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    tns_model.fit(tns_X_train, tns_y_train, validation_data = (tns_X_test, tns_y_test), callbacks=[monitor, checkpointer], \n",
    "                  verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid, softmax & adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 59.782875475843554\n",
      "R2 score -3.649891853911912\n",
      "MSE::  3573.9922001602167\n"
     ]
    }
   ],
   "source": [
    "tns_model.load_weights('tns/weights.hdf5')\n",
    "tns_pred = tns_model.predict(tns_X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(tns_y_test, tns_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(tns_y_test, tns_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(tns_y_test, tns_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 156.5364 - val_loss: 3607.0677\n",
      "Epoch 2/100\n",
      " - 1s - loss: 121.0755 - val_loss: 3557.9811\n",
      "Epoch 3/100\n",
      " - 1s - loss: 119.5348 - val_loss: 3419.9210\n",
      "Epoch 4/100\n",
      " - 1s - loss: 61.8178 - val_loss: 2647.6000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 34.5038 - val_loss: 2324.4097\n",
      "Epoch 6/100\n",
      " - 1s - loss: 22.0005 - val_loss: 2100.1373\n",
      "Epoch 7/100\n",
      " - 1s - loss: 16.9141 - val_loss: 1960.0131\n",
      "Epoch 8/100\n",
      " - 1s - loss: 15.5890 - val_loss: 1868.2249\n",
      "Epoch 9/100\n",
      " - 1s - loss: 86.6651 - val_loss: 3508.2941\n",
      "Epoch 10/100\n",
      " - 1s - loss: 120.9889 - val_loss: 3563.0284\n",
      "Epoch 11/100\n",
      " - 1s - loss: 121.0123 - val_loss: 3564.1775\n",
      "Epoch 12/100\n",
      " - 1s - loss: 120.9958 - val_loss: 3547.7823\n",
      "Epoch 13/100\n",
      " - 1s - loss: 120.9776 - val_loss: 3495.6256\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 156.8081 - val_loss: 3552.8506\n",
      "Epoch 2/100\n",
      " - 1s - loss: 121.0267 - val_loss: 3553.0899\n",
      "Epoch 3/100\n",
      " - 1s - loss: 120.9544 - val_loss: 3571.0961\n",
      "Epoch 4/100\n",
      " - 1s - loss: 105.2608 - val_loss: 3044.4342\n",
      "Epoch 5/100\n",
      " - 1s - loss: 48.3790 - val_loss: 2528.4573\n",
      "Epoch 6/100\n",
      " - 1s - loss: 29.3112 - val_loss: 2225.0114\n",
      "Epoch 7/100\n",
      " - 1s - loss: 19.6102 - val_loss: 2046.5296\n",
      "Epoch 8/100\n",
      " - 1s - loss: 125.6449 - val_loss: 3601.2883\n",
      "Epoch 9/100\n",
      " - 1s - loss: 121.0578 - val_loss: 3559.4655\n",
      "Epoch 10/100\n",
      " - 1s - loss: 121.0160 - val_loss: 3540.4845\n",
      "Epoch 11/100\n",
      " - 1s - loss: 121.0049 - val_loss: 3529.3231\n",
      "Epoch 12/100\n",
      " - 1s - loss: 120.9047 - val_loss: 3589.9649\n",
      "Epoch 00012: early stopping\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 160.5565 - val_loss: 3608.8923\n",
      "Epoch 2/100\n",
      " - 1s - loss: 120.8686 - val_loss: 3476.6871\n",
      "Epoch 3/100\n",
      " - 1s - loss: 71.0845 - val_loss: 2730.0445\n",
      "Epoch 4/100\n",
      " - 1s - loss: 36.9118 - val_loss: 2333.7505\n",
      "Epoch 5/100\n",
      " - 1s - loss: 23.6134 - val_loss: 2108.3710\n",
      "Epoch 6/100\n",
      " - 1s - loss: 17.7329 - val_loss: 1970.8522\n",
      "Epoch 7/100\n",
      " - 1s - loss: 14.9720 - val_loss: 1880.8355\n",
      "Epoch 8/100\n",
      " - 1s - loss: 17.7844 - val_loss: 1812.0849\n",
      "Epoch 9/100\n",
      " - 1s - loss: 15.0092 - val_loss: 1789.0912\n",
      "Epoch 10/100\n",
      " - 1s - loss: 127.4964 - val_loss: 3444.2430\n",
      "Epoch 11/100\n",
      " - 1s - loss: 121.0423 - val_loss: 3524.9593\n",
      "Epoch 12/100\n",
      " - 1s - loss: 120.9440 - val_loss: 3554.2990\n",
      "Epoch 13/100\n",
      " - 1s - loss: 121.0136 - val_loss: 3577.8798\n",
      "Epoch 14/100\n",
      " - 1s - loss: 120.9867 - val_loss: 3552.4527\n",
      "Epoch 00014: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 162.0221 - val_loss: 3615.5431\n",
      "Epoch 2/100\n",
      " - 1s - loss: 117.7183 - val_loss: 3376.6281\n",
      "Epoch 3/100\n",
      " - 1s - loss: 62.2724 - val_loss: 2632.6686\n",
      "Epoch 4/100\n",
      " - 1s - loss: 33.9500 - val_loss: 2303.0156\n",
      "Epoch 5/100\n",
      " - 1s - loss: 21.5593 - val_loss: 2084.7671\n",
      "Epoch 6/100\n",
      " - 1s - loss: 19.6285 - val_loss: 1958.0871\n",
      "Epoch 7/100\n",
      " - 1s - loss: 15.8607 - val_loss: 1866.6642\n",
      "Epoch 8/100\n",
      " - 1s - loss: 15.4884 - val_loss: 1810.6088\n",
      "Epoch 9/100\n",
      " - 1s - loss: 17.3264 - val_loss: 1775.2357\n",
      "Epoch 10/100\n",
      " - 1s - loss: 13.7814 - val_loss: 1757.8967\n",
      "Epoch 11/100\n",
      " - 1s - loss: 12.5650 - val_loss: 1738.1546\n",
      "Epoch 12/100\n",
      " - 1s - loss: 13.4175 - val_loss: 1724.7015\n",
      "Epoch 13/100\n",
      " - 1s - loss: 7.5555 - val_loss: 1702.6081\n",
      "Epoch 14/100\n",
      " - 1s - loss: 5.9044 - val_loss: 1656.1314\n",
      "Epoch 15/100\n",
      " - 1s - loss: 3.3893 - val_loss: 1621.8865\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.8380 - val_loss: 1589.5659\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.5266 - val_loss: 1561.2669\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.2031 - val_loss: 1536.7027\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.0135 - val_loss: 1515.4391\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.8383 - val_loss: 1497.6965\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.5125 - val_loss: 1480.3590\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.6067 - val_loss: 1465.2994\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.5340 - val_loss: 1453.1963\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.3976 - val_loss: 1445.5682\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.0791 - val_loss: 1431.2738\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.6360 - val_loss: 1423.2155\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.4546 - val_loss: 1416.1956\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.0474 - val_loss: 1406.9389\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.1068 - val_loss: 1404.8578\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.6364 - val_loss: 1396.5826\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.8897 - val_loss: 1393.1864\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.9148 - val_loss: 1388.9185\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.0743 - val_loss: 1383.2973\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.7873 - val_loss: 1375.4151\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.8856 - val_loss: 1398.3303\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.9922 - val_loss: 1366.3147\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.7150 - val_loss: 1361.5037\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.7245 - val_loss: 1356.3735\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.6729 - val_loss: 1352.5578\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.6701 - val_loss: 1348.3995\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.6004 - val_loss: 1345.8045\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.6532 - val_loss: 1341.4435\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5981 - val_loss: 1339.1281\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5298 - val_loss: 1335.6631\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5410 - val_loss: 1334.8815\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5351 - val_loss: 1331.7934\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4983 - val_loss: 1329.5039\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5108 - val_loss: 1328.1607\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5279 - val_loss: 1326.2905\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4807 - val_loss: 1323.7251\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4561 - val_loss: 1329.8552\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5689 - val_loss: 1320.9170\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4298 - val_loss: 1320.9468\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4615 - val_loss: 1317.7720\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.4226 - val_loss: 1315.1908\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4110 - val_loss: 1314.2288\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4651 - val_loss: 1312.8961\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3909 - val_loss: 1311.4309\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3575 - val_loss: 1310.3408\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3834 - val_loss: 1307.9082\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3705 - val_loss: 1307.3679\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3687 - val_loss: 1305.6484\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3908 - val_loss: 1305.0014\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3594 - val_loss: 1303.6747\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3653 - val_loss: 1302.4971\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3468 - val_loss: 1302.4637\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3555 - val_loss: 1298.7439\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3361 - val_loss: 1298.1065\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3607 - val_loss: 1297.8718\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3439 - val_loss: 1298.7112\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3953 - val_loss: 1296.2715\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3406 - val_loss: 1300.0017\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3341 - val_loss: 1295.0690\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3445 - val_loss: 1294.9852\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3506 - val_loss: 1294.0291\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3457 - val_loss: 1292.8239\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3452 - val_loss: 1291.7063\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3466 - val_loss: 1290.6418\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3158 - val_loss: 1290.2803\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3186 - val_loss: 1289.5605\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3016 - val_loss: 1289.9602\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3291 - val_loss: 1290.9137\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3394 - val_loss: 1289.6727\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3283 - val_loss: 1288.5376\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3083 - val_loss: 1285.9124\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3893 - val_loss: 1287.3070\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3035 - val_loss: 1287.4675\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3558 - val_loss: 1285.1873\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3012 - val_loss: 1287.9332\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3127 - val_loss: 1284.0936\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2961 - val_loss: 1283.6230\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2875 - val_loss: 1282.6494\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2824 - val_loss: 1282.0304\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2791 - val_loss: 1281.2949\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2796 - val_loss: 1281.7296\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2813 - val_loss: 1281.4536\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2990 - val_loss: 1280.9064\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3020 - val_loss: 1279.9960\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2794 - val_loss: 1281.3494\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2643 - val_loss: 1278.7198\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 156.0275 - val_loss: 3537.6434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      " - 1s - loss: 115.1418 - val_loss: 3239.2797\n",
      "Epoch 3/100\n",
      " - 1s - loss: 56.6168 - val_loss: 2559.6910\n",
      "Epoch 4/100\n",
      " - 1s - loss: 33.3745 - val_loss: 2315.6147\n",
      "Epoch 5/100\n",
      " - 1s - loss: 23.4958 - val_loss: 2126.7769\n",
      "Epoch 6/100\n",
      " - 1s - loss: 16.8123 - val_loss: 2229.3616\n",
      "Epoch 7/100\n",
      " - 1s - loss: 16.5518 - val_loss: 1878.9864\n",
      "Epoch 8/100\n",
      " - 1s - loss: 14.5530 - val_loss: 1827.6616\n",
      "Epoch 9/100\n",
      " - 1s - loss: 16.5670 - val_loss: 1785.8865\n",
      "Epoch 10/100\n",
      " - 1s - loss: 9.2995 - val_loss: 1747.9872\n",
      "Epoch 11/100\n",
      " - 1s - loss: 6.4612 - val_loss: 1701.0964\n",
      "Epoch 12/100\n",
      " - 1s - loss: 5.5044 - val_loss: 1662.4629\n",
      "Epoch 13/100\n",
      " - 1s - loss: 4.0758 - val_loss: 1621.0252\n",
      "Epoch 14/100\n",
      " - 1s - loss: 3.5173 - val_loss: 1591.8485\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.8099 - val_loss: 1562.7738\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.5371 - val_loss: 1581.9246\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.6075 - val_loss: 1522.8858\n",
      "Epoch 18/100\n",
      " - 1s - loss: 3.0335 - val_loss: 1502.7640\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.9052 - val_loss: 1496.0081\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.1883 - val_loss: 2774.7257\n",
      "Epoch 21/100\n",
      " - 1s - loss: 5.6105 - val_loss: 1478.4644\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.8045 - val_loss: 1462.2589\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.6866 - val_loss: 1449.7978\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.5059 - val_loss: 1437.3782\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.8841 - val_loss: 1430.3214\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.4611 - val_loss: 1421.6889\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.2835 - val_loss: 1412.4932\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.1076 - val_loss: 1406.5069\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.0905 - val_loss: 1405.0499\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.0896 - val_loss: 1400.0512\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.8857 - val_loss: 1384.9029\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.7765 - val_loss: 1379.1481\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.7509 - val_loss: 1375.0695\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.7846 - val_loss: 1370.3315\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.7034 - val_loss: 1366.9516\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.0641 - val_loss: 1367.6731\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.7387 - val_loss: 1368.0705\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.6140 - val_loss: 1359.4848\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.6507 - val_loss: 1354.9749\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.6213 - val_loss: 1352.1690\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5791 - val_loss: 1347.8006\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.6095 - val_loss: 1345.1139\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.6171 - val_loss: 1346.4680\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.6410 - val_loss: 1345.2669\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.6643 - val_loss: 1340.5342\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5554 - val_loss: 1338.0619\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4526 - val_loss: 1393.5864\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.6717 - val_loss: 1337.8224\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4640 - val_loss: 1335.6088\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4503 - val_loss: 1332.6728\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4581 - val_loss: 1331.7874\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.4863 - val_loss: 1329.5785\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4403 - val_loss: 1327.9404\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5416 - val_loss: 1326.9257\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.4570 - val_loss: 1325.2581\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4095 - val_loss: 1323.5069\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4504 - val_loss: 1323.0595\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4364 - val_loss: 1320.5753\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4144 - val_loss: 1318.9431\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4316 - val_loss: 1317.7367\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3884 - val_loss: 1317.0363\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3736 - val_loss: 1316.2333\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4299 - val_loss: 1314.7516\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3768 - val_loss: 1313.0364\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4004 - val_loss: 1311.6716\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3846 - val_loss: 1311.8568\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3877 - val_loss: 1311.1446\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3634 - val_loss: 1307.9452\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3694 - val_loss: 1306.7482\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3604 - val_loss: 1305.7744\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3663 - val_loss: 1306.2107\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3367 - val_loss: 1306.2897\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3355 - val_loss: 1304.0820\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3384 - val_loss: 1303.8398\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3496 - val_loss: 1301.6595\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3382 - val_loss: 1300.9432\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3167 - val_loss: 1300.8620\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3443 - val_loss: 1332.9822\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.5416 - val_loss: 1302.3225\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3333 - val_loss: 1309.8429\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3926 - val_loss: 1300.9216\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3360 - val_loss: 1301.3685\n",
      "Epoch 00082: early stopping\n"
     ]
    }
   ],
   "source": [
    "# tanh, sigmoid, softmax & sgd\n",
    "checkpointer = ModelCheckpoint(filepath=\"tns/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    tns_model = Sequential()\n",
    "    # Build network\n",
    "    tns_model.add(Dense(130, input_dim = tns_X_train.shape[1], activation='tanh')) # Hidden 1\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(30, activation='softmax')) # Hidden 3\n",
    "    tns_model.add(Dense(1)) # Output\n",
    "\n",
    "    tns_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    tns_model.fit(tns_X_train, tns_y_train, validation_data = (tns_X_test, tns_y_test), callbacks=[monitor, checkpointer], \n",
    "                  verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for tanh, sigmoid, softmax & sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35.75919099817196\n",
      "R2 score -0.6636601798177184\n",
      "MSE::  1278.7197408437423\n"
     ]
    }
   ],
   "source": [
    "tns_model.load_weights('tns/weights.hdf5')\n",
    "tns_pred = tns_model.predict(tns_X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(tns_y_test, tns_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(tns_y_test, tns_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(tns_y_test, tns_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 328.9407 - val_loss: 5219.6906\n",
      "Epoch 2/100\n",
      " - 1s - loss: 320.2944 - val_loss: 5193.8567\n",
      "Epoch 3/100\n",
      " - 1s - loss: 314.9112 - val_loss: 5168.2764\n",
      "Epoch 4/100\n",
      " - 1s - loss: 309.6021 - val_loss: 5142.8647\n",
      "Epoch 5/100\n",
      " - 1s - loss: 304.3934 - val_loss: 5117.9651\n",
      "Epoch 6/100\n",
      " - 1s - loss: 299.2541 - val_loss: 5092.7563\n",
      "Epoch 7/100\n",
      " - 1s - loss: 294.1634 - val_loss: 5067.6091\n",
      "Epoch 8/100\n",
      " - 1s - loss: 289.1578 - val_loss: 5042.2657\n",
      "Epoch 9/100\n",
      " - 1s - loss: 284.2740 - val_loss: 5017.5134\n",
      "Epoch 10/100\n",
      " - 1s - loss: 279.3855 - val_loss: 4992.7327\n",
      "Epoch 11/100\n",
      " - 1s - loss: 274.6165 - val_loss: 4967.9286\n",
      "Epoch 12/100\n",
      " - 1s - loss: 269.9134 - val_loss: 4943.1297\n",
      "Epoch 13/100\n",
      " - 1s - loss: 265.2710 - val_loss: 4918.4473\n",
      "Epoch 14/100\n",
      " - 1s - loss: 260.7024 - val_loss: 4893.9029\n",
      "Epoch 15/100\n",
      " - 1s - loss: 256.2236 - val_loss: 4869.4953\n",
      "Epoch 16/100\n",
      " - 1s - loss: 251.8511 - val_loss: 4845.0108\n",
      "Epoch 17/100\n",
      " - 1s - loss: 247.5665 - val_loss: 4821.0637\n",
      "Epoch 18/100\n",
      " - 1s - loss: 243.3009 - val_loss: 4796.4832\n",
      "Epoch 19/100\n",
      " - 1s - loss: 239.1292 - val_loss: 4772.4530\n",
      "Epoch 20/100\n",
      " - 1s - loss: 235.0490 - val_loss: 4748.7465\n",
      "Epoch 21/100\n",
      " - 1s - loss: 231.0018 - val_loss: 4724.8375\n",
      "Epoch 22/100\n",
      " - 1s - loss: 227.0602 - val_loss: 4700.6333\n",
      "Epoch 23/100\n",
      " - 1s - loss: 223.1856 - val_loss: 4676.9390\n",
      "Epoch 24/100\n",
      " - 1s - loss: 219.3874 - val_loss: 4653.5504\n",
      "Epoch 25/100\n",
      " - 1s - loss: 215.6882 - val_loss: 4629.8614\n",
      "Epoch 26/100\n",
      " - 1s - loss: 212.0009 - val_loss: 4606.2813\n",
      "Epoch 27/100\n",
      " - 1s - loss: 208.3621 - val_loss: 4582.6861\n",
      "Epoch 28/100\n",
      " - 1s - loss: 204.9274 - val_loss: 4559.5197\n",
      "Epoch 29/100\n",
      " - 1s - loss: 201.4404 - val_loss: 4535.8705\n",
      "Epoch 30/100\n",
      " - 1s - loss: 198.1230 - val_loss: 4513.2958\n",
      "Epoch 31/100\n",
      " - 1s - loss: 194.8224 - val_loss: 4490.2178\n",
      "Epoch 32/100\n",
      " - 1s - loss: 191.6143 - val_loss: 4467.2469\n",
      "Epoch 33/100\n",
      " - 1s - loss: 188.5045 - val_loss: 4444.6436\n",
      "Epoch 34/100\n",
      " - 1s - loss: 185.4860 - val_loss: 4422.1323\n",
      "Epoch 35/100\n",
      " - 1s - loss: 182.5359 - val_loss: 4399.6169\n",
      "Epoch 36/100\n",
      " - 1s - loss: 179.5833 - val_loss: 4376.6264\n",
      "Epoch 37/100\n",
      " - 1s - loss: 176.7948 - val_loss: 4354.7623\n",
      "Epoch 38/100\n",
      " - 1s - loss: 174.0137 - val_loss: 4332.2963\n",
      "Epoch 39/100\n",
      " - 1s - loss: 171.3733 - val_loss: 4310.4564\n",
      "Epoch 40/100\n",
      " - 1s - loss: 168.8020 - val_loss: 4288.4086\n",
      "Epoch 41/100\n",
      " - 1s - loss: 166.2759 - val_loss: 4266.7490\n",
      "Epoch 42/100\n",
      " - 1s - loss: 163.8119 - val_loss: 4244.6681\n",
      "Epoch 43/100\n",
      " - 1s - loss: 161.3902 - val_loss: 4222.9683\n",
      "Epoch 44/100\n",
      " - 1s - loss: 159.1273 - val_loss: 4201.1691\n",
      "Epoch 45/100\n",
      " - 1s - loss: 156.9301 - val_loss: 4180.6606\n",
      "Epoch 46/100\n",
      " - 1s - loss: 154.7704 - val_loss: 4159.1198\n",
      "Epoch 47/100\n",
      " - 1s - loss: 152.6343 - val_loss: 4138.0599\n",
      "Epoch 48/100\n",
      " - 1s - loss: 150.6402 - val_loss: 4116.7989\n",
      "Epoch 49/100\n",
      " - 1s - loss: 148.6915 - val_loss: 4096.1808\n",
      "Epoch 50/100\n",
      " - 1s - loss: 146.8248 - val_loss: 4075.1781\n",
      "Epoch 51/100\n",
      " - 1s - loss: 145.0411 - val_loss: 4054.3424\n",
      "Epoch 52/100\n",
      " - 1s - loss: 143.3284 - val_loss: 4035.5238\n",
      "Epoch 53/100\n",
      " - 1s - loss: 141.7567 - val_loss: 4015.0609\n",
      "Epoch 54/100\n",
      " - 1s - loss: 140.1508 - val_loss: 3994.6404\n",
      "Epoch 55/100\n",
      " - 1s - loss: 138.6713 - val_loss: 3976.0363\n",
      "Epoch 56/100\n",
      " - 1s - loss: 137.2975 - val_loss: 3956.9964\n",
      "Epoch 57/100\n",
      " - 1s - loss: 135.9219 - val_loss: 3937.3424\n",
      "Epoch 58/100\n",
      " - 1s - loss: 134.5920 - val_loss: 3917.9621\n",
      "Epoch 59/100\n",
      " - 1s - loss: 133.3704 - val_loss: 3899.4927\n",
      "Epoch 60/100\n",
      " - 1s - loss: 132.2344 - val_loss: 3880.6641\n",
      "Epoch 61/100\n",
      " - 1s - loss: 131.1592 - val_loss: 3862.2697\n",
      "Epoch 62/100\n",
      " - 1s - loss: 130.1587 - val_loss: 3845.8279\n",
      "Epoch 63/100\n",
      " - 1s - loss: 129.2909 - val_loss: 3828.6388\n",
      "Epoch 64/100\n",
      " - 1s - loss: 128.4176 - val_loss: 3812.8779\n",
      "Epoch 65/100\n",
      " - 1s - loss: 127.6088 - val_loss: 3795.6328\n",
      "Epoch 66/100\n",
      " - 1s - loss: 126.8334 - val_loss: 3778.6264\n",
      "Epoch 67/100\n",
      " - 1s - loss: 126.1299 - val_loss: 3763.7177\n",
      "Epoch 68/100\n",
      " - 1s - loss: 125.5505 - val_loss: 3748.6592\n",
      "Epoch 69/100\n",
      " - 1s - loss: 124.9707 - val_loss: 3734.2183\n",
      "Epoch 70/100\n",
      " - 1s - loss: 124.4602 - val_loss: 3719.6362\n",
      "Epoch 71/100\n",
      " - 1s - loss: 123.9874 - val_loss: 3705.7799\n",
      "Epoch 72/100\n",
      " - 1s - loss: 123.5381 - val_loss: 3692.3142\n",
      "Epoch 73/100\n",
      " - 1s - loss: 123.1669 - val_loss: 3680.4660\n",
      "Epoch 74/100\n",
      " - 1s - loss: 122.8623 - val_loss: 3669.3561\n",
      "Epoch 75/100\n",
      " - 1s - loss: 122.5803 - val_loss: 3657.5676\n",
      "Epoch 76/100\n",
      " - 1s - loss: 122.3275 - val_loss: 3647.5278\n",
      "Epoch 77/100\n",
      " - 1s - loss: 122.1062 - val_loss: 3638.1711\n",
      "Epoch 78/100\n",
      " - 1s - loss: 121.9478 - val_loss: 3631.0663\n",
      "Epoch 79/100\n",
      " - 1s - loss: 121.7980 - val_loss: 3622.4980\n",
      "Epoch 80/100\n",
      " - 1s - loss: 121.6519 - val_loss: 3614.6200\n",
      "Epoch 81/100\n",
      " - 1s - loss: 121.5443 - val_loss: 3607.4702\n",
      "Epoch 82/100\n",
      " - 1s - loss: 121.4387 - val_loss: 3601.6269\n",
      "Epoch 83/100\n",
      " - 1s - loss: 121.3608 - val_loss: 3595.4205\n",
      "Epoch 84/100\n",
      " - 1s - loss: 121.2818 - val_loss: 3589.7066\n",
      "Epoch 85/100\n",
      " - 1s - loss: 121.2217 - val_loss: 3584.5023\n",
      "Epoch 86/100\n",
      " - 1s - loss: 121.1693 - val_loss: 3580.1234\n",
      "Epoch 87/100\n",
      " - 1s - loss: 121.1274 - val_loss: 3576.3666\n",
      "Epoch 88/100\n",
      " - 1s - loss: 121.0931 - val_loss: 3571.6944\n",
      "Epoch 89/100\n",
      " - 1s - loss: 121.0570 - val_loss: 3567.4321\n",
      "Epoch 90/100\n",
      " - 1s - loss: 121.0225 - val_loss: 3564.0953\n",
      "Epoch 91/100\n",
      " - 1s - loss: 121.0007 - val_loss: 3561.1971\n",
      "Epoch 92/100\n",
      " - 1s - loss: 120.9817 - val_loss: 3558.4369\n",
      "Epoch 93/100\n",
      " - 1s - loss: 120.9668 - val_loss: 3556.0784\n",
      "Epoch 94/100\n",
      " - 1s - loss: 120.9537 - val_loss: 3552.8881\n",
      "Epoch 95/100\n",
      " - 1s - loss: 120.9380 - val_loss: 3552.0011\n",
      "Epoch 96/100\n",
      " - 1s - loss: 120.9320 - val_loss: 3548.9081\n",
      "Epoch 97/100\n",
      " - 1s - loss: 120.9184 - val_loss: 3546.8288\n",
      "Epoch 98/100\n",
      " - 1s - loss: 120.9133 - val_loss: 3545.4724\n",
      "Epoch 99/100\n",
      " - 1s - loss: 120.9074 - val_loss: 3545.4677\n",
      "Epoch 100/100\n",
      " - 1s - loss: 120.9083 - val_loss: 3543.8988\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 329.4199 - val_loss: 5222.5886\n",
      "Epoch 2/100\n",
      " - 1s - loss: 320.9284 - val_loss: 5196.8172\n",
      "Epoch 3/100\n",
      " - 1s - loss: 315.4823 - val_loss: 5171.3335\n",
      "Epoch 4/100\n",
      " - 1s - loss: 310.2180 - val_loss: 5146.1842\n",
      "Epoch 5/100\n",
      " - 1s - loss: 305.0112 - val_loss: 5120.6877\n",
      "Epoch 6/100\n",
      " - 1s - loss: 299.8278 - val_loss: 5095.2523\n",
      "Epoch 7/100\n",
      " - 1s - loss: 294.7282 - val_loss: 5070.4299\n",
      "Epoch 8/100\n",
      " - 1s - loss: 289.7261 - val_loss: 5045.0930\n",
      "Epoch 9/100\n",
      " - 1s - loss: 284.7648 - val_loss: 5020.2965\n",
      "Epoch 10/100\n",
      " - 1s - loss: 279.9434 - val_loss: 4995.5953\n",
      "Epoch 11/100\n",
      " - 1s - loss: 275.1340 - val_loss: 4970.6633\n",
      "Epoch 12/100\n",
      " - 1s - loss: 270.4304 - val_loss: 4945.9594\n",
      "Epoch 13/100\n",
      " - 1s - loss: 265.7896 - val_loss: 4921.1981\n",
      "Epoch 14/100\n",
      " - 1s - loss: 261.2229 - val_loss: 4896.6083\n",
      "Epoch 15/100\n",
      " - 1s - loss: 256.7493 - val_loss: 4872.2265\n",
      "Epoch 16/100\n",
      " - 1s - loss: 252.3325 - val_loss: 4847.7531\n",
      "Epoch 17/100\n",
      " - 1s - loss: 247.9827 - val_loss: 4823.2728\n",
      "Epoch 18/100\n",
      " - 1s - loss: 243.7197 - val_loss: 4799.1720\n",
      "Epoch 19/100\n",
      " - 1s - loss: 239.5740 - val_loss: 4775.0037\n",
      "Epoch 20/100\n",
      " - 1s - loss: 235.4445 - val_loss: 4751.1258\n",
      "Epoch 21/100\n",
      " - 1s - loss: 231.3992 - val_loss: 4726.7180\n",
      "Epoch 22/100\n",
      " - 1s - loss: 227.4581 - val_loss: 4703.1606\n",
      "Epoch 23/100\n",
      " - 1s - loss: 223.5312 - val_loss: 4678.9387\n",
      "Epoch 24/100\n",
      " - 1s - loss: 219.7471 - val_loss: 4655.7796\n",
      "Epoch 25/100\n",
      " - 1s - loss: 216.0043 - val_loss: 4632.1361\n",
      "Epoch 26/100\n",
      " - 1s - loss: 212.3387 - val_loss: 4608.4022\n",
      "Epoch 27/100\n",
      " - 1s - loss: 208.7308 - val_loss: 4584.9926\n",
      "Epoch 28/100\n",
      " - 1s - loss: 205.2475 - val_loss: 4561.8679\n",
      "Epoch 29/100\n",
      " - 1s - loss: 201.8116 - val_loss: 4538.7003\n",
      "Epoch 30/100\n",
      " - 1s - loss: 198.4869 - val_loss: 4515.6912\n",
      "Epoch 31/100\n",
      " - 1s - loss: 195.1646 - val_loss: 4492.2657\n",
      "Epoch 32/100\n",
      " - 1s - loss: 192.0300 - val_loss: 4470.2610\n",
      "Epoch 33/100\n",
      " - 1s - loss: 188.8856 - val_loss: 4447.1463\n",
      "Epoch 34/100\n",
      " - 1s - loss: 185.8109 - val_loss: 4424.4541\n",
      "Epoch 35/100\n",
      " - 1s - loss: 182.7872 - val_loss: 4401.2655\n",
      "Epoch 36/100\n",
      " - 1s - loss: 179.8976 - val_loss: 4379.1462\n",
      "Epoch 37/100\n",
      " - 1s - loss: 177.0355 - val_loss: 4356.7199\n",
      "Epoch 38/100\n",
      " - 1s - loss: 174.2878 - val_loss: 4334.3222\n",
      "Epoch 39/100\n",
      " - 1s - loss: 171.6201 - val_loss: 4311.9878\n",
      "Epoch 40/100\n",
      " - 1s - loss: 169.0438 - val_loss: 4290.6713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      " - 1s - loss: 166.4960 - val_loss: 4268.7186\n",
      "Epoch 42/100\n",
      " - 1s - loss: 164.0536 - val_loss: 4246.6913\n",
      "Epoch 43/100\n",
      " - 1s - loss: 161.6543 - val_loss: 4225.1363\n",
      "Epoch 44/100\n",
      " - 1s - loss: 159.3187 - val_loss: 4203.9401\n",
      "Epoch 45/100\n",
      " - 1s - loss: 157.1214 - val_loss: 4182.3980\n",
      "Epoch 46/100\n",
      " - 1s - loss: 154.9424 - val_loss: 4160.5788\n",
      "Epoch 47/100\n",
      " - 1s - loss: 152.8738 - val_loss: 4139.7083\n",
      "Epoch 48/100\n",
      " - 1s - loss: 150.8775 - val_loss: 4119.2274\n",
      "Epoch 49/100\n",
      " - 1s - loss: 148.9358 - val_loss: 4098.3921\n",
      "Epoch 50/100\n",
      " - 1s - loss: 147.0683 - val_loss: 4077.8380\n",
      "Epoch 51/100\n",
      " - 1s - loss: 145.2412 - val_loss: 4056.6947\n",
      "Epoch 52/100\n",
      " - 1s - loss: 143.5297 - val_loss: 4036.4032\n",
      "Epoch 53/100\n",
      " - 1s - loss: 141.8854 - val_loss: 4017.3882\n",
      "Epoch 54/100\n",
      " - 1s - loss: 140.3205 - val_loss: 3996.9000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 138.8071 - val_loss: 3976.9659\n",
      "Epoch 56/100\n",
      " - 1s - loss: 137.3489 - val_loss: 3957.2399\n",
      "Epoch 57/100\n",
      " - 1s - loss: 135.9608 - val_loss: 3937.8564\n",
      "Epoch 58/100\n",
      " - 1s - loss: 134.6756 - val_loss: 3919.4416\n",
      "Epoch 59/100\n",
      " - 1s - loss: 133.4760 - val_loss: 3899.9605\n",
      "Epoch 60/100\n",
      " - 1s - loss: 132.3043 - val_loss: 3882.3471\n",
      "Epoch 61/100\n",
      " - 1s - loss: 131.2411 - val_loss: 3864.5535\n",
      "Epoch 62/100\n",
      " - 1s - loss: 130.2395 - val_loss: 3846.5027\n",
      "Epoch 63/100\n",
      " - 1s - loss: 129.2957 - val_loss: 3829.1017\n",
      "Epoch 64/100\n",
      " - 1s - loss: 128.4030 - val_loss: 3812.1533\n",
      "Epoch 65/100\n",
      " - 1s - loss: 127.5925 - val_loss: 3794.8815\n",
      "Epoch 66/100\n",
      " - 1s - loss: 126.8647 - val_loss: 3780.4945\n",
      "Epoch 67/100\n",
      " - 1s - loss: 126.1868 - val_loss: 3764.1009\n",
      "Epoch 68/100\n",
      " - 1s - loss: 125.5550 - val_loss: 3748.8209\n",
      "Epoch 69/100\n",
      " - 1s - loss: 125.0110 - val_loss: 3734.7906\n",
      "Epoch 70/100\n",
      " - 1s - loss: 124.4820 - val_loss: 3719.7341\n",
      "Epoch 71/100\n",
      " - 1s - loss: 124.0347 - val_loss: 3707.5065\n",
      "Epoch 72/100\n",
      " - 1s - loss: 123.6122 - val_loss: 3694.2012\n",
      "Epoch 73/100\n",
      " - 1s - loss: 123.2290 - val_loss: 3682.2589\n",
      "Epoch 74/100\n",
      " - 1s - loss: 122.8929 - val_loss: 3670.4459\n",
      "Epoch 75/100\n",
      " - 1s - loss: 122.6006 - val_loss: 3658.3091\n",
      "Epoch 76/100\n",
      " - 1s - loss: 122.3366 - val_loss: 3648.7046\n",
      "Epoch 77/100\n",
      " - 1s - loss: 122.1302 - val_loss: 3639.4381\n",
      "Epoch 78/100\n",
      " - 1s - loss: 121.9524 - val_loss: 3630.8790\n",
      "Epoch 79/100\n",
      " - 1s - loss: 121.7858 - val_loss: 3622.0411\n",
      "Epoch 80/100\n",
      " - 1s - loss: 121.6511 - val_loss: 3614.9497\n",
      "Epoch 81/100\n",
      " - 1s - loss: 121.5416 - val_loss: 3608.0700\n",
      "Epoch 82/100\n",
      " - 1s - loss: 121.4452 - val_loss: 3601.6714\n",
      "Epoch 83/100\n",
      " - 1s - loss: 121.3566 - val_loss: 3595.5373\n",
      "Epoch 84/100\n",
      " - 1s - loss: 121.2896 - val_loss: 3590.5294\n",
      "Epoch 85/100\n",
      " - 1s - loss: 121.2288 - val_loss: 3584.7815\n",
      "Epoch 86/100\n",
      " - 1s - loss: 121.1691 - val_loss: 3579.3209\n",
      "Epoch 87/100\n",
      " - 1s - loss: 121.1204 - val_loss: 3574.4907\n",
      "Epoch 88/100\n",
      " - 1s - loss: 121.0788 - val_loss: 3570.9573\n",
      "Epoch 89/100\n",
      " - 1s - loss: 121.0537 - val_loss: 3568.2676\n",
      "Epoch 90/100\n",
      " - 1s - loss: 121.0336 - val_loss: 3565.9276\n",
      "Epoch 91/100\n",
      " - 1s - loss: 121.0101 - val_loss: 3562.2198\n",
      "Epoch 92/100\n",
      " - 1s - loss: 120.9880 - val_loss: 3559.3574\n",
      "Epoch 93/100\n",
      " - 1s - loss: 120.9708 - val_loss: 3556.1009\n",
      "Epoch 94/100\n",
      " - 1s - loss: 120.9519 - val_loss: 3553.0416\n",
      "Epoch 95/100\n",
      " - 1s - loss: 120.9384 - val_loss: 3550.5164\n",
      "Epoch 96/100\n",
      " - 1s - loss: 120.9278 - val_loss: 3547.8290\n",
      "Epoch 97/100\n",
      " - 1s - loss: 120.9177 - val_loss: 3546.4170\n",
      "Epoch 98/100\n",
      " - 1s - loss: 120.9118 - val_loss: 3545.0468\n",
      "Epoch 99/100\n",
      " - 1s - loss: 120.9064 - val_loss: 3544.1155\n",
      "Epoch 100/100\n",
      " - 1s - loss: 120.9048 - val_loss: 3542.9857\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 329.1890 - val_loss: 5220.2823\n",
      "Epoch 2/100\n",
      " - 1s - loss: 319.2499 - val_loss: 5188.1378\n",
      "Epoch 3/100\n",
      " - 1s - loss: 313.7175 - val_loss: 5162.8854\n",
      "Epoch 4/100\n",
      " - 1s - loss: 308.4285 - val_loss: 5137.4722\n",
      "Epoch 5/100\n",
      " - 1s - loss: 303.2054 - val_loss: 5111.9352\n",
      "Epoch 6/100\n",
      " - 1s - loss: 298.1212 - val_loss: 5087.3839\n",
      "Epoch 7/100\n",
      " - 1s - loss: 293.0875 - val_loss: 5061.8432\n",
      "Epoch 8/100\n",
      " - 1s - loss: 288.1156 - val_loss: 5037.0382\n",
      "Epoch 9/100\n",
      " - 1s - loss: 283.1947 - val_loss: 5012.3160\n",
      "Epoch 10/100\n",
      " - 1s - loss: 278.3630 - val_loss: 4987.3205\n",
      "Epoch 11/100\n",
      " - 1s - loss: 273.6188 - val_loss: 4962.5375\n",
      "Epoch 12/100\n",
      " - 1s - loss: 268.9328 - val_loss: 4937.9563\n",
      "Epoch 13/100\n",
      " - 1s - loss: 264.3519 - val_loss: 4913.2274\n",
      "Epoch 14/100\n",
      " - 1s - loss: 259.7668 - val_loss: 4888.4830\n",
      "Epoch 15/100\n",
      " - 1s - loss: 255.3139 - val_loss: 4864.1574\n",
      "Epoch 16/100\n",
      " - 1s - loss: 250.9090 - val_loss: 4839.8708\n",
      "Epoch 17/100\n",
      " - 1s - loss: 246.6329 - val_loss: 4815.2407\n",
      "Epoch 18/100\n",
      " - 1s - loss: 242.4644 - val_loss: 4791.9203\n",
      "Epoch 19/100\n",
      " - 1s - loss: 238.3019 - val_loss: 4767.7892\n",
      "Epoch 20/100\n",
      " - 1s - loss: 234.1753 - val_loss: 4743.6374\n",
      "Epoch 21/100\n",
      " - 1s - loss: 230.1990 - val_loss: 4719.7341\n",
      "Epoch 22/100\n",
      " - 1s - loss: 226.2281 - val_loss: 4695.8104\n",
      "Epoch 23/100\n",
      " - 1s - loss: 222.4063 - val_loss: 4672.1594\n",
      "Epoch 24/100\n",
      " - 1s - loss: 218.6141 - val_loss: 4648.1425\n",
      "Epoch 25/100\n",
      " - 1s - loss: 214.9126 - val_loss: 4625.4518\n",
      "Epoch 26/100\n",
      " - 1s - loss: 211.3322 - val_loss: 4602.1576\n",
      "Epoch 27/100\n",
      " - 1s - loss: 207.7765 - val_loss: 4578.7519\n",
      "Epoch 28/100\n",
      " - 1s - loss: 204.2902 - val_loss: 4555.4801\n",
      "Epoch 29/100\n",
      " - 1s - loss: 200.8747 - val_loss: 4532.0759\n",
      "Epoch 30/100\n",
      " - 1s - loss: 197.5090 - val_loss: 4508.7200\n",
      "Epoch 31/100\n",
      " - 1s - loss: 194.3597 - val_loss: 4486.6349\n",
      "Epoch 32/100\n",
      " - 1s - loss: 191.1384 - val_loss: 4463.7131\n",
      "Epoch 33/100\n",
      " - 1s - loss: 188.0196 - val_loss: 4440.7388\n",
      "Epoch 34/100\n",
      " - 1s - loss: 184.9963 - val_loss: 4418.4800\n",
      "Epoch 35/100\n",
      " - 1s - loss: 182.0538 - val_loss: 4395.7065\n",
      "Epoch 36/100\n",
      " - 1s - loss: 179.1470 - val_loss: 4373.2622\n",
      "Epoch 37/100\n",
      " - 1s - loss: 176.3178 - val_loss: 4350.5392\n",
      "Epoch 38/100\n",
      " - 1s - loss: 173.6086 - val_loss: 4328.9315\n",
      "Epoch 39/100\n",
      " - 1s - loss: 170.9729 - val_loss: 4306.9240\n",
      "Epoch 40/100\n",
      " - 1s - loss: 168.3945 - val_loss: 4285.0345\n",
      "Epoch 41/100\n",
      " - 1s - loss: 165.8427 - val_loss: 4262.4779\n",
      "Epoch 42/100\n",
      " - 1s - loss: 163.4848 - val_loss: 4242.0781\n",
      "Epoch 43/100\n",
      " - 1s - loss: 161.1336 - val_loss: 4220.3707\n",
      "Epoch 44/100\n",
      " - 1s - loss: 158.8290 - val_loss: 4198.5691\n",
      "Epoch 45/100\n",
      " - 1s - loss: 156.5947 - val_loss: 4177.4545\n",
      "Epoch 46/100\n",
      " - 1s - loss: 154.4811 - val_loss: 4156.5254\n",
      "Epoch 47/100\n",
      " - 1s - loss: 152.3768 - val_loss: 4135.1995\n",
      "Epoch 48/100\n",
      " - 1s - loss: 150.3822 - val_loss: 4114.0632\n",
      "Epoch 49/100\n",
      " - 1s - loss: 148.4997 - val_loss: 4093.7044\n",
      "Epoch 50/100\n",
      " - 1s - loss: 146.6277 - val_loss: 4072.4603\n",
      "Epoch 51/100\n",
      " - 1s - loss: 144.8704 - val_loss: 4052.5208\n",
      "Epoch 52/100\n",
      " - 1s - loss: 143.1655 - val_loss: 4032.6006\n",
      "Epoch 53/100\n",
      " - 1s - loss: 141.5498 - val_loss: 4012.1992\n",
      "Epoch 54/100\n",
      " - 1s - loss: 139.9859 - val_loss: 3992.2628\n",
      "Epoch 55/100\n",
      " - 1s - loss: 138.4876 - val_loss: 3972.9156\n",
      "Epoch 56/100\n",
      " - 1s - loss: 137.0877 - val_loss: 3954.0854\n",
      "Epoch 57/100\n",
      " - 1s - loss: 135.7293 - val_loss: 3934.8870\n",
      "Epoch 58/100\n",
      " - 1s - loss: 134.4273 - val_loss: 3914.8763\n",
      "Epoch 59/100\n",
      " - 1s - loss: 133.2481 - val_loss: 3897.8647\n",
      "Epoch 60/100\n",
      " - 1s - loss: 132.1757 - val_loss: 3880.2632\n",
      "Epoch 61/100\n",
      " - 1s - loss: 131.1506 - val_loss: 3861.6200\n",
      "Epoch 62/100\n",
      " - 1s - loss: 130.1334 - val_loss: 3845.2253\n",
      "Epoch 63/100\n",
      " - 1s - loss: 129.2377 - val_loss: 3828.3965\n",
      "Epoch 64/100\n",
      " - 1s - loss: 128.3885 - val_loss: 3811.9783\n",
      "Epoch 65/100\n",
      " - 1s - loss: 127.6022 - val_loss: 3794.3166\n",
      "Epoch 66/100\n",
      " - 1s - loss: 126.8131 - val_loss: 3778.1826\n",
      "Epoch 67/100\n",
      " - 1s - loss: 126.1765 - val_loss: 3763.5603\n",
      "Epoch 68/100\n",
      " - 1s - loss: 125.5279 - val_loss: 3748.6044\n",
      "Epoch 69/100\n",
      " - 1s - loss: 124.9662 - val_loss: 3734.4425\n",
      "Epoch 70/100\n",
      " - 1s - loss: 124.4661 - val_loss: 3720.9014\n",
      "Epoch 71/100\n",
      " - 1s - loss: 124.0273 - val_loss: 3707.1239\n",
      "Epoch 72/100\n",
      " - 1s - loss: 123.6086 - val_loss: 3693.9124\n",
      "Epoch 73/100\n",
      " - 1s - loss: 123.2376 - val_loss: 3682.9203\n",
      "Epoch 74/100\n",
      " - 1s - loss: 122.9137 - val_loss: 3670.1089\n",
      "Epoch 75/100\n",
      " - 1s - loss: 122.6118 - val_loss: 3660.1204\n",
      "Epoch 76/100\n",
      " - 1s - loss: 122.3682 - val_loss: 3649.3905\n",
      "Epoch 77/100\n",
      " - 1s - loss: 122.1430 - val_loss: 3640.0235\n",
      "Epoch 78/100\n",
      " - 1s - loss: 121.9722 - val_loss: 3631.0858\n",
      "Epoch 79/100\n",
      " - 1s - loss: 121.8093 - val_loss: 3623.5772\n",
      "Epoch 80/100\n",
      " - 1s - loss: 121.6704 - val_loss: 3615.1061\n",
      "Epoch 81/100\n",
      " - 1s - loss: 121.5333 - val_loss: 3607.5087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      " - 1s - loss: 121.4375 - val_loss: 3601.2066\n",
      "Epoch 83/100\n",
      " - 1s - loss: 121.3502 - val_loss: 3594.8590\n",
      "Epoch 84/100\n",
      " - 1s - loss: 121.2690 - val_loss: 3588.1958\n",
      "Epoch 85/100\n",
      " - 1s - loss: 121.1959 - val_loss: 3582.0560\n",
      "Epoch 86/100\n",
      " - 1s - loss: 121.1414 - val_loss: 3576.4955\n",
      "Epoch 87/100\n",
      " - 1s - loss: 121.0962 - val_loss: 3573.1673\n",
      "Epoch 88/100\n",
      " - 1s - loss: 121.0658 - val_loss: 3568.5849\n",
      "Epoch 89/100\n",
      " - 1s - loss: 121.0303 - val_loss: 3565.0674\n",
      "Epoch 90/100\n",
      " - 1s - loss: 121.0086 - val_loss: 3561.8548\n",
      "Epoch 91/100\n",
      " - 1s - loss: 120.9869 - val_loss: 3559.1993\n",
      "Epoch 92/100\n",
      " - 1s - loss: 120.9708 - val_loss: 3556.8066\n",
      "Epoch 93/100\n",
      " - 1s - loss: 120.9554 - val_loss: 3553.8034\n",
      "Epoch 94/100\n",
      " - 1s - loss: 120.9418 - val_loss: 3551.5575\n",
      "Epoch 95/100\n",
      " - 1s - loss: 120.9328 - val_loss: 3550.2419\n",
      "Epoch 96/100\n",
      " - 1s - loss: 120.9265 - val_loss: 3548.7948\n",
      "Epoch 97/100\n",
      " - 1s - loss: 120.9211 - val_loss: 3547.3162\n",
      "Epoch 98/100\n",
      " - 1s - loss: 120.9145 - val_loss: 3545.7516\n",
      "Epoch 99/100\n",
      " - 1s - loss: 120.9091 - val_loss: 3544.5114\n",
      "Epoch 100/100\n",
      " - 1s - loss: 120.9049 - val_loss: 3543.1999\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 326.8255 - val_loss: 5210.5717\n",
      "Epoch 2/100\n",
      " - 1s - loss: 318.4113 - val_loss: 5184.8857\n",
      "Epoch 3/100\n",
      " - 1s - loss: 312.9769 - val_loss: 5159.3418\n",
      "Epoch 4/100\n",
      " - 1s - loss: 307.7551 - val_loss: 5133.8158\n",
      "Epoch 5/100\n",
      " - 1s - loss: 302.5578 - val_loss: 5109.0536\n",
      "Epoch 6/100\n",
      " - 1s - loss: 297.3669 - val_loss: 5083.5190\n",
      "Epoch 7/100\n",
      " - 1s - loss: 292.4060 - val_loss: 5058.5543\n",
      "Epoch 8/100\n",
      " - 1s - loss: 287.3715 - val_loss: 5033.5438\n",
      "Epoch 9/100\n",
      " - 1s - loss: 282.5126 - val_loss: 5008.7003\n",
      "Epoch 10/100\n",
      " - 1s - loss: 277.6916 - val_loss: 4983.6881\n",
      "Epoch 11/100\n",
      " - 1s - loss: 272.8877 - val_loss: 4958.8959\n",
      "Epoch 12/100\n",
      " - 1s - loss: 268.1958 - val_loss: 4934.2260\n",
      "Epoch 13/100\n",
      " - 1s - loss: 263.5624 - val_loss: 4909.1724\n",
      "Epoch 14/100\n",
      " - 1s - loss: 259.0706 - val_loss: 4885.1685\n",
      "Epoch 15/100\n",
      " - 1s - loss: 254.6482 - val_loss: 4860.4905\n",
      "Epoch 16/100\n",
      " - 1s - loss: 250.3056 - val_loss: 4836.1220\n",
      "Epoch 17/100\n",
      " - 1s - loss: 245.9721 - val_loss: 4812.0071\n",
      "Epoch 18/100\n",
      " - 1s - loss: 241.7599 - val_loss: 4787.8637\n",
      "Epoch 19/100\n",
      " - 1s - loss: 237.6089 - val_loss: 4763.4213\n",
      "Epoch 20/100\n",
      " - 1s - loss: 233.5681 - val_loss: 4740.0115\n",
      "Epoch 21/100\n",
      " - 1s - loss: 229.5709 - val_loss: 4715.7664\n",
      "Epoch 22/100\n",
      " - 1s - loss: 225.6451 - val_loss: 4692.1228\n",
      "Epoch 23/100\n",
      " - 1s - loss: 221.8138 - val_loss: 4668.2105\n",
      "Epoch 24/100\n",
      " - 1s - loss: 218.1020 - val_loss: 4645.1465\n",
      "Epoch 25/100\n",
      " - 1s - loss: 214.4226 - val_loss: 4621.8080\n",
      "Epoch 26/100\n",
      " - 1s - loss: 210.7296 - val_loss: 4598.1318\n",
      "Epoch 27/100\n",
      " - 1s - loss: 207.1941 - val_loss: 4574.7798\n",
      "Epoch 28/100\n",
      " - 1s - loss: 203.6714 - val_loss: 4551.4312\n",
      "Epoch 29/100\n",
      " - 1s - loss: 200.3252 - val_loss: 4528.5849\n",
      "Epoch 30/100\n",
      " - 1s - loss: 196.9967 - val_loss: 4505.2749\n",
      "Epoch 31/100\n",
      " - 1s - loss: 193.7524 - val_loss: 4482.1860\n",
      "Epoch 32/100\n",
      " - 1s - loss: 190.5689 - val_loss: 4459.4668\n",
      "Epoch 33/100\n",
      " - 1s - loss: 187.4709 - val_loss: 4436.6455\n",
      "Epoch 34/100\n",
      " - 1s - loss: 184.4408 - val_loss: 4413.6125\n",
      "Epoch 35/100\n",
      " - 1s - loss: 181.4695 - val_loss: 4391.7146\n",
      "Epoch 36/100\n",
      " - 1s - loss: 178.6257 - val_loss: 4369.2665\n",
      "Epoch 37/100\n",
      " - 1s - loss: 175.7869 - val_loss: 4346.6783\n",
      "Epoch 38/100\n",
      " - 1s - loss: 173.0954 - val_loss: 4324.6587\n",
      "Epoch 39/100\n",
      " - 1s - loss: 170.4471 - val_loss: 4302.0614\n",
      "Epoch 40/100\n",
      " - 1s - loss: 167.8577 - val_loss: 4280.4683\n",
      "Epoch 41/100\n",
      " - 1s - loss: 165.3603 - val_loss: 4258.2096\n",
      "Epoch 42/100\n",
      " - 1s - loss: 162.9898 - val_loss: 4237.8204\n",
      "Epoch 43/100\n",
      " - 1s - loss: 160.6643 - val_loss: 4215.6920\n",
      "Epoch 44/100\n",
      " - 1s - loss: 158.4075 - val_loss: 4194.6916\n",
      "Epoch 45/100\n",
      " - 1s - loss: 156.2658 - val_loss: 4173.9604\n",
      "Epoch 46/100\n",
      " - 1s - loss: 154.1864 - val_loss: 4153.0798\n",
      "Epoch 47/100\n",
      " - 1s - loss: 152.0777 - val_loss: 4132.1988\n",
      "Epoch 48/100\n",
      " - 1s - loss: 150.1216 - val_loss: 4111.5122\n",
      "Epoch 49/100\n",
      " - 1s - loss: 148.1691 - val_loss: 4090.2289\n",
      "Epoch 50/100\n",
      " - 1s - loss: 146.3527 - val_loss: 4070.2401\n",
      "Epoch 51/100\n",
      " - 1s - loss: 144.6043 - val_loss: 4049.4959\n",
      "Epoch 52/100\n",
      " - 1s - loss: 142.8985 - val_loss: 4029.0168\n",
      "Epoch 53/100\n",
      " - 1s - loss: 141.2789 - val_loss: 4008.7707\n",
      "Epoch 54/100\n",
      " - 1s - loss: 139.7400 - val_loss: 3989.5753\n",
      "Epoch 55/100\n",
      " - 1s - loss: 138.2503 - val_loss: 3970.1843\n",
      "Epoch 56/100\n",
      " - 1s - loss: 136.8343 - val_loss: 3950.3053\n",
      "Epoch 57/100\n",
      " - 1s - loss: 135.5042 - val_loss: 3930.8722\n",
      "Epoch 58/100\n",
      " - 1s - loss: 134.3044 - val_loss: 3914.0441\n",
      "Epoch 59/100\n",
      " - 1s - loss: 133.1415 - val_loss: 3895.4768\n",
      "Epoch 60/100\n",
      " - 1s - loss: 131.9583 - val_loss: 3875.7384\n",
      "Epoch 61/100\n",
      " - 1s - loss: 130.9079 - val_loss: 3857.6532\n",
      "Epoch 62/100\n",
      " - 1s - loss: 129.9192 - val_loss: 3840.7433\n",
      "Epoch 63/100\n",
      " - 1s - loss: 128.9793 - val_loss: 3823.0822\n",
      "Epoch 64/100\n",
      " - 1s - loss: 128.1271 - val_loss: 3805.1957\n",
      "Epoch 65/100\n",
      " - 1s - loss: 127.3575 - val_loss: 3790.9518\n",
      "Epoch 66/100\n",
      " - 1s - loss: 126.6684 - val_loss: 3775.3344\n",
      "Epoch 67/100\n",
      " - 1s - loss: 125.9918 - val_loss: 3759.2399\n",
      "Epoch 68/100\n",
      " - 1s - loss: 125.3780 - val_loss: 3744.7170\n",
      "Epoch 69/100\n",
      " - 1s - loss: 124.8366 - val_loss: 3730.8712\n",
      "Epoch 70/100\n",
      " - 1s - loss: 124.3487 - val_loss: 3717.4806\n",
      "Epoch 71/100\n",
      " - 1s - loss: 123.8813 - val_loss: 3703.1161\n",
      "Epoch 72/100\n",
      " - 1s - loss: 123.4887 - val_loss: 3691.1223\n",
      "Epoch 73/100\n",
      " - 1s - loss: 123.1265 - val_loss: 3678.6714\n",
      "Epoch 74/100\n",
      " - 1s - loss: 122.8094 - val_loss: 3666.9602\n",
      "Epoch 75/100\n",
      " - 1s - loss: 122.5124 - val_loss: 3654.9634\n",
      "Epoch 76/100\n",
      " - 1s - loss: 122.2705 - val_loss: 3644.8711\n",
      "Epoch 77/100\n",
      " - 1s - loss: 122.0598 - val_loss: 3635.1897\n",
      "Epoch 78/100\n",
      " - 1s - loss: 121.8672 - val_loss: 3625.8834\n",
      "Epoch 79/100\n",
      " - 1s - loss: 121.7062 - val_loss: 3617.6457\n",
      "Epoch 80/100\n",
      " - 1s - loss: 121.5814 - val_loss: 3609.7087\n",
      "Epoch 81/100\n",
      " - 1s - loss: 121.4675 - val_loss: 3602.2611\n",
      "Epoch 82/100\n",
      " - 1s - loss: 121.3782 - val_loss: 3597.9823\n",
      "Epoch 83/100\n",
      " - 1s - loss: 121.3201 - val_loss: 3592.3737\n",
      "Epoch 84/100\n",
      " - 1s - loss: 121.2445 - val_loss: 3586.6419\n",
      "Epoch 85/100\n",
      " - 1s - loss: 121.1893 - val_loss: 3581.7937\n",
      "Epoch 86/100\n",
      " - 1s - loss: 121.1364 - val_loss: 3576.7691\n",
      "Epoch 87/100\n",
      " - 1s - loss: 121.0990 - val_loss: 3573.4222\n",
      "Epoch 88/100\n",
      " - 1s - loss: 121.0660 - val_loss: 3568.9548\n",
      "Epoch 89/100\n",
      " - 1s - loss: 121.0324 - val_loss: 3564.4013\n",
      "Epoch 90/100\n",
      " - 1s - loss: 121.0023 - val_loss: 3560.3941\n",
      "Epoch 91/100\n",
      " - 1s - loss: 120.9763 - val_loss: 3557.4134\n",
      "Epoch 92/100\n",
      " - 1s - loss: 120.9606 - val_loss: 3554.9604\n",
      "Epoch 93/100\n",
      " - 1s - loss: 120.9462 - val_loss: 3552.4970\n",
      "Epoch 94/100\n",
      " - 1s - loss: 120.9374 - val_loss: 3551.1281\n",
      "Epoch 95/100\n",
      " - 1s - loss: 120.9303 - val_loss: 3548.6270\n",
      "Epoch 96/100\n",
      " - 1s - loss: 120.9199 - val_loss: 3546.8738\n",
      "Epoch 97/100\n",
      " - 1s - loss: 120.9114 - val_loss: 3545.0098\n",
      "Epoch 98/100\n",
      " - 1s - loss: 120.9071 - val_loss: 3543.8474\n",
      "Epoch 99/100\n",
      " - 1s - loss: 120.9033 - val_loss: 3542.9172\n",
      "Epoch 100/100\n",
      " - 1s - loss: 120.8986 - val_loss: 3541.4181\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 327.5720 - val_loss: 5216.4375\n",
      "Epoch 2/100\n",
      " - 1s - loss: 319.6236 - val_loss: 5190.6749\n",
      "Epoch 3/100\n",
      " - 1s - loss: 314.2619 - val_loss: 5165.1636\n",
      "Epoch 4/100\n",
      " - 1s - loss: 308.9837 - val_loss: 5140.0393\n",
      "Epoch 5/100\n",
      " - 1s - loss: 303.6981 - val_loss: 5114.7628\n",
      "Epoch 6/100\n",
      " - 1s - loss: 298.6052 - val_loss: 5089.2473\n",
      "Epoch 7/100\n",
      " - 1s - loss: 293.5231 - val_loss: 5064.4299\n",
      "Epoch 8/100\n",
      " - 1s - loss: 288.5149 - val_loss: 5039.4222\n",
      "Epoch 9/100\n",
      " - 1s - loss: 283.5960 - val_loss: 5014.3937\n",
      "Epoch 10/100\n",
      " - 1s - loss: 278.7834 - val_loss: 4989.5011\n",
      "Epoch 11/100\n",
      " - 1s - loss: 274.0201 - val_loss: 4964.7890\n",
      "Epoch 12/100\n",
      " - 1s - loss: 269.3383 - val_loss: 4940.1864\n",
      "Epoch 13/100\n",
      " - 1s - loss: 264.6890 - val_loss: 4915.4685\n",
      "Epoch 14/100\n",
      " - 1s - loss: 260.1528 - val_loss: 4890.7233\n",
      "Epoch 15/100\n",
      " - 1s - loss: 255.6634 - val_loss: 4866.2410\n",
      "Epoch 16/100\n",
      " - 1s - loss: 251.3412 - val_loss: 4841.8955\n",
      "Epoch 17/100\n",
      " - 1s - loss: 246.9888 - val_loss: 4817.5241\n",
      "Epoch 18/100\n",
      " - 1s - loss: 242.7282 - val_loss: 4793.3984\n",
      "Epoch 19/100\n",
      " - 1s - loss: 238.5719 - val_loss: 4769.3159\n",
      "Epoch 20/100\n",
      " - 1s - loss: 234.4972 - val_loss: 4745.4679\n",
      "Epoch 21/100\n",
      " - 1s - loss: 230.4353 - val_loss: 4721.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      " - 1s - loss: 226.5213 - val_loss: 4697.7459\n",
      "Epoch 23/100\n",
      " - 1s - loss: 222.6318 - val_loss: 4673.8117\n",
      "Epoch 24/100\n",
      " - 1s - loss: 218.8969 - val_loss: 4650.0594\n",
      "Epoch 25/100\n",
      " - 1s - loss: 215.1719 - val_loss: 4626.4837\n",
      "Epoch 26/100\n",
      " - 1s - loss: 211.4820 - val_loss: 4602.9218\n",
      "Epoch 27/100\n",
      " - 1s - loss: 207.9001 - val_loss: 4579.5997\n",
      "Epoch 28/100\n",
      " - 1s - loss: 204.4044 - val_loss: 4556.1383\n",
      "Epoch 29/100\n",
      " - 1s - loss: 200.9958 - val_loss: 4532.9226\n",
      "Epoch 30/100\n",
      " - 1s - loss: 197.6708 - val_loss: 4509.9911\n",
      "Epoch 31/100\n",
      " - 1s - loss: 194.3798 - val_loss: 4486.9155\n",
      "Epoch 32/100\n",
      " - 1s - loss: 191.2134 - val_loss: 4463.9971\n",
      "Epoch 33/100\n",
      " - 1s - loss: 188.0952 - val_loss: 4441.1022\n",
      "Epoch 34/100\n",
      " - 1s - loss: 185.0294 - val_loss: 4418.1566\n",
      "Epoch 35/100\n",
      " - 1s - loss: 182.1405 - val_loss: 4396.8178\n",
      "Epoch 36/100\n",
      " - 1s - loss: 179.2542 - val_loss: 4373.9578\n",
      "Epoch 37/100\n",
      " - 1s - loss: 176.4232 - val_loss: 4351.5576\n",
      "Epoch 38/100\n",
      " - 1s - loss: 173.6691 - val_loss: 4328.6227\n",
      "Epoch 39/100\n",
      " - 1s - loss: 171.0458 - val_loss: 4307.6998\n",
      "Epoch 40/100\n",
      " - 1s - loss: 168.4735 - val_loss: 4285.5865\n",
      "Epoch 41/100\n",
      " - 1s - loss: 165.9742 - val_loss: 4264.0150\n",
      "Epoch 42/100\n",
      " - 1s - loss: 163.5217 - val_loss: 4241.6132\n",
      "Epoch 43/100\n",
      " - 1s - loss: 161.2467 - val_loss: 4221.4835\n",
      "Epoch 44/100\n",
      " - 1s - loss: 158.9602 - val_loss: 4199.9060\n",
      "Epoch 45/100\n",
      " - 1s - loss: 156.7442 - val_loss: 4178.4803\n",
      "Epoch 46/100\n",
      " - 1s - loss: 154.5638 - val_loss: 4157.1222\n",
      "Epoch 47/100\n",
      " - 1s - loss: 152.4736 - val_loss: 4136.3484\n",
      "Epoch 48/100\n",
      " - 1s - loss: 150.5121 - val_loss: 4115.3603\n",
      "Epoch 49/100\n",
      " - 1s - loss: 148.5302 - val_loss: 4094.0545\n",
      "Epoch 50/100\n",
      " - 1s - loss: 146.6442 - val_loss: 4073.0716\n",
      "Epoch 51/100\n",
      " - 1s - loss: 144.8960 - val_loss: 4053.4629\n",
      "Epoch 52/100\n",
      " - 1s - loss: 143.2058 - val_loss: 4032.9113\n",
      "Epoch 53/100\n",
      " - 1s - loss: 141.5826 - val_loss: 4013.2326\n",
      "Epoch 54/100\n",
      " - 1s - loss: 140.0034 - val_loss: 3993.0822\n",
      "Epoch 55/100\n",
      " - 1s - loss: 138.5256 - val_loss: 3973.8997\n",
      "Epoch 56/100\n",
      " - 1s - loss: 137.1094 - val_loss: 3954.0250\n",
      "Epoch 57/100\n",
      " - 1s - loss: 135.7481 - val_loss: 3934.9395\n",
      "Epoch 58/100\n",
      " - 1s - loss: 134.4529 - val_loss: 3915.0963\n",
      "Epoch 59/100\n",
      " - 1s - loss: 133.2800 - val_loss: 3897.0674\n",
      "Epoch 60/100\n",
      " - 1s - loss: 132.1381 - val_loss: 3878.8730\n",
      "Epoch 61/100\n",
      " - 1s - loss: 131.0845 - val_loss: 3861.7905\n",
      "Epoch 62/100\n",
      " - 1s - loss: 130.1028 - val_loss: 3844.2098\n",
      "Epoch 63/100\n",
      " - 1s - loss: 129.1658 - val_loss: 3826.4758\n",
      "Epoch 64/100\n",
      " - 1s - loss: 128.3131 - val_loss: 3810.7419\n",
      "Epoch 65/100\n",
      " - 1s - loss: 127.5020 - val_loss: 3793.4397\n",
      "Epoch 66/100\n",
      " - 1s - loss: 126.7842 - val_loss: 3777.7458\n",
      "Epoch 67/100\n",
      " - 1s - loss: 126.0961 - val_loss: 3762.1446\n",
      "Epoch 68/100\n",
      " - 1s - loss: 125.4575 - val_loss: 3745.9978\n",
      "Epoch 69/100\n",
      " - 1s - loss: 124.8874 - val_loss: 3732.2217\n",
      "Epoch 70/100\n",
      " - 1s - loss: 124.3955 - val_loss: 3718.2174\n",
      "Epoch 71/100\n",
      " - 1s - loss: 123.9333 - val_loss: 3703.9874\n",
      "Epoch 72/100\n",
      " - 1s - loss: 123.5206 - val_loss: 3692.4373\n",
      "Epoch 73/100\n",
      " - 1s - loss: 123.1782 - val_loss: 3680.6125\n",
      "Epoch 74/100\n",
      " - 1s - loss: 122.8582 - val_loss: 3669.8309\n",
      "Epoch 75/100\n",
      " - 1s - loss: 122.6008 - val_loss: 3658.2656\n",
      "Epoch 76/100\n",
      " - 1s - loss: 122.3444 - val_loss: 3648.1438\n",
      "Epoch 77/100\n",
      " - 1s - loss: 122.1358 - val_loss: 3639.6019\n",
      "Epoch 78/100\n",
      " - 1s - loss: 121.9549 - val_loss: 3629.9167\n",
      "Epoch 79/100\n",
      " - 1s - loss: 121.7848 - val_loss: 3621.4369\n",
      "Epoch 80/100\n",
      " - 1s - loss: 121.6556 - val_loss: 3614.7618\n",
      "Epoch 81/100\n",
      " - 1s - loss: 121.5350 - val_loss: 3607.2660\n",
      "Epoch 82/100\n",
      " - 1s - loss: 121.4324 - val_loss: 3599.5550\n",
      "Epoch 83/100\n",
      " - 1s - loss: 121.3297 - val_loss: 3593.1979\n",
      "Epoch 84/100\n",
      " - 1s - loss: 121.2532 - val_loss: 3587.3946\n",
      "Epoch 85/100\n",
      " - 1s - loss: 121.1947 - val_loss: 3581.8803\n",
      "Epoch 86/100\n",
      " - 1s - loss: 121.1374 - val_loss: 3576.9317\n",
      "Epoch 87/100\n",
      " - 1s - loss: 121.0981 - val_loss: 3572.8198\n",
      "Epoch 88/100\n",
      " - 1s - loss: 121.0625 - val_loss: 3568.3161\n",
      "Epoch 89/100\n",
      " - 1s - loss: 121.0296 - val_loss: 3565.0940\n",
      "Epoch 90/100\n",
      " - 1s - loss: 121.0066 - val_loss: 3561.1931\n",
      "Epoch 91/100\n",
      " - 1s - loss: 120.9832 - val_loss: 3558.8467\n",
      "Epoch 92/100\n",
      " - 1s - loss: 120.9684 - val_loss: 3555.3359\n",
      "Epoch 93/100\n",
      " - 1s - loss: 120.9493 - val_loss: 3552.3142\n",
      "Epoch 94/100\n",
      " - 1s - loss: 120.9367 - val_loss: 3551.0164\n",
      "Epoch 95/100\n",
      " - 1s - loss: 120.9302 - val_loss: 3549.5029\n",
      "Epoch 96/100\n",
      " - 1s - loss: 120.9238 - val_loss: 3548.4898\n",
      "Epoch 97/100\n",
      " - 1s - loss: 120.9180 - val_loss: 3546.7437\n",
      "Epoch 98/100\n",
      " - 1s - loss: 120.9127 - val_loss: 3545.3323\n",
      "Epoch 99/100\n",
      " - 1s - loss: 120.9069 - val_loss: 3543.8164\n",
      "Epoch 100/100\n",
      " - 1s - loss: 120.9023 - val_loss: 3542.4906\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, softmax & rmsprop\n",
    "checkpointer = ModelCheckpoint(filepath=\"tns/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    tns_model = Sequential()\n",
    "    # Build network\n",
    "    tns_model.add(Dense(130, input_dim = tns_X_train.shape[1], activation='relu')) # Hidden 1\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    tns_model.add(Dropout(0.10))\n",
    "    tns_model.add(Dense(30, activation='softmax')) # Hidden 3\n",
    "    tns_model.add(Dense(1)) # Output\n",
    "\n",
    "    tns_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    tns_model.fit(tns_X_train, tns_y_train, validation_data = (tns_X_test, tns_y_test), callbacks=[monitor, checkpointer], \n",
    "                  verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid, softmax & rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 59.50981597917062\n",
      "R2 score -3.6075119103099906\n",
      "MSE::  3541.4181978747506\n"
     ]
    }
   ],
   "source": [
    "tns_model.load_weights('tns/weights.hdf5')\n",
    "tns_pred = tns_model.predict(tns_X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(tns_y_test, tns_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(tns_y_test, tns_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(tns_y_test, tns_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tunning for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 28s - loss: 156.0248 - val_loss: 3749.1831\n",
      "Epoch 2/100\n",
      " - 13s - loss: 121.5813 - val_loss: 3552.3154\n",
      "Epoch 3/100\n",
      " - 14s - loss: 120.6852 - val_loss: 3540.3361\n",
      "Epoch 4/100\n",
      " - 14s - loss: 120.6475 - val_loss: 3529.6099\n",
      "Epoch 5/100\n",
      " - 13s - loss: 120.6592 - val_loss: 3552.0479\n",
      "Epoch 6/100\n",
      " - 14s - loss: 120.6652 - val_loss: 3532.2451\n",
      "Epoch 7/100\n",
      " - 14s - loss: 120.6947 - val_loss: 3543.9848\n",
      "Epoch 8/100\n",
      " - 14s - loss: 120.6902 - val_loss: 3536.0820\n",
      "Epoch 9/100\n",
      " - 14s - loss: 120.6379 - val_loss: 3547.0559\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 27s - loss: 144.7632 - val_loss: 3651.3827\n",
      "Epoch 2/100\n",
      " - 15s - loss: 120.9602 - val_loss: 3536.3377\n",
      "Epoch 3/100\n",
      " - 15s - loss: 120.6423 - val_loss: 3533.8492\n",
      "Epoch 4/100\n",
      " - 16s - loss: 120.6527 - val_loss: 3550.9649\n",
      "Epoch 5/100\n",
      " - 16s - loss: 120.7637 - val_loss: 3517.2922\n",
      "Epoch 6/100\n",
      " - 15s - loss: 120.6447 - val_loss: 3536.2584\n",
      "Epoch 7/100\n",
      " - 14s - loss: 120.6930 - val_loss: 3536.4901\n",
      "Epoch 8/100\n",
      " - 15s - loss: 120.6814 - val_loss: 3542.6048\n",
      "Epoch 9/100\n",
      " - 14s - loss: 120.6770 - val_loss: 3551.2752\n",
      "Epoch 10/100\n",
      " - 14s - loss: 120.6268 - val_loss: 3500.5325\n",
      "Epoch 11/100\n",
      " - 14s - loss: 120.7650 - val_loss: 3523.3185\n",
      "Epoch 12/100\n",
      " - 14s - loss: 120.7567 - val_loss: 3546.0523\n",
      "Epoch 13/100\n",
      " - 14s - loss: 120.7481 - val_loss: 3544.8766\n",
      "Epoch 14/100\n",
      " - 14s - loss: 120.6284 - val_loss: 3519.9371\n",
      "Epoch 15/100\n",
      " - 14s - loss: 120.6793 - val_loss: 3554.4386\n",
      "Epoch 00015: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 28s - loss: 145.5801 - val_loss: 3654.0733\n",
      "Epoch 2/100\n",
      " - 16s - loss: 120.9669 - val_loss: 3537.4189\n",
      "Epoch 3/100\n",
      " - 16s - loss: 120.6657 - val_loss: 3525.7457\n",
      "Epoch 4/100\n",
      " - 16s - loss: 120.6781 - val_loss: 3540.6609\n",
      "Epoch 5/100\n",
      " - 16s - loss: 120.6367 - val_loss: 3532.2896\n",
      "Epoch 6/100\n",
      " - 17s - loss: 120.6080 - val_loss: 3553.6777\n",
      "Epoch 7/100\n",
      " - 16s - loss: 120.7819 - val_loss: 3545.9710\n",
      "Epoch 8/100\n",
      " - 16s - loss: 120.6767 - val_loss: 3557.1668\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 29s - loss: 166.2426 - val_loss: 3867.7369\n",
      "Epoch 2/100\n",
      " - 18s - loss: 124.0692 - val_loss: 3608.0092\n",
      "Epoch 3/100\n",
      " - 18s - loss: 120.7557 - val_loss: 3535.0336\n",
      "Epoch 4/100\n",
      " - 17s - loss: 120.7546 - val_loss: 3539.6499\n",
      "Epoch 5/100\n",
      " - 16s - loss: 120.6527 - val_loss: 3528.9247\n",
      "Epoch 6/100\n",
      " - 16s - loss: 120.6812 - val_loss: 3525.8217\n",
      "Epoch 7/100\n",
      " - 18s - loss: 120.6432 - val_loss: 3536.3580\n",
      "Epoch 8/100\n",
      " - 17s - loss: 120.7147 - val_loss: 3535.0534\n",
      "Epoch 9/100\n",
      " - 16s - loss: 120.6623 - val_loss: 3521.5791\n",
      "Epoch 10/100\n",
      " - 16s - loss: 120.7740 - val_loss: 3503.9545\n",
      "Epoch 11/100\n",
      " - 17s - loss: 120.6922 - val_loss: 3525.4141\n",
      "Epoch 12/100\n",
      " - 17s - loss: 120.6629 - val_loss: 3518.1283\n",
      "Epoch 13/100\n",
      " - 16s - loss: 120.6726 - val_loss: 3526.5516\n",
      "Epoch 14/100\n",
      " - 17s - loss: 120.6427 - val_loss: 3502.8618\n",
      "Epoch 15/100\n",
      " - 20s - loss: 120.7005 - val_loss: 3538.8687\n",
      "Epoch 16/100\n",
      " - 16s - loss: 120.6367 - val_loss: 3540.2128\n",
      "Epoch 17/100\n",
      " - 16s - loss: 120.6825 - val_loss: 3540.3526\n",
      "Epoch 18/100\n",
      " - 16s - loss: 120.6650 - val_loss: 3532.2768\n",
      "Epoch 19/100\n",
      " - 16s - loss: 120.7300 - val_loss: 3548.0440\n",
      "Epoch 00019: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 30s - loss: 155.0714 - val_loss: 3733.1612\n",
      "Epoch 2/100\n",
      " - 16s - loss: 121.5990 - val_loss: 3554.1647\n",
      "Epoch 3/100\n",
      " - 16s - loss: 120.6686 - val_loss: 3535.3967\n",
      "Epoch 4/100\n",
      " - 16s - loss: 120.7446 - val_loss: 3534.6281\n",
      "Epoch 5/100\n",
      " - 17s - loss: 120.6729 - val_loss: 3543.0523\n",
      "Epoch 6/100\n",
      " - 16s - loss: 120.6179 - val_loss: 3497.2652\n",
      "Epoch 7/100\n",
      " - 17s - loss: 120.6930 - val_loss: 3506.8451\n",
      "Epoch 8/100\n",
      " - 17s - loss: 120.7154 - val_loss: 3534.4074\n",
      "Epoch 9/100\n",
      " - 16s - loss: 120.6824 - val_loss: 3526.4632\n",
      "Epoch 10/100\n",
      " - 16s - loss: 120.6599 - val_loss: 3528.2412\n",
      "Epoch 11/100\n",
      " - 16s - loss: 120.6667 - val_loss: 3505.5263\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid & adam, neuron=256\n",
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(256, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='sigmoid'))\n",
    "    #lstm_model.add(Dropout(0.10))\n",
    "    #lstm_model.add(Dense(100, activation='softmax'))\n",
    "    #lstm_model.add(Dropout(0.10))\n",
    "   # lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score for relu, sigmoid & adam, neuron=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 59.13768039279805\n",
      "R2 score -3.539033034236347\n",
      "MSE::  3497.265242240731\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 25s - loss: 148.8464 - val_loss: 3447.7140\n",
      "Epoch 2/100\n",
      " - 10s - loss: 118.9894 - val_loss: 3471.1748\n",
      "Epoch 3/100\n",
      " - 10s - loss: 118.1150 - val_loss: 3493.3556\n",
      "Epoch 4/100\n",
      " - 9s - loss: 123.5420 - val_loss: 3662.1413\n",
      "Epoch 5/100\n",
      " - 9s - loss: 115.8610 - val_loss: 3530.2127\n",
      "Epoch 6/100\n",
      " - 9s - loss: 115.3032 - val_loss: 3529.6076\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 23s - loss: 148.9515 - val_loss: 3777.4079\n",
      "Epoch 2/100\n",
      " - 13s - loss: 117.4459 - val_loss: 3551.1050\n",
      "Epoch 3/100\n",
      " - 10s - loss: 114.8811 - val_loss: 3544.0123\n",
      "Epoch 4/100\n",
      " - 10s - loss: 115.8144 - val_loss: 3550.8328\n",
      "Epoch 5/100\n",
      " - 10s - loss: 114.7487 - val_loss: 3542.8700\n",
      "Epoch 6/100\n",
      " - 10s - loss: 126.6394 - val_loss: 3451.7449\n",
      "Epoch 7/100\n",
      " - 11s - loss: 118.4659 - val_loss: 3475.0809\n",
      "Epoch 8/100\n",
      " - 10s - loss: 121.4233 - val_loss: 3575.2698\n",
      "Epoch 9/100\n",
      " - 10s - loss: 116.3966 - val_loss: 3549.8560\n",
      "Epoch 10/100\n",
      " - 10s - loss: 115.8493 - val_loss: 3506.7394\n",
      "Epoch 11/100\n",
      " - 12s - loss: 115.9713 - val_loss: 3552.5889\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 24s - loss: 151.9376 - val_loss: 3620.2014\n",
      "Epoch 2/100\n",
      " - 10s - loss: 115.5577 - val_loss: 3541.7372\n",
      "Epoch 3/100\n",
      " - 10s - loss: 115.2999 - val_loss: 3510.5268\n",
      "Epoch 4/100\n",
      " - 10s - loss: 117.4643 - val_loss: 3536.0074\n",
      "Epoch 5/100\n",
      " - 11s - loss: 119.3881 - val_loss: 3562.7525\n",
      "Epoch 6/100\n",
      " - 10s - loss: 120.6917 - val_loss: 3567.3084\n",
      "Epoch 7/100\n",
      " - 10s - loss: 120.6797 - val_loss: 3526.5546\n",
      "Epoch 8/100\n",
      " - 10s - loss: 120.7240 - val_loss: 3546.5826\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 24s - loss: 151.8127 - val_loss: 3498.6662\n",
      "Epoch 2/100\n",
      " - 11s - loss: 117.4791 - val_loss: 3451.1198\n",
      "Epoch 3/100\n",
      " - 12s - loss: 118.2668 - val_loss: 3527.6474\n",
      "Epoch 4/100\n",
      " - 11s - loss: 117.9834 - val_loss: 3500.3043\n",
      "Epoch 5/100\n",
      " - 11s - loss: 118.9093 - val_loss: 3517.3040\n",
      "Epoch 6/100\n",
      " - 11s - loss: 120.7267 - val_loss: 3531.8496\n",
      "Epoch 7/100\n",
      " - 11s - loss: 120.1669 - val_loss: 3508.1375\n",
      "Epoch 00007: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 25s - loss: 149.8576 - val_loss: 3545.8184\n",
      "Epoch 2/100\n",
      " - 13s - loss: 120.6597 - val_loss: 3522.4584\n",
      "Epoch 3/100\n",
      " - 12s - loss: 118.7652 - val_loss: 3525.3885\n",
      "Epoch 4/100\n",
      " - 11s - loss: 118.1266 - val_loss: 3492.9233\n",
      "Epoch 5/100\n",
      " - 12s - loss: 117.9279 - val_loss: 3479.9728\n",
      "Epoch 6/100\n",
      " - 12s - loss: 117.5700 - val_loss: 3495.7283\n",
      "Epoch 7/100\n",
      " - 11s - loss: 117.6621 - val_loss: 3489.3372\n",
      "Epoch 8/100\n",
      " - 12s - loss: 117.6772 - val_loss: 3513.8793\n",
      "Epoch 9/100\n",
      " - 12s - loss: 117.8028 - val_loss: 3505.1528\n",
      "Epoch 10/100\n",
      " - 12s - loss: 118.1535 - val_loss: 3495.0969\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, softmax & sgd, neuron=200\n",
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(200, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    #lstm_model.add(Dense(150, activation='sigmoid'))\n",
    "    #lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(100, activation='softmax'))\n",
    "    #lstm_model.add(Dropout(0.10))\n",
    "   # lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, softmax & sgd, neuron=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 58.7172379721014\n",
      "R2 score -3.4747214791655914\n",
      "MSE::  3447.7140350723867\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 26s - loss: 129.5607 - val_loss: 3441.2883\n",
      "Epoch 2/100\n",
      " - 8s - loss: 59.8620 - val_loss: 2742.8346\n",
      "Epoch 3/100\n",
      " - 7s - loss: 24.8348 - val_loss: 2172.6734\n",
      "Epoch 4/100\n",
      " - 7s - loss: 8.7605 - val_loss: 1746.5388\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.4769 - val_loss: 1525.0336\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.4497 - val_loss: 1446.6431\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.0700 - val_loss: 1404.4234\n",
      "Epoch 8/100\n",
      " - 8s - loss: 1.7636 - val_loss: 1505.5508\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.6988 - val_loss: 1494.1094\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.3993 - val_loss: 1354.3938\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.4513 - val_loss: 1343.8902\n",
      "Epoch 12/100\n",
      " - 7s - loss: 1.1577 - val_loss: 1345.2199\n",
      "Epoch 13/100\n",
      " - 7s - loss: 1.1591 - val_loss: 1359.7545\n",
      "Epoch 14/100\n",
      " - 7s - loss: 1.0450 - val_loss: 1482.1946\n",
      "Epoch 15/100\n",
      " - 7s - loss: 1.0644 - val_loss: 1434.0390\n",
      "Epoch 16/100\n",
      " - 7s - loss: 1.0015 - val_loss: 1333.3260\n",
      "Epoch 17/100\n",
      " - 7s - loss: 1.0420 - val_loss: 1327.4573\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.9190 - val_loss: 1332.4571\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.9343 - val_loss: 1327.6581\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.8148 - val_loss: 1324.7839\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.8015 - val_loss: 1306.8678\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.7539 - val_loss: 1302.0356\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.7126 - val_loss: 1301.2909\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.7610 - val_loss: 1296.9942\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.6942 - val_loss: 1315.1194\n",
      "Epoch 26/100\n",
      " - 9s - loss: 0.7019 - val_loss: 1294.6703\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.6591 - val_loss: 1288.9676\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.6572 - val_loss: 1301.9244\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.7057 - val_loss: 1293.9281\n",
      "Epoch 30/100\n",
      " - 7s - loss: 0.6534 - val_loss: 1312.4538\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.6438 - val_loss: 1300.8534\n",
      "Epoch 32/100\n",
      " - 7s - loss: 0.6409 - val_loss: 1283.9659\n",
      "Epoch 33/100\n",
      " - 7s - loss: 0.6056 - val_loss: 1289.2007\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.5910 - val_loss: 1295.3616\n",
      "Epoch 35/100\n",
      " - 7s - loss: 0.5878 - val_loss: 1274.6684\n",
      "Epoch 36/100\n",
      " - 7s - loss: 0.6067 - val_loss: 1272.6220\n",
      "Epoch 37/100\n",
      " - 7s - loss: 0.6337 - val_loss: 1282.6805\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.5934 - val_loss: 1314.7001\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.5530 - val_loss: 1323.8489\n",
      "Epoch 40/100\n",
      " - 7s - loss: 0.5370 - val_loss: 1289.7732\n",
      "Epoch 41/100\n",
      " - 7s - loss: 0.5616 - val_loss: 1294.5386\n",
      "Epoch 00041: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 144.6986 - val_loss: 3609.8497\n",
      "Epoch 2/100\n",
      " - 9s - loss: 71.9062 - val_loss: 2913.3298\n",
      "Epoch 3/100\n",
      " - 7s - loss: 32.6161 - val_loss: 2338.1692\n",
      "Epoch 4/100\n",
      " - 7s - loss: 12.8597 - val_loss: 1900.3307\n",
      "Epoch 5/100\n",
      " - 7s - loss: 4.7303 - val_loss: 1610.5954\n",
      "Epoch 6/100\n",
      " - 8s - loss: 2.9446 - val_loss: 1511.0405\n",
      "Epoch 7/100\n",
      " - 8s - loss: 2.3647 - val_loss: 1421.8561\n",
      "Epoch 8/100\n",
      " - 8s - loss: 1.9196 - val_loss: 1395.3197\n",
      "Epoch 9/100\n",
      " - 10s - loss: 1.7314 - val_loss: 1599.5543\n",
      "Epoch 10/100\n",
      " - 10s - loss: 1.4374 - val_loss: 1416.1238\n",
      "Epoch 11/100\n",
      " - 8s - loss: 1.3930 - val_loss: 1352.2714\n",
      "Epoch 12/100\n",
      " - 9s - loss: 1.2123 - val_loss: 1343.2453\n",
      "Epoch 13/100\n",
      " - 9s - loss: 1.2622 - val_loss: 1331.2798\n",
      "Epoch 14/100\n",
      " - 8s - loss: 1.1506 - val_loss: 1333.9069\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.9936 - val_loss: 1376.8424\n",
      "Epoch 16/100\n",
      " - 9s - loss: 1.0016 - val_loss: 1574.5813\n",
      "Epoch 17/100\n",
      " - 11s - loss: 0.8928 - val_loss: 1649.5342\n",
      "Epoch 18/100\n",
      " - 9s - loss: 0.9105 - val_loss: 1436.6063\n",
      "Epoch 00018: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 126.0609 - val_loss: 3423.8424\n",
      "Epoch 2/100\n",
      " - 8s - loss: 60.5845 - val_loss: 2791.8483\n",
      "Epoch 3/100\n",
      " - 7s - loss: 28.1419 - val_loss: 2258.8068\n",
      "Epoch 4/100\n",
      " - 7s - loss: 10.9773 - val_loss: 1845.8160\n",
      "Epoch 5/100\n",
      " - 7s - loss: 4.2623 - val_loss: 1604.8193\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.5216 - val_loss: 1527.1146\n",
      "Epoch 7/100\n",
      " - 7s - loss: 1.9549 - val_loss: 1420.6726\n",
      "Epoch 8/100\n",
      " - 7s - loss: 1.8440 - val_loss: 1418.2480\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.5718 - val_loss: 1374.9038\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.4926 - val_loss: 1369.8032\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.2007 - val_loss: 1370.7695\n",
      "Epoch 12/100\n",
      " - 10s - loss: 1.2532 - val_loss: 1389.4258\n",
      "Epoch 13/100\n",
      " - 8s - loss: 1.1236 - val_loss: 1336.8180\n",
      "Epoch 14/100\n",
      " - 11s - loss: 1.0192 - val_loss: 1384.2744\n",
      "Epoch 15/100\n",
      " - 8s - loss: 1.0405 - val_loss: 1319.6713\n",
      "Epoch 16/100\n",
      " - 9s - loss: 0.9552 - val_loss: 1378.8142\n",
      "Epoch 17/100\n",
      " - 9s - loss: 0.8928 - val_loss: 1332.9363\n",
      "Epoch 18/100\n",
      " - 9s - loss: 1.0397 - val_loss: 1323.3929\n",
      "Epoch 19/100\n",
      " - 10s - loss: 0.8950 - val_loss: 1316.8044\n",
      "Epoch 20/100\n",
      " - 10s - loss: 0.8451 - val_loss: 1340.8354\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.8479 - val_loss: 1355.4159\n",
      "Epoch 22/100\n",
      " - 10s - loss: 0.8370 - val_loss: 1335.3653\n",
      "Epoch 23/100\n",
      " - 9s - loss: 0.8573 - val_loss: 1348.4105\n",
      "Epoch 24/100\n",
      " - 9s - loss: 0.7238 - val_loss: 1461.7191\n",
      "Epoch 00024: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 24s - loss: 121.0271 - val_loss: 3378.5302\n",
      "Epoch 2/100\n",
      " - 7s - loss: 57.2503 - val_loss: 2722.8188\n",
      "Epoch 3/100\n",
      " - 7s - loss: 24.6398 - val_loss: 2183.8472\n",
      "Epoch 4/100\n",
      " - 7s - loss: 9.0367 - val_loss: 1785.1048\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.7293 - val_loss: 1553.6300\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.4751 - val_loss: 1481.6731\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.0890 - val_loss: 1403.9779\n",
      "Epoch 8/100\n",
      " - 7s - loss: 1.6719 - val_loss: 1378.3431\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.5359 - val_loss: 1377.9065\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.3604 - val_loss: 1436.6371\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.4521 - val_loss: 1343.3100\n",
      "Epoch 12/100\n",
      " - 7s - loss: 1.3354 - val_loss: 1374.4682\n",
      "Epoch 13/100\n",
      " - 7s - loss: 1.1516 - val_loss: 2006.8942\n",
      "Epoch 14/100\n",
      " - 7s - loss: 1.0642 - val_loss: 1860.1820\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.9071 - val_loss: 2156.7696\n",
      "Epoch 16/100\n",
      " - 7s - loss: 1.1890 - val_loss: 1319.0728\n",
      "Epoch 17/100\n",
      " - 7s - loss: 1.0348 - val_loss: 1319.4943\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.9611 - val_loss: 1321.0774\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.8761 - val_loss: 1313.0259\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.8213 - val_loss: 1320.7480\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.7875 - val_loss: 1325.3731\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.8596 - val_loss: 1304.7482\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.8362 - val_loss: 1340.1094\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.8064 - val_loss: 1419.1181\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.6726 - val_loss: 1556.5672\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.6768 - val_loss: 1320.5204\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.7984 - val_loss: 1364.5543\n",
      "Epoch 00027: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 23s - loss: 130.8157 - val_loss: 3524.6045\n",
      "Epoch 2/100\n",
      " - 7s - loss: 66.8860 - val_loss: 2876.4385\n",
      "Epoch 3/100\n",
      " - 7s - loss: 31.9056 - val_loss: 2332.3921\n",
      "Epoch 4/100\n",
      " - 7s - loss: 12.9240 - val_loss: 1911.3614\n",
      "Epoch 5/100\n",
      " - 7s - loss: 5.2109 - val_loss: 1639.3722\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.9174 - val_loss: 1518.9171\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.1996 - val_loss: 1440.7346\n",
      "Epoch 8/100\n",
      " - 7s - loss: 1.8265 - val_loss: 1402.6859\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.6519 - val_loss: 1388.3421\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.3238 - val_loss: 1400.4231\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.3524 - val_loss: 1889.6099\n",
      "Epoch 12/100\n",
      " - 7s - loss: 1.3890 - val_loss: 1468.2018\n",
      "Epoch 13/100\n",
      " - 7s - loss: 1.1471 - val_loss: 1595.6949\n",
      "Epoch 14/100\n",
      " - 7s - loss: 1.1349 - val_loss: 1363.0048\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.9883 - val_loss: 1366.5419\n",
      "Epoch 16/100\n",
      " - 7s - loss: 1.0281 - val_loss: 1372.3251\n",
      "Epoch 17/100\n",
      " - 8s - loss: 0.9645 - val_loss: 1318.5333\n",
      "Epoch 18/100\n",
      " - 9s - loss: 0.8745 - val_loss: 1317.5193\n",
      "Epoch 19/100\n",
      " - 9s - loss: 1.0119 - val_loss: 1334.3700\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.8398 - val_loss: 1599.4607\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.8102 - val_loss: 1314.4991\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.8059 - val_loss: 1327.2823\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.7771 - val_loss: 1298.0983\n",
      "Epoch 24/100\n",
      " - 10s - loss: 0.7607 - val_loss: 1347.2740\n",
      "Epoch 25/100\n",
      " - 9s - loss: 0.7221 - val_loss: 1302.8384\n",
      "Epoch 26/100\n",
      " - 11s - loss: 0.7010 - val_loss: 1367.1137\n",
      "Epoch 27/100\n",
      " - 9s - loss: 0.6649 - val_loss: 1293.5765\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.6378 - val_loss: 1358.1291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      " - 8s - loss: 0.6388 - val_loss: 1293.6634\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.6141 - val_loss: 1304.6147\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.6196 - val_loss: 1288.3507\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.6456 - val_loss: 1334.8615\n",
      "Epoch 33/100\n",
      " - 9s - loss: 0.6262 - val_loss: 1314.1524\n",
      "Epoch 34/100\n",
      " - 9s - loss: 0.6284 - val_loss: 1784.4017\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.6230 - val_loss: 1372.3921\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.5810 - val_loss: 2141.3339\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid & rmsprop, neuron=128\n",
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(128, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='sigmoid'))\n",
    "   # lstm_model.add(Dropout(0.10))\n",
    "    #lstm_model.add(Dense(100, activation='softmax'))\n",
    "    #lstm_model.add(Dropout(0.10))\n",
    "   # lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid & rmsprop, neuron=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35.6738285606477\n",
      "R2 score -0.6517115799041675\n",
      "MSE::  1272.6220441744836\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tunning for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 1, 7, 32)          4032      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 4, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 2, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 500)               64500     \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 325,225\n",
      "Trainable params: 325,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 327.5721 - val_loss: 5152.9400\n",
      "Epoch 2/100\n",
      " - 2s - loss: 278.9443 - val_loss: 4819.4971\n",
      "Epoch 3/100\n",
      " - 2s - loss: 207.5351 - val_loss: 4313.3072\n",
      "Epoch 4/100\n",
      " - 2s - loss: 143.6913 - val_loss: 3752.6549\n",
      "Epoch 5/100\n",
      " - 2s - loss: 121.3979 - val_loss: 3480.5055\n",
      "Epoch 6/100\n",
      " - 2s - loss: 120.7774 - val_loss: 3532.1195\n",
      "Epoch 7/100\n",
      " - 2s - loss: 120.5620 - val_loss: 3530.4130\n",
      "Epoch 00007: early stopping\n",
      "1\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 111.7620 - val_loss: 3324.3867\n",
      "Epoch 2/100\n",
      " - 2s - loss: 58.2091 - val_loss: 2650.4315\n",
      "Epoch 3/100\n",
      " - 2s - loss: 22.7779 - val_loss: 2127.9609\n",
      "Epoch 4/100\n",
      " - 2s - loss: 9.6224 - val_loss: 1817.0660\n",
      "Epoch 5/100\n",
      " - 2s - loss: 4.2333 - val_loss: 1651.8458\n",
      "Epoch 6/100\n",
      " - 2s - loss: 2.4144 - val_loss: 1547.9907\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.6148 - val_loss: 1472.4775\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.5095 - val_loss: 1426.3007\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.1235 - val_loss: 1391.1138\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.0128 - val_loss: 1363.3082\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.0188 - val_loss: 1339.4132\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.3285 - val_loss: 1330.2268\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.8373 - val_loss: 1319.9277\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.2647 - val_loss: 1309.2082\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.8576 - val_loss: 1301.3891\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.6745 - val_loss: 1287.2633\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.7130 - val_loss: 1274.0949\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.6362 - val_loss: 1263.1127\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.4803 - val_loss: 1249.3896\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.4291 - val_loss: 1236.9815\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.4528 - val_loss: 1227.3808\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.4554 - val_loss: 1220.0491\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.4228 - val_loss: 1214.1696\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.4678 - val_loss: 1205.6924\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.3995 - val_loss: 1201.1490\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.3903 - val_loss: 1194.3464\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.3976 - val_loss: 1187.1324\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.4000 - val_loss: 1184.8476\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.3597 - val_loss: 1179.4395\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.5596 - val_loss: 1176.5487\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.6218 - val_loss: 1183.1980\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.3758 - val_loss: 1181.4514\n",
      "Epoch 00032: early stopping\n",
      "2\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 1.4469 - val_loss: 1199.5681\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3623 - val_loss: 1191.2606\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3145 - val_loss: 1182.1934\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3067 - val_loss: 1171.3335\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.3038 - val_loss: 1163.0143\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.3048 - val_loss: 1154.5026\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2934 - val_loss: 1145.4993\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2833 - val_loss: 1135.0938\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.4148 - val_loss: 1138.3843\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.4054 - val_loss: 1138.3893\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 2.0125 - val_loss: 1167.5570\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.5820 - val_loss: 1181.4529\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3290 - val_loss: 1173.3669\n",
      "Epoch 00003: early stopping\n",
      "4\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 2.5941 - val_loss: 1225.2389\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.4551 - val_loss: 1214.2632\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3293 - val_loss: 1198.9612\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2870 - val_loss: 1183.5878\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2792 - val_loss: 1176.9171\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2793 - val_loss: 1171.1635\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2782 - val_loss: 1163.6096\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2620 - val_loss: 1157.2004\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2797 - val_loss: 1153.7873\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2629 - val_loss: 1148.9327\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2624 - val_loss: 1142.3705\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.3003 - val_loss: 1141.7737\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.2789 - val_loss: 1140.4365\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.2500 - val_loss: 1135.5211\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.2438 - val_loss: 1134.7395\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.2491 - val_loss: 1131.3868\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.2388 - val_loss: 1129.2346\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.3374 - val_loss: 1128.0652\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.3799 - val_loss: 1138.0735\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.3749 - val_loss: 1146.7233\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, softmax & adam, kernal_size = (5,5) \n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),activation='relu',input_shape=input_shape, padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1),activation='sigmoid',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(128,kernel_size=(5, 5), strides=(1, 1),activation='softmax',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(500, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.summary()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"cnn/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)   \n",
    "    cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, verbose=1, mode='auto')\n",
    "    cnn_model.fit(cnn_X_train, lstm_y_train, batch_size=128, validation_data=(cnn_X_test, lstm_y_test), \n",
    "                  callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid, softmax & adam, kernal_size = (5,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 33.58668172050748\n",
      "R2 score -0.464094028606832\n",
      "MSE::  1128.065188994671\n"
     ]
    }
   ],
   "source": [
    "cnn_model.load_weights('cnn/weights.hdf5')\n",
    "\n",
    "cnn_pred = cnn_model.predict(cnn_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, cnn_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, cnn_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 1, 7, 32)          10272     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 4, 64)          131136    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 2, 128)         524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 500)               64500     \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 730,825\n",
      "Trainable params: 730,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 305.0728 - val_loss: 4934.5873\n",
      "Epoch 2/100\n",
      " - 7s - loss: 227.3345 - val_loss: 4479.3442\n",
      "Epoch 3/100\n",
      " - 8s - loss: 165.6883 - val_loss: 4052.9900\n",
      "Epoch 4/100\n",
      " - 7s - loss: 123.0372 - val_loss: 3601.2132\n",
      "Epoch 5/100\n",
      " - 7s - loss: 78.5568 - val_loss: 3076.9003\n",
      "Epoch 6/100\n",
      " - 7s - loss: 46.6004 - val_loss: 2608.3100\n",
      "Epoch 7/100\n",
      " - 7s - loss: 24.1666 - val_loss: 2161.1471\n",
      "Epoch 8/100\n",
      " - 8s - loss: 13.4453 - val_loss: 1862.3818\n",
      "Epoch 9/100\n",
      " - 9s - loss: 8.6096 - val_loss: 1691.2234\n",
      "Epoch 10/100\n",
      " - 9s - loss: 7.2134 - val_loss: 1603.0390\n",
      "Epoch 11/100\n",
      " - 8s - loss: 6.0415 - val_loss: 1564.7812\n",
      "Epoch 12/100\n",
      " - 8s - loss: 6.1109 - val_loss: 1562.8308\n",
      "Epoch 13/100\n",
      " - 8s - loss: 4.2061 - val_loss: 1519.5115\n",
      "Epoch 14/100\n",
      " - 8s - loss: 4.9545 - val_loss: 1495.0714\n",
      "Epoch 15/100\n",
      " - 8s - loss: 4.3669 - val_loss: 1476.6730\n",
      "Epoch 16/100\n",
      " - 7s - loss: 4.5317 - val_loss: 1477.2225\n",
      "Epoch 17/100\n",
      " - 7s - loss: 3.0960 - val_loss: 1440.7667\n",
      "Epoch 18/100\n",
      " - 7s - loss: 3.1027 - val_loss: 1449.8745\n",
      "Epoch 19/100\n",
      " - 7s - loss: 3.5243 - val_loss: 1435.0929\n",
      "Epoch 20/100\n",
      " - 7s - loss: 3.1130 - val_loss: 1423.2194\n",
      "Epoch 21/100\n",
      " - 8s - loss: 2.8016 - val_loss: 1367.1604\n",
      "Epoch 22/100\n",
      " - 7s - loss: 2.8635 - val_loss: 1373.0494\n",
      "Epoch 23/100\n",
      " - 10s - loss: 2.6278 - val_loss: 1401.1150\n",
      "Epoch 00023: early stopping\n",
      "1\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 4.2812 - val_loss: 1384.3374\n",
      "Epoch 2/100\n",
      " - 7s - loss: 2.3534 - val_loss: 1380.6503\n",
      "Epoch 3/100\n",
      " - 7s - loss: 2.2472 - val_loss: 1374.6751\n",
      "Epoch 4/100\n",
      " - 7s - loss: 2.0052 - val_loss: 1370.5839\n",
      "Epoch 5/100\n",
      " - 7s - loss: 2.2137 - val_loss: 1403.8554\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.0262 - val_loss: 1390.7332\n",
      "Epoch 00006: early stopping\n",
      "2\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 3.1546 - val_loss: 1383.3284\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.7138 - val_loss: 1377.7726\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.8113 - val_loss: 1405.4323\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.4169 - val_loss: 1384.5890\n",
      "Epoch 00004: early stopping\n",
      "3\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 2.6166 - val_loss: 1375.6116\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.5249 - val_loss: 1362.4872\n",
      "Epoch 3/100\n",
      " - 8s - loss: 1.2181 - val_loss: 1369.8687\n",
      "Epoch 4/100\n",
      " - 9s - loss: 1.5193 - val_loss: 1379.1766\n",
      "Epoch 00004: early stopping\n",
      "4\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 23s - loss: 2.4210 - val_loss: 1379.3275\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.1305 - val_loss: 1328.7789\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.2929 - val_loss: 1442.7109\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.6037 - val_loss: 1388.0763\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, softmax & rmsprop, kernal_size = (8,8) \n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(8, 8), strides=(1, 1),activation='relu',input_shape=input_shape, padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(8, 8), strides=(1, 1),activation='sigmoid',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(128,kernel_size=(8, 8), strides=(1, 1),activation='softmax',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(500, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.summary()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"cnn/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)   \n",
    "    cnn_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, verbose=1, mode='auto')\n",
    "    cnn_model.fit(cnn_X_train, lstm_y_train, batch_size=128, validation_data=(cnn_X_test, lstm_y_test), \n",
    "                  callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for relu, sigmoid, softmax & rmsprop, kernal_size = (8,8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 36.45242002901831\n",
      "R2 score -0.7245965125366167\n",
      "MSE::  1328.7789259719757\n"
     ]
    }
   ],
   "source": [
    "cnn_model.load_weights('cnn/weights.hdf5')\n",
    "\n",
    "cnn_pred = cnn_model.predict(cnn_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, cnn_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, cnn_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 1, 7, 32)          672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1, 4, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 500)               64500     \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 175.0346 - val_loss: 3546.6313\n",
      "Epoch 2/100\n",
      " - 2s - loss: 115.0500 - val_loss: 3473.7397\n",
      "Epoch 3/100\n",
      " - 1s - loss: 110.6615 - val_loss: 3099.1483\n",
      "Epoch 4/100\n",
      " - 1s - loss: 114.9588 - val_loss: 3257.9747\n",
      "Epoch 5/100\n",
      " - 1s - loss: 124.8971 - val_loss: 3503.7423\n",
      "Epoch 00005: early stopping\n",
      "1\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 121.0396 - val_loss: 3648.4099\n",
      "Epoch 2/100\n",
      " - 1s - loss: 121.2427 - val_loss: 3481.4470\n",
      "Epoch 3/100\n",
      " - 1s - loss: 120.6318 - val_loss: 3486.1311\n",
      "Epoch 4/100\n",
      " - 1s - loss: 115.9005 - val_loss: 3665.2389\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 116.6219 - val_loss: 2940.8030\n",
      "Epoch 2/100\n",
      " - 1s - loss: 118.1310 - val_loss: 3470.5473\n",
      "Epoch 3/100\n",
      " - 1s - loss: 120.9476 - val_loss: 3574.6375\n",
      "Epoch 00003: early stopping\n",
      "3\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 121.1531 - val_loss: 3460.0959\n",
      "Epoch 2/100\n",
      " - 1s - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujali\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:543: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\ujali\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:436: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: nan - val_loss: nan\n",
      "Epoch 00003: early stopping\n",
      "4\n",
      "Train on 3066 samples, validate on 1309 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      " - 1s - loss: nan - val_loss: nan\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "# relu, sigmoid, softmax & sgd, kernal_size = (2,2) \n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(2, 2), strides=(1, 1),activation='relu',input_shape=input_shape, padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(2, 2), strides=(1, 1),activation='sigmoid',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Conv2D(128,kernel_size=(2, 2), strides=(1, 1),activation='softmax',padding='same'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(500, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.summary()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"cnn/weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)   \n",
    "    cnn_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, verbose=1, mode='auto')\n",
    "    cnn_model.fit(cnn_X_train, lstm_y_train, batch_size=128, validation_data=(cnn_X_test, lstm_y_test), \n",
    "                  callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# relu, sigmoid, softmax & sgd, kernal_size = (2,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 54.22917122758208\n",
      "R2 score -2.8168114495757717\n",
      "MSE::  2940.8030120304156\n"
     ]
    }
   ],
   "source": [
    "cnn_model.load_weights('cnn/weights.hdf5')\n",
    "\n",
    "cnn_pred = cnn_model.predict(cnn_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, cnn_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, cnn_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Feature 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different sequence sizes for vectorizing the data and pridicting the close value for the nth day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3068, 5, 5)\n",
      "Shape of y_train: (3068,)\n",
      "Shape of x_test: (1311, 5, 5)\n",
      "Shape of y_test: (1311,)\n"
     ]
    }
   ],
   "source": [
    "lstm_X_train, lstm_y_train = to_sequences(5, list_X_train)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(lstm_X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(lstm_y_train.shape))\n",
    "\n",
    "lstm_X_test, lstm_y_test = to_sequences(5, list_X_test)\n",
    "\n",
    "print(\"Shape of x_test: {}\".format(lstm_X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(lstm_y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1311 samples\n",
      "Epoch 1/100\n",
      " - 38s - loss: 42.4660 - val_loss: 165.9230\n",
      "Epoch 2/100\n",
      " - 19s - loss: 10.2280 - val_loss: 236.6722\n",
      "Epoch 3/100\n",
      " - 19s - loss: 6.5715 - val_loss: 722.0345\n",
      "Epoch 4/100\n",
      " - 19s - loss: 4.8429 - val_loss: 217.3399\n",
      "Epoch 5/100\n",
      " - 23s - loss: 3.7861 - val_loss: 430.0473\n",
      "Epoch 6/100\n",
      " - 18s - loss: 3.5748 - val_loss: 275.3755\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1311 samples\n",
      "Epoch 1/100\n",
      " - 35s - loss: 40.0629 - val_loss: 44.6024\n",
      "Epoch 2/100\n",
      " - 18s - loss: 9.5222 - val_loss: 269.9022\n",
      "Epoch 3/100\n",
      " - 19s - loss: 5.8828 - val_loss: 193.8951\n",
      "Epoch 4/100\n",
      " - 18s - loss: 4.1783 - val_loss: 322.9933\n",
      "Epoch 5/100\n",
      " - 18s - loss: 5.6753 - val_loss: 426.0769\n",
      "Epoch 6/100\n",
      " - 18s - loss: 3.9832 - val_loss: 351.5621\n",
      "Epoch 00006: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1311 samples\n",
      "Epoch 1/100\n",
      " - 36s - loss: 61.1573 - val_loss: 134.5600\n",
      "Epoch 2/100\n",
      " - 19s - loss: 8.5732 - val_loss: 207.0760\n",
      "Epoch 3/100\n",
      " - 20s - loss: 4.6469 - val_loss: 220.0813\n",
      "Epoch 4/100\n",
      " - 19s - loss: 3.8236 - val_loss: 198.2777\n",
      "Epoch 5/100\n",
      " - 19s - loss: 7.1429 - val_loss: 152.2268\n",
      "Epoch 6/100\n",
      " - 18s - loss: 4.7742 - val_loss: 367.5840\n",
      "Epoch 00006: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1311 samples\n",
      "Epoch 1/100\n",
      " - 37s - loss: 41.6139 - val_loss: 272.9009\n",
      "Epoch 2/100\n",
      " - 20s - loss: 7.7708 - val_loss: 252.8352\n",
      "Epoch 3/100\n",
      " - 20s - loss: 6.5249 - val_loss: 133.3515\n",
      "Epoch 4/100\n",
      " - 18s - loss: 4.4459 - val_loss: 141.1539\n",
      "Epoch 5/100\n",
      " - 17s - loss: 6.1224 - val_loss: 118.7637\n",
      "Epoch 6/100\n",
      " - 18s - loss: 4.1613 - val_loss: 306.7212\n",
      "Epoch 7/100\n",
      " - 18s - loss: 3.2654 - val_loss: 431.9972\n",
      "Epoch 8/100\n",
      " - 17s - loss: 2.6215 - val_loss: 392.4196\n",
      "Epoch 9/100\n",
      " - 19s - loss: 2.5178 - val_loss: 393.1290\n",
      "Epoch 10/100\n",
      " - 24s - loss: 2.2319 - val_loss: 407.8611\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1311 samples\n",
      "Epoch 1/100\n",
      " - 37s - loss: 52.5298 - val_loss: 109.9563\n",
      "Epoch 2/100\n",
      " - 18s - loss: 8.2950 - val_loss: 204.1935\n",
      "Epoch 3/100\n",
      " - 18s - loss: 5.1343 - val_loss: 98.0028\n",
      "Epoch 4/100\n",
      " - 19s - loss: 4.5531 - val_loss: 160.7387\n",
      "Epoch 5/100\n",
      " - 19s - loss: 3.8159 - val_loss: 227.1345\n",
      "Epoch 6/100\n",
      " - 18s - loss: 4.0192 - val_loss: 341.5135\n",
      "Epoch 7/100\n",
      " - 18s - loss: 2.8486 - val_loss: 356.4422\n",
      "Epoch 8/100\n",
      " - 21s - loss: 2.8171 - val_loss: 205.4479\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(256, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(5,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(100, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for Sequence Size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.678500770883402\n",
      "R2 score 0.942054080484016\n",
      "MSE::  44.6023725466902\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3063, 10, 5)\n",
      "Shape of y_train: (3063,)\n",
      "Shape of x_test: (1306, 10, 5)\n",
      "Shape of y_test: (1306,)\n"
     ]
    }
   ],
   "source": [
    "lstm_X_train, lstm_y_train = to_sequences(10, list_X_train)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(lstm_X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(lstm_y_train.shape))\n",
    "\n",
    "lstm_X_test, lstm_y_test = to_sequences(10, list_X_test)\n",
    "\n",
    "print(\"Shape of x_test: {}\".format(lstm_X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(lstm_y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3063 samples, validate on 1306 samples\n",
      "Epoch 1/100\n",
      " - 58s - loss: 48.1722 - val_loss: 161.4105\n",
      "Epoch 2/100\n",
      " - 35s - loss: 7.5949 - val_loss: 188.0555\n",
      "Epoch 3/100\n",
      " - 35s - loss: 5.6363 - val_loss: 217.4528\n",
      "Epoch 4/100\n",
      " - 35s - loss: 5.2518 - val_loss: 336.9488\n",
      "Epoch 5/100\n",
      " - 34s - loss: 3.5703 - val_loss: 269.4001\n",
      "Epoch 6/100\n",
      " - 34s - loss: 3.3514 - val_loss: 334.3573\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3063 samples, validate on 1306 samples\n",
      "Epoch 1/100\n",
      " - 54s - loss: 53.4853 - val_loss: 186.6790\n",
      "Epoch 2/100\n",
      " - 33s - loss: 17.6304 - val_loss: 278.4780\n",
      "Epoch 3/100\n",
      " - 53s - loss: 6.5941 - val_loss: 661.7158\n",
      "Epoch 4/100\n",
      " - 40s - loss: 5.7353 - val_loss: 516.1079\n",
      "Epoch 5/100\n",
      " - 42s - loss: 4.0791 - val_loss: 374.5149\n",
      "Epoch 6/100\n",
      " - 42s - loss: 3.1664 - val_loss: 456.1546\n",
      "Epoch 00006: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3063 samples, validate on 1306 samples\n",
      "Epoch 1/100\n",
      " - 84s - loss: 50.6196 - val_loss: 365.3169\n",
      "Epoch 2/100\n",
      " - 43s - loss: 14.5288 - val_loss: 344.8392\n",
      "Epoch 3/100\n",
      " - 43s - loss: 7.5905 - val_loss: 263.2923\n",
      "Epoch 4/100\n",
      " - 43s - loss: 4.7854 - val_loss: 260.2609\n",
      "Epoch 5/100\n",
      " - 44s - loss: 5.5481 - val_loss: 352.2194\n",
      "Epoch 6/100\n",
      " - 44s - loss: 4.1295 - val_loss: 327.2636\n",
      "Epoch 7/100\n",
      " - 45s - loss: 3.2904 - val_loss: 240.5662\n",
      "Epoch 8/100\n",
      " - 43s - loss: 2.9924 - val_loss: 211.1820\n",
      "Epoch 9/100\n",
      " - 43s - loss: 3.2761 - val_loss: 224.9331\n",
      "Epoch 10/100\n",
      " - 43s - loss: 2.5072 - val_loss: 216.9340\n",
      "Epoch 11/100\n",
      " - 43s - loss: 2.7459 - val_loss: 339.5211\n",
      "Epoch 12/100\n",
      " - 43s - loss: 3.0329 - val_loss: 433.5297\n",
      "Epoch 13/100\n",
      " - 43s - loss: 2.9813 - val_loss: 362.5721\n",
      "Epoch 00013: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3063 samples, validate on 1306 samples\n",
      "Epoch 1/100\n",
      " - 71s - loss: 44.4044 - val_loss: 356.7111\n",
      "Epoch 2/100\n",
      " - 42s - loss: 12.0126 - val_loss: 179.9897\n",
      "Epoch 3/100\n",
      " - 42s - loss: 5.1237 - val_loss: 339.0004\n",
      "Epoch 4/100\n",
      " - 42s - loss: 3.5222 - val_loss: 320.3398\n",
      "Epoch 5/100\n",
      " - 42s - loss: 3.6669 - val_loss: 388.6483\n",
      "Epoch 6/100\n",
      " - 43s - loss: 3.1772 - val_loss: 286.9093\n",
      "Epoch 7/100\n",
      " - 43s - loss: 3.1430 - val_loss: 420.5743\n",
      "Epoch 00007: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3063 samples, validate on 1306 samples\n",
      "Epoch 1/100\n",
      " - 71s - loss: 49.9390 - val_loss: 377.5919\n",
      "Epoch 2/100\n",
      " - 44s - loss: 7.8740 - val_loss: 395.7085\n",
      "Epoch 3/100\n",
      " - 44s - loss: 6.2641 - val_loss: 301.0800\n",
      "Epoch 4/100\n",
      " - 44s - loss: 4.1972 - val_loss: 402.6333\n",
      "Epoch 5/100\n",
      " - 44s - loss: 3.3582 - val_loss: 377.4242\n",
      "Epoch 6/100\n",
      " - 44s - loss: 3.2928 - val_loss: 331.0622\n",
      "Epoch 7/100\n",
      " - 44s - loss: 3.3509 - val_loss: 292.6791\n",
      "Epoch 8/100\n",
      " - 44s - loss: 3.3695 - val_loss: 391.0502\n",
      "Epoch 9/100\n",
      " - 44s - loss: 2.4343 - val_loss: 425.6656\n",
      "Epoch 10/100\n",
      " - 44s - loss: 2.8469 - val_loss: 390.4060\n",
      "Epoch 11/100\n",
      " - 44s - loss: 2.8296 - val_loss: 469.6478\n",
      "Epoch 12/100\n",
      " - 44s - loss: 2.4668 - val_loss: 418.1974\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(256, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(10,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(100, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for Sequence Size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.704744983066426\n",
      "R2 score 0.7908157855907795\n",
      "MSE::  161.41054508475153\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3065, 8, 5)\n",
      "Shape of y_train: (3065,)\n",
      "Shape of x_test: (1308, 8, 5)\n",
      "Shape of y_test: (1308,)\n"
     ]
    }
   ],
   "source": [
    "lstm_X_train, lstm_y_train = to_sequences(8, list_X_train)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(lstm_X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(lstm_y_train.shape))\n",
    "\n",
    "lstm_X_test, lstm_y_test = to_sequences(8, list_X_test)\n",
    "\n",
    "print(\"Shape of x_test: {}\".format(lstm_X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(lstm_y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3065 samples, validate on 1308 samples\n",
      "Epoch 1/100\n",
      " - 65s - loss: 41.7839 - val_loss: 92.1265\n",
      "Epoch 2/100\n",
      " - 36s - loss: 18.2719 - val_loss: 316.0993\n",
      "Epoch 3/100\n",
      " - 36s - loss: 7.7761 - val_loss: 163.4652\n",
      "Epoch 4/100\n",
      " - 36s - loss: 4.0644 - val_loss: 366.3321\n",
      "Epoch 5/100\n",
      " - 36s - loss: 3.3124 - val_loss: 283.0124\n",
      "Epoch 6/100\n",
      " - 39s - loss: 2.5585 - val_loss: 332.2272\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3065 samples, validate on 1308 samples\n",
      "Epoch 1/100\n",
      " - 66s - loss: 65.2736 - val_loss: 248.2000\n",
      "Epoch 2/100\n",
      " - 41s - loss: 20.8445 - val_loss: 330.6069\n",
      "Epoch 3/100\n",
      " - 40s - loss: 26.1126 - val_loss: 419.6238\n",
      "Epoch 4/100\n",
      " - 38s - loss: 10.1319 - val_loss: 128.4288\n",
      "Epoch 5/100\n",
      " - 38s - loss: 5.5814 - val_loss: 325.8761\n",
      "Epoch 6/100\n",
      " - 39s - loss: 5.1341 - val_loss: 291.0508\n",
      "Epoch 7/100\n",
      " - 39s - loss: 3.6255 - val_loss: 494.2617\n",
      "Epoch 8/100\n",
      " - 40s - loss: 3.5250 - val_loss: 275.7062\n",
      "Epoch 9/100\n",
      " - 38s - loss: 2.5781 - val_loss: 439.4158\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3065 samples, validate on 1308 samples\n",
      "Epoch 1/100\n",
      " - 67s - loss: 42.0614 - val_loss: 337.8177\n",
      "Epoch 2/100\n",
      " - 43s - loss: 8.4806 - val_loss: 272.5553\n",
      "Epoch 3/100\n",
      " - 44s - loss: 6.5565 - val_loss: 422.4799\n",
      "Epoch 4/100\n",
      " - 37s - loss: 5.7414 - val_loss: 277.1339\n",
      "Epoch 5/100\n",
      " - 37s - loss: 3.6340 - val_loss: 204.0041\n",
      "Epoch 6/100\n",
      " - 36s - loss: 3.1074 - val_loss: 261.7831\n",
      "Epoch 7/100\n",
      " - 37s - loss: 3.5428 - val_loss: 478.6173\n",
      "Epoch 8/100\n",
      " - 36s - loss: 2.9328 - val_loss: 241.9678\n",
      "Epoch 9/100\n",
      " - 37s - loss: 2.3722 - val_loss: 482.3124\n",
      "Epoch 10/100\n",
      " - 37s - loss: 3.4492 - val_loss: 413.2699\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3065 samples, validate on 1308 samples\n",
      "Epoch 1/100\n",
      " - 63s - loss: 46.4317 - val_loss: 315.6641\n",
      "Epoch 2/100\n",
      " - 35s - loss: 10.6983 - val_loss: 156.3900\n",
      "Epoch 3/100\n",
      " - 36s - loss: 4.6736 - val_loss: 256.6810\n",
      "Epoch 4/100\n",
      " - 35s - loss: 4.5535 - val_loss: 403.1865\n",
      "Epoch 5/100\n",
      " - 36s - loss: 4.2608 - val_loss: 244.9357\n",
      "Epoch 6/100\n",
      " - 36s - loss: 4.5742 - val_loss: 330.5315\n",
      "Epoch 7/100\n",
      " - 35s - loss: 3.2496 - val_loss: 415.4016\n",
      "Epoch 00007: early stopping\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3065 samples, validate on 1308 samples\n",
      "Epoch 1/100\n",
      " - 66s - loss: 44.8367 - val_loss: 184.7429\n",
      "Epoch 2/100\n",
      " - 38s - loss: 13.6044 - val_loss: 426.8457\n",
      "Epoch 3/100\n",
      " - 38s - loss: 11.5094 - val_loss: 529.4395\n",
      "Epoch 4/100\n",
      " - 38s - loss: 5.2815 - val_loss: 434.7815\n",
      "Epoch 5/100\n",
      " - 38s - loss: 3.9740 - val_loss: 210.3470\n",
      "Epoch 6/100\n",
      " - 39s - loss: 4.0745 - val_loss: 308.0811\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"lstm/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(i)\n",
    "    print('Build model...')\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(256, activation='relu', dropout=0.1, recurrent_dropout=0.1, input_shape=(8,5)))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(150, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(100, activation='relu'))\n",
    "    lstm_model.add(Dropout(0.10))\n",
    "    lstm_model.add(Dense(50, activation='relu'))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_test, lstm_y_test), \n",
    "                   callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores for Sequence Size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.598255712427706\n",
      "R2 score 0.8804892584221987\n",
      "MSE::  92.1265127211511\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights('lstm/best_weights.hdf5')\n",
    "\n",
    "lstm_pred = lstm_model.predict(lstm_X_test)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(lstm_y_test, lstm_pred)) \n",
    "\n",
    "print(\"RMSE: {}\".format(score))\n",
    "print(\"R2 score\",metrics.r2_score(lstm_y_test, lstm_pred))\n",
    "print(\"MSE:: \", metrics.mean_squared_error(lstm_y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
